title,body,visibility,tags
update frequently asked questions for hw,we will collect another round of aws request the ddl to fill in the form is april th p m instructions are at q cv can i use pretrained models existing frameworks a contrains many specifications on using libraries frameworks please read carefully q rs what is the results csv file in the rs dataset a that is the sample output please refer to section of the writeup q where is section a sorry that is a typo it is section q what version of the library or language should i use a whichever you prefer pin,public,hw9
hw released,the write up for hw can be found in piazza resources there are three separate assignments on autolab one for each task you only need to submit one of them pin,public,hw9
permitted libraries for hw,the following libraries can be used in homework if there is a library you would like to use that is not included on this list please submit your request below this list will be updated as libraries are approved for use sci kit learn sklearn for pythonscipy numpy matplotlib csv re regular expressions osshogun ml toolbox for octaveopencvsimplecvtensorflow and tensorflow slimtorch pytorchpython imaging librarykevin murphy's bayes net toolboxfactorie malletopengmkerasmatconvnetmatlab statistic and ml toolboxtheanocaffeglove https nlp stanford edu projects glove matlab neural network toolbox nltk pyfann pandas tflearn pin,public,hw9
final exam review and mock final,hi all we have heard from many students who are concerned about the fact that they will not be able to make it to the final exam review recitation originally scheduled for thursday may pm therefore we have moved the final exam review session to take place during class on wednesday may so that all students are able to attend since the review session is now taking place during class we are going to give a mock final on thursday may from pm in place of your regularly scheduled recitation mock final locations section a ph sections b and c dh we will not be offering any other sessions for the mock final if you want to take the mock final you must be present on may from pm if you are not able to attend you may pick up a copy of the mock final the following day warm regards course staff pin,public,exam
tips for programming machine learning algorithms,hi all one of the key learning objectives of this course is the ability to translate back and forth between math and code python octave etc our hope is that you learn this through hands on practice on the homework if you're like me when you first see the material in lecture you may feel as though it makes sense however the process of implementing that ml algorithm then exposes important gaps in your understanding this is a great opportunity for learning that said it can also be frustrating here are a few tips for programming ml algorithms work through a small example on paper first do this in two phases before you start implementing anything in phase i write down some pseudocode it might only be a few lines describing the algorithm you are implementing identify the data structures you'll need to efficiently store data parameters intermediate quantities etc in phase ii construct a tiny datasets e g features examples and simplify it as much as possible on paper run your algorithm end to end on this tiny dataset and jot down all of the intermediate quantities and the final result check that your code works as expected on the tiny dataset from phase ii above if it doesn't work this provides an excellent debugging tool find the first intermediate quantity for which your code and paper implementations came up with different values the source of your bug is likely not too far away check that your code works on synthetically generated data that matches the model's assumptions in class i often generate simple d datasets and plot the results so we can see what the model has learned if you generate the data in a way that you know the model should be able to learn from then you can often better assess what's going wrong with your code don't trust your code if your code seems to run end to end on your laptop but doesn't work on autolab there's a good chance your code isn't doing what you think it is check the function signature given in the homework writeup and make sure that your implementation matches what is expected check if the function signature is ambiguous for example if the function signature expects a matrix that has dimensions n and m but we didn't specify m times n vs n times m you should let us know with a piazza note don't trust autolab a on autolab does not imply that your code is correct assuming otherwise could cause you to lose points on qna or gradescope questions related to your programming implementation our unit tests on autolab check for expected outputs on given known inputs however you could still have bugs in your code that autolab doesn't catch for example there are many different functions that given x as input will return y as output write unit tests for your code since autolab can't be trusted you don't know which edge cases it catches and which it doesn't write your own unit tests which you do trust this is standard practice in industry and no software engineer would trust your code if you couldn't demonstrate that it passed a battery of known unit tests ex if you are optimizing your code for speed a really helpful unit test is to make sure that the output of the optimized version is identical to the output of the known to be correct but slow version you just wrote ex remove stochasticity when testing if you need to test something for correctness remove the stochasticity from the problem we did this for you in hw by providing known initial cluster centers for k means this is generally good practice for unit tests start early it's sometimes difficult to assess how easy or difficult a programming assignment is until you've actually completed it correctly the software industry knows this and works really hard to make these time requirement predictions nonetheless because debugging ml algorithms can be particularly tricky it's always good to assume you'll need lots of time we think that and above are so important that we have started to incorporate them into the homework questions note that homework will be a much more challenging programming assignment than the previous assignments hopefully these programming tips will be helpful as you build your first cnn cheers matt ps if you're curious to learn more about the challenges of developing real world machine learning systems at scale check out this paper from google folks sculley et al machine learning the high interest credit card of technical debt pin,public,hw7 other
peer tutoring group assignments,hello all the peer tutoring group assignments are now available each tutor should contact their group members to arrange a weekly meeting please check your email for more information peer tutoring group assignments for those of you who are participating in the peer tutoring program take note of the following all meetings must take place at a prearranged public location and time if any changes are made to the meeting schedule you must notify the assistant instructors if any issues arise between group members notify the assistant instructors all students are still bound by the collaboration policy you should not give out homework solutions or share code with other students if you signed up for the tutoring program on or before march th but are not on the list please email the assistant instructors all students involved in the peer tutoring program should review our standing appointment policy tutors information for tutors warm regards brynn update see for information if you are having difficulty contacting your group pin,public,other
office hour queueing system,hi all for all office hours going forward we will be using the an online office hours queue using it is easy log into https queue mlcourse org using any google account e g your google apps linked andrew account or an gmail com address when you arrive at office hours in person not before add yourself to the queue with a question the ta will call you when it's your turn some other details the tas will attempt to spend a fixed number of minutes with each person e g in order to more evenly allocate their time if you're still feeling stuck after your time is up feel free to add yourself back to the queue with another question if the ta calls you and you're not there they will freeze your position on the queue you can unfreeze yourself when you come back if you are frozen twice you will lose your place in line having your question written down clearly ahead of time helps us a lot if you're not sure what your question is spend a bit of time thinking through what you are trying to ask this process is often in and of itself quite elucidating we are hoping that this will help you all better plan out your time and increase access to our tas cheers matt ps the oh queue is also linked from our course website pin,public,logistics
piazza etiquette,the best questions for piazza and the ones on which you will surely receive good answers will typically exhibit the following qualities they are short and targeted the type of answer you want is not ambiguous you highlight the specific aspect of a concept or problem that is confusing they are asked a couple days before the deadline of a homework matt pin,public,logistics
final exam,hi all the final exam for this course is scheduled to take place monday may from p m p m we do not yet have a location for the exam but i will update this post as soon as we know which classroom s we have been assigned note you will be allowed to bring a page sheet of notes front and back to use during the exam warm regards brynn p s for information about the midterm exam see pin,public,exam
do note post code or solutions publicly,hi all our course policy is extremely clear that you have a duty to protect your own work as such you are expected not to post code or homework solutions publicly either to piazza or anywhere else github bitbucket web forums etc that said we want to protect honest students from others' mistakes so we need a special case if another student posts code or a homework solution publicly in a piazza note you may inadvertently be exposed to it at no fault of your own this exposure is not cheating so what should you do if no one else has inform the class and instructors that this appears to be a code solution that should not have been posted the tas will change the note to be private as quickly as possible do not refer back to that code solution if a copy was stored in your email just delete it then write your own answer without it when submitting your collaboration questions note that you saw the publicly posted code solution in the piazza note doing so will ensure that we do not penalize you for something that could not possibly be construed as purposeful cheating the above special case only applies to publicly posted piazza notes containing homework solutions cheers matt ps if you haven't already i encourage you to read pin,public,other
please do not cheat,hi all speaking on behalf of the entire course staff we all want you to succeed in this course my primary goal this semester is to see you all become machine learning experts and demonstrate that ability on the homework and exams it has come to my attention that there may be submissions for hw which appear to violate our course policy specifically it appears as though we have received duplicate code from more than one pair of students at this time we are still investigating the matter as such we will likely not be able to notify those students prior to the hw deadline this is of the utmost importance because our course policy dictates that two incidents of cheating e g duplicate code submission will lead to automatic failure in the course we are unable to waiver on this policy in order to be fair to the students who have worked diligently without cheating i encourage each of you to please re read our entire course policy on collaboration on the course website this was carefully written to express our values for your education and assessment pay particular attention to the section duty to protect one's work if the language is unclear you could additionally watch the video from lecture on this topic you could even ask questions after class on monday or wednesday if you believe that you have submitted the same code as another student for hw in part or in full please contact me via email as soon as possible though coming forward will not lessen the penalty it will act as a demonstration of your integrity further it will enable me to work with you to ensure that it does not happen a second time dealing with each suspected incident of cheating takes an enormous amount of time on the part of the course staff that is time that we would otherwise be spending preparing exam questions fine tuning and testing homeworks or thinking through how to more carefully explain the material in lectures and recitations we do not want you to cheat both for you own good and for the good of this course please do not cheat sincerely matt pin,public,other
lecture videos panopto folder,hi all i just wanted to reiterate that the lecture videos appear in the folder linked below as soon as they are uploaded this is usually by pm on the same day as the lecture the easiest way to find them is to click the link twice the first time you will log in with your andrew id and see an empty folder the second time it will take you directly to the list of videos all lecture videos panopto folder https scs hosted panopto com panopto pages sessions list aspx folderid c f e fd f f b e cd dfb fyi i also added links on the schedule page of our website to individual videos however you should always just look for the latest videos directly in the panopto folder since they will usually appear there a few days before i get them linked in the schedule of course we strongly prefer that you attend class in person see however if you are unable to for some reason you are also welcome to catch up via the video cheers matt pin,public,videos
recitation schedule and slides,please find recitation schedule here you can access slides and other materials from the recitations here pin,public,logistics
resources for math review,the table below contains some of the lecture materials from the course math background for machine learning the material contained in these lecture notes represents a good portion of the knowledge we expect you to come into this course with particularly related to the math background not as much the computer science while our background exercises were created to try to cover the majority of this material the following notes contain detailed explanations of a wider breadth of topics we strongly suggest that you review them lecture topiclecture notessetssets lecture notestypesdata types and functionslogicpropositional logicprobability probability probability factored distributions mean and variance linear algebra functions and function spaces vector spaces vector spaces and dimension geometry of functions matrices and linear operators linear equations matrix calculus vector space examples matrix differentials working with differentials second and higher differentials working with differentials ii statistics and inference continuous random variables statistical inference the lists below contain some additional resources for reviewing probability and linear algebra these come from a variety of sources but are all very thorough probability probability cheatsheet blitzstein chenprobability review slides rob hall linear algebra linear algebra review notes zico kolter linear algebra review videos zico kolter matrix cookbook notes petersen pederson pin,public,hw1
course website,hi all the course website is here http www cs cmu edu mgormley courses s matt pin,public,logistics
rs writeup analysis of results,what would be things to write in the analysis of results section of the gradescope writeup for the rs task thank you,public,hw9
cv and rs autograder up,hi all the new version of cv and rs autograder is ready you can see your new final scores on autolab now if you have any questions please leave a message under this post good luck hw team,public,hw9
rs missing,what should we do about users that have rated no movie or movies that was not rated by any user thanks,public,hw9
nlp unable to get f score,i have stored the test data set columns in a csv and my predicted labels column in another when i use the comparetwo function it gives me a weird result instead of the f score comparetwo 'test csv' 'predict csv' b'' am i giving the correct inputs to the function can someone help me figure this out thanks,public,hw9
changes to hw grading scheme,hi all we are making three important changes to the way grades for hw will be assigned the changes the changes to your grades will all be monotonically increasing that is no one's grade will go down for all three tasks we will interpolate between the current grade thresholds in the current grading scheme a submission with a rmse would receive an but a rmse would receive a our new interpolation scheme will ensure that these two submissions receive more similar grades for the nlp task only we will slightly adjust the thresholds required to obtain the corresponding grades this will not hurt your grade the purpose of this change is to reflect the abundance of tuning and feature engineering that is required to get top performance on this task some students have put forth a substantial effort towards this assignment but still haven't been able to obtain good performance on autolab we will be adding a new grading scheme that applies to all students let alpha denote the autolab score and beta denote the gradescope report score the old grading scheme computed your score as alpha beta under the new scheme we will compute your grade as max alpha beta min alpha beta in words the highest grade you can receive from the alternate report focused scheme is the purpose of this change is to ensure that if you put in a substantial effort towards training interesting models tuning hyperparameters doing appropriate pre processing and feature engineering and reporting your results then you will still be able to get an a grade on this assignment our assessment of that significant effort will be through our grading of your gradescope report the changes for and will take some time to put into place we will send a followup announcement when these changes are live on autolab some comments it is my strong preference to think of a grading scheme as a contract the assignment specifies the work to be done and the grade that you receive for doing it i recognize that for those of you who were already well on your way to receiving a on this assignment a change of contract of this variety is simply unfair that is you could have potentially expended slightly less effort for a slightly worse grade if you had this information earlier you have my utmost apologies these changes were not put into place specifically for you rather the goal of these changes is to ensure that we do not give out unfairly low grades to students who put forth a substantial effort but who have thus far been unable to achieve a high score on autolab our goal was to expose you to the very real challenges of getting machine learning algorithms to work on real world problems i believe these changes to the grading scheme will more accurately reflect that goal if you have any concerns about these changes i encourage you to chat with me after class on wednesday or at my office hours on thursday cheers matt,public,hw9
how to submit regrade request in gradescope,in the course website it says if you believe an error was made during manual grading you ll be able to submit a regrade request on gradescope can someone explain how exactly i can submit a regrade request in gradescope thank you,public,logistics
q in homework,in the solution it says v pc x but in the matlab code it say x reduced unbiased x u n components i'm very confused so should it be pc v x also in some references it says vv t i is this correct and why,public,hw6
cv how many iterations do we need to train the model,now with my deep cnn zca whitening and data augmentation implemented with keras i still can't achieve the baseline if i just use a simple cnn my accuracy would be around which is also below the claimed baseline any suggestions on what might be the problem we ran like iterations is it not enough thank you,public,hw9
data augmentation,hey currently i have an accuracy of when i add data augmentation and zca whitening i'm getting an accuracy of did anyone else face this problem if so can you give me some insight as to how i must proceed thanks in advance,public,hw9
how to determine what k should be,hi i'm starting to do the matrix factorization method and i currently have r the sparse matrix with the rows as the users and the columns as the movies i'm wondering how to divide this matrix into the two matrices u and v specifically what k should be and given k what the entries should be within each matrix,public,hw9
rs k value of latent factor matrix,can anyone give some hints about how to find k value of latent factor matrix do i just randomly select an interval of k and run algorithm to compare which one give me lowest rmse of validation set thanks,public,hw9
rs als number of iterations,hi i know that als converges faster than sgd but what would be a good approx number of epochs iterations the als algo should run for thanks,public,hw9
is it possible that the validation rmse keep on increasing while the train rmse decreasing,i attended today's ta session for rs and implement als based on the ta session but now i am facing that the validation rmse just keep on increasing each iteration although the train rmse is decreasing,public,hw9
what's the difference between using a validation set and adding number of iteration,from my perspective both methods aim to increase the accuracy and cross validation is just iterating over the training set for multiple times in one epoch so what's the purpose of using a validation set,public,hw9
are the team members need to submit a single report for hw,are the team members need to submit a single report for hw,public,hw9
build on found code,for this particular homework if we found code that implements part of the assignment for example preprocessing of the data would we be able to edit and build on the code to complete the task as long as we cite our sources,public,hw9
install tensorflow io error in aws,when i try to use aws and install tensorflow on it the following error occurs ioerror errno no usable temporary directory found in ' tmp' ' var tmp' ' usr tmp' ' home ubuntu' i googled the error and i don't really understand the solution and it may be due to insufficient space but i literally only have the data and the code in aws and maybe the packages i need installed and none of the solutions to solve this that i found online make sense to me aka i don't understand the code and where to put it run it help pls edit resolved,public,hw9
hw cv keras running out of memory,i have a convnet built using keras theano that seems to be correctly classifying most images to improve the classification i tried changing features of the neural network but i would also like to add more epochs to the convnet training phase the problem is that the memory usage increases after every epoch the convnet is trained on and it runs out of all gb of memory after about epochs has anyone run into the same keras memory issue or does anyone know a workaround fix to prevent keras from using so much memory,public,hw9
feature engineering,can anyone define and give an example of feature engineering in our gradescope writeup should tuning hyperparameters be mentioned in the model implemented section thank you,public,hw9
als is not working,after first initialization the rmse never change or even increase after iterations but according to what we learnt the als is guaranteed to converge to local minimum did anyone also facing this issue do anyone has any idea about how to constrain non negative using als do anyone reach or below i used als nmf i wrote all of them and also build in function none of them can stably even reach just wondering is there any suggestions,public,hw9
reinforcement learning lecture,in the slides of the reinforcement learning lecture it seems that current v pi s q pi s a needs to be calculated based on future v and q which is v pi s' q pi s' a' my question is how this can be done if we need future information to calculate the present value,public,other
nlp need help with word vec,i am struggling to understand how to apply word vec and use the vector representations can someone assist with installing and using word vec or even glove for our data set in python i converted the data set into the desired format i e each sentence is an element in a list but i get the following error traceback most recent call last file line in file c anaconda lib site packages gensim py win amd egg gensim models word vec py line in init self build vocab sentences trim rule trim rule file c anaconda lib site packages gensim py win amd egg gensim models word vec py line in build vocab self scan vocab sentences progress per progress per trim rule trim rule initial survey file c anaconda lib site packages gensim py win amd egg gensim models word vec py line in scan vocab vocab word typeerror unhashable type 'list' thanks,public,hw9
rs loss decreasing but nothing happens to rmse,hi we are trying out russ's probabilistic matrix factorization approach now our loss function is definitely reducing steadily but the rmse doesn't budge at all what can we do any comments train loss train rmse validset loss validset rmse train loss train rmse validset loss validset rmse train loss train rmse validset loss validset rmse train loss train rmse validset loss validset rmse train loss train rmse validset loss validset rmse,public,hw9
rs movies that appear in the testing dataset but not in the training dataset,when i tried to create the output file for autolab there appeared to be movie ids that existed in the testing dataset but not in the training dataset what should we do about these predictions these are the movie ids that i found were in the testing dataset but not in the training dataset,public,hw9
gradescope submit,in the write up for submitting on gradescope we are given the instruction as in autolab click group options under options and in gradescope see https youtu be alesbkel zk t s for a demonstration of how to submit as a group however in the video link there is an assignment option where we could choose to create a group while we do not find the option in our current gradescope dashboard any other encountering the same problem,public,hw9
cv matlab incorrect labels on test data,i could be missing something big here i am parsing the data from the train and test set the exact same way yet visualizing the test data shows images that are not reflected by the labels in results csv is there something different about how the test data is processed is results csv not labeled data but just a sample output of the format our data should be in,public,hw9
grades and solution for the previous homeworks,when would we tentatively get the final scores of hw and can we get the solutions of all the homeworks before the final exam,public,hw6 hw7 hw8 exam
setting partners for gradescope,how do we set partners for gradescope,public,hw9
any suggestion on rs using als,i am working on rs using als now but now matter how i change the rank and max iteration the rmse quickly converge to or some value near here i am not sure what's wrong with the implementation is anyone can give some suggestion on this,public,hw9
change to brynn's office hours,hi all unfortunately i will not be able to hold office hours this week but wei has offered to cover them in my place they are still scheduled from but will be held in the th floor lounge outside warm regards brynn,public,logistics
rs how to create validation set,hi how can we create the validation set in matrix factorization thanks,public,hw9
rs non negative constraint,is non negative constraint making u and v have only non negative entries do we just change all negative entries of u and v to after computing u and v thank you,public,hw9
hw report template,hi is hw report template provided thanks,public,hw9
extra office hour for recommendation system am,due to high volume of questions for recommendation system task i will hold an extra office hour for recommendation system on tuesday am am ghc simon du,public,logistics hw9
final exam scope,hi all i've had a few questions about whether this week's material will be covered on the exam everything up to and including today's lecture is fair game for the final exam wednesday's lecture will be a review warm regards course staff,public,exam
how to prepare the final exam,as title,public,exam
question about due date of hw,hi sir i have checked the due date of pdf and found it's but the due date on the autolab is which one is the real due date,public,hw9
rmse for training and testing in recommender system,i used svd and the rmse for training dataset can be but the rmse for testing dataset is more than could anyone tell me why the rmse for testing dataset is such large,public,hw9
using simple regression for reco system,why don't we use simple linear regression for reco system here we can prepare the train and test dataset using the given rating matrix train set would be known ratingstest set would be unknown ratingsfeature would be the user and movie attributeseg age occupation sex genre ratings i think this approach would work i just want to know what are the disadvantages of using this over matrix factorization thanks,public,hw9
rs what is the intuitive meaning of constraints like non negativity,does constraints like non negativity means the latent matrix should contains all positive values why we need to do this what is the intuitive meaning of being all positive semi positive or else,public,hw9
hw write up page limit,for hw report we slightly exceeded the page limit into rd page due to graphs is it fine or should we stick to pages hard limit,public,hw9
will there be different review lectures for different section,will there be different review lectures for different section if no what timeslot sectiona or sectionb should the review lecture be held,public,exam logistics
gradescope exceeding pages,hi i tried to describe my work and the work flow in the pdf and i found if i want to have the work described in detail the pages limit will be easily exceeded do i have to follow the pages limit mandatory,public,hw9
rs als on whole matrix,when we use als for each iteration i'm updating u by updating each row of u and i'm updating v by updating each column of v because we can only rely on the observed i j in z each iteration takes a lot of time do i have to update u and v by updating the whole matrix u at once and updating the whole matrix v at once,public,hw9
matt's office hours last week thu,hi all if you tried to attend my office hours last week you would have found that i wasn't there i'm terribly sorry i wasn't able to provide advance notice of my absence from campus that day if you were one of the unlucky few who were waiting for me you have my utmost apologies i hope you were able to make one of our ta office hours instead see you on monday cheers matt,public,logistics
rs sgd,when performing sgd for rs should we pick our matrix indexes randomly to perform the updates or should we step through each index like we did in every sgd hw,public,hw9
how long does it take to train the data set for cifar,could someone please let me know if you're using keras approximately how many epochs and batches are you using to train the data and how long it takes and what accuracy you are achieving,public,hw9
cifar cnn accuracy low,i built a cnn with total layers with preprocessing of the data and dropout among other things similar to my training and validation accuracy are low stuck at around this is clearly not a simple convnet in the writeup a simple convnet is supposed to get how were these baseline accuracies obtained they seem greatly exaggerated so far i've compared upwards of different architectures tuning different parameters for whitening parameter initialization etc yet i'm not getting the results one should expect to see are there any resources you can point us to or recommendations for which hyperparameters are most meaningful i understand the purposes of this assignment is to discover this for ourselves but even so the benchmarks in place seem too high given a one week assignment thank you so much,public,hw9
no permission to download software onto cluster machine,i was trying to install tensor flow on machines in the wean hall cluster and i faced several issues on mac as well as pc is it that we are not allowed to modify those systems or did i miss a crucial step like creating a new python environment or using a docker,public,hw9
rs solve als faster,for rs i am using als i computed the update formula and made my function operate that formula for each update that includes matrix inverse and doing matrix multiplication each iteration takes too long time is there some other faster way of solving the least square other than computing the formula and actually do the matrix operations,public,hw9
non negative constraint,in recommender system what's the advantage of non negative constraint,public,hw9
bug in the comparetwo code,i'm doing the nlp task and i tried to use the comparetwo code but it keeps telling me index out of bound i was wondering if there's a bug in the code for the predicted label and test label files how exactly am i supposed to write them in the csv,public,hw9
slved,solved,public,hw9
rs sgd tuning learning parameter,hi if i'm using sgd for the matrix factorization method in reco systems what is an approximate value of the learning parameter or do we need to tune this parameter as well if so what is a min and max range of the values we need to consider any pointers towards this would be highly appreciated thanks,public,hw9
questions about the cv dataset cifar,in this homework we are giving a small part of cifar dataset is the test set of our dataset comes from the test set of the original cifar dataset or it comes from the training set of the original cifar dataset the case is that i use the original cifar training dataset to train my model i hope given more images the model could learn high quality features then i use this model to predict the class of the hw 's test dataset then only thing i need to do is to change the class to the class which is suitable to our dataset let's say the vehicle is in the original dataset i only need to change the class to so that it would be compatible to our test set it seems that i am getting accuracy i have not submitted the final result yet i am pretty sure that i only use the training dataset of cifar classes to train my model the only thing that comes to my mind is that the test set of this homework maybe a subset of the original cifar training dataset is that possible for ta or professor or anyone to answer my question please thanks,public,hw9
weird predictions with keras zca whitening cv,i am using keras to build my cv model but the problem is whenever i use zca whitening i get weird predictions for example it will only predict either or classes not all the training accuracy was and if i remove it then i get sensible predictions but on the test data i only got an accuracy of and according to the scoring rubric i need at least accuracy what are my options here,public,hw9
rs negative values for latent factors,hi if i am getting negative values in my latent factor matrices for user and movies how should i deal with them shall i make them or thanks,public,hw9
aws credit codes,how do we put in the aws credit codes as in where exactly is the option,public,hw9
rs non negative matrix factorization what could cause the error to exponentially increase,i read the paper regarding non negative matrix factorization more times than i am proud to admit however i think that at the end is a simple change with respect to the original algorithm the only change that i'm making based on the following two equations is changing my update alpha according to equation number and now my alpha is alpha frac u i u i t cdot u i cdot v j however when i do that my error rate start increasing exponentially instead of decreasing is my approach incorrect is there any other thing which i should take into account,public,hw9
rs using als,i used the als and each iteration is really slow for every iteration i update each row of u that corresponds to each user where i fix the columns of v the items which the user's ratings are observed also i update each column of v that corresponds to each item where i fix the rows of u the users whose ratings on that item are observed am i missing something thank you,public,hw9
cv applying zca whitening using keras,hi i am using keras's imagedatagenerator to apply zca whitening on the input image batches codes as following datagen imagedatagenerator zca whitening true datagen fit xtrain it gives me following error would anyone help me with this problem thanks,public,hw9
rs matrix factorization initialization of u and v before sgd,how should u and v be initialized before running sgd,public,hw9
rs als vector,when using als for updating user matrix we need the vector of all the ratings on every item from the particular user how should we do this if we have missing entries for the vector,public,hw9
rs how can i go about using user attributes and movie attributes,how do i incorporate user attributes and movie attributes in my matrix factorization,public,hw9
how to run keras on gpu failure and successful experience included share welcomed,hi all i keep trying to run keras on gpu and i failed multiple times here i want to share with you my failure experience and the walkaround to achieve my goal to begin we can run keras with tensorflow backend on gpu if any available gpu is detected failure i try to install all related dependencies on aws gpu machine that's torturing i follow the guide here http ramhiser com installing tensorflow on an aws ec instance with gpu support and find it's time consuming and it will cause version conflict in short build environment from scratch is not recommended if you don't have prior experience don't do that failure tensorflow recommends using its official docker image perfect docker guide https www digitalocean com community tutorials how to install and use docker on ubuntu wow that's awesome so i follow the guide here https github com floydhub dl docker what is docker and here https gist github com wangruohui df f dc d f d d aa d and find the only setup is to install nvidia driver on my aws machine but that finally requires me turn off the secure boot of the machine which is impossible at least for now i cannot figure out how to do this on cloud machine but on your own linux machine it's easy to do that failure my friend recommends using already setup aws machine where i can buy from aws ami marketplace by simply search deep learning ami and all necessary libraries tensorflow theano caffe mxnet and of course nvidia stuff etc are installed on the machine created from that ami it looks good isn't it but aws starts to limit gpu instances that i can launch which is annoying it tells me the upper limit of gpu instance i can launch is excuse me so i send message to customer support and they don't response yet wow this is a good way to do and i will try it later if i get higher limit success using floyd search floyd deep learning and you will find it https www floydhub com really handy the only thing you need to do is to install its cli and then you can run keras on floyd's gpu with one line command only thing to keep in mind is that it supports only keras and tensorflow now so remember to modify your code if you use keras and tensorflow it makes each epoch of training x faster than my own laptop with cpu and even aws cxx machine with cpu huge improvement so that we can try a lot more models cheers any other easy way to set up deep learning environment is welcomed let's discuss about that so our life can be easier edit apr i have figured out the way to run keras with gpu cat keras floyd requirements txt then use command for example floyd run gpu env tensorflow py python cifar cnn py evan,public,hw9
csv file too large,i have an output csv file which is mb and autolab does not allow me to upload it so i'm wondering whether i am doing anything wrong and if there's anyway to fix this problem thanks,public,hw9
rs convergence criterion time,hi i am training the non validation set what is a convergence criterion for updates for rs also is this process supposed to take very long thank you,public,hw9
rmse omega,what is omega test it says omega denotes the indices of test ratings but i don't understand what omega test is normal rmse calculations usually just take the square root of the mean of r ij r ij,public,hw9
clerical mistakes in matrix factorization,hi the image is from page of whiteboard on matrix factorization should it be u i v j t instead of u i t v j thx edit does it because all vectors are actually column vectors maybe that's why matt write so,public,other
autolab down,hello my partner and i tried posting our answers to autolab and we are not getting a response is autolab down thanks michael,public,hw9
rs best way to preprocess data,hi what is the best way to handle rows with missing rows is removing the rows the best option or is there a better way to handle it,public,hw9
rs approximation error,hw rs when checking if convergence is reached using approximation error mse of residual matrix only the observed entries what's a reasonable criterion value of mse to use thank you,public,hw9
what's the coverage of the final exam,hi will the final exam cover all the lecture of this semester or just those after the midterm thanks,public,exam
lecture matrix factorization case and case,hi all can anyone tell me what does low rank factorization case and case here want to do for case i have convinced myself that for a matrix r rank r k then there exists u and v with rank u rank v k that r uv' but when in case rank r k matt said r uv' my question in case why do we need to specify that k min m n i prove that for any k min m n there exists u and v that r uv' proof can be found here wiki rank factorization in its example rank a rank c rank f and a cf in case r uv what are u and v here how do we get these u and v also if we know what u and v are why r uv please clarify thanks evan,public,other
words in dataset not in corpus data,i'm doing the nlp task and i'm trying to find vector representations of the words i realize that some of the words in the dataset do not exist in the corpus some of these words are really strange words that i've never seen before so i can't find a synonym so what should i do for these words how should i use vectors to represent them thanks,public,hw9
missing entry in matrix,i am trying to convert the dat file loaded as np column array into a matrix where each row is the user and each column is the movie after preprocessing if we deleted a user's rating on a movie should i use as the corresponding entry in my matrix,public,hw9
video,when will the video of information theory be uploaded,public,logistics videos
rs after preprocessing,for rs the writeup says you need to do some pre processing to ignore them we recommend first try to use movie user mean prediction to see if you have processed data correctly is this saying that we are recommended to after doing preprocessing use movie user mean prediction and submit it to autolab to see if the results is reasonable thank you,public,hw9
how to view hw feedback,how can i view the feedback that the peer reviewers gave to my hw submission i don't find a way to do it on easychair,public,hw5 hw9
loading training dataset,how should we load the dat training dataset file into python thank you,public,hw9
matrix factorization method,for recommender systems do we have to do nmf for matrix factorization or can we decide to use other approaches such as probabilistic matrix factorization,public,hw9
best student written summaries of hw papers,i chose recommender systems for hw but i'm thinking about switching to nlp for hw one of the summaries i reviewed was excellent for recommender systems and if there were others that are very good they could help students in hw who decide to switch to check their understanding maybe the instructors could post a few of the highly reviewed student summaries done in hw edit also even if the instructors don't post them they are busy as well if your own summary was highly reviewed feel free to post it,public,hw9
matrix factorization rs,can we achieve rsme with gradient descent for matrix factorization or do we need to use some other technique for convergence we tried using als also but with that we get even higher,public,hw9
aws credits,when will the aws credits requested in the second round get handed out,public,hw9 logistics
autolab group submissions,if someone is working in a group do they get permitted submissions because both team members can get submissions each,public,hw9
rs uploading the results,hi how r we supposed to upload the results csv file i uploaded a file but it gave me saying that it didnt detect a tar file thanks,public,hw9
regularization question,i have a question about regularization lecture in this slide it's telling us the result for different numbers of parameters but isn't the number of parameters i e number of dimensions determined by the input overrightarrow x of the training data i e don't we not have a choice of the number of parameters or is it that we're simply setting the unused parameters to and the model contains all the parameters thank you,public,other
mf for netflix problem,in lecture we looked at an example of matrix factorization used on movies can someone tell me what the numbers in each matrix r u and v indicate also what is our ultimate goal in the movie context thank you,public,other
group submission,for homework if i'm working in a group of do i submit as a group too i e my teammate and i together make a single submission in gradescope and also a single submission in autolab thank you,public,hw9
rs data pre processing,according to the write up i should be getting a rmse value by simply using the mean of all ratings however i keep getting rmse and when using movie user mean prediction is even worse should i be using the testing dat and results csv data to check the rmse apart from removing invalid rows is there any other step before calculating the average i should be doing,public,hw9
rs rating prediction,hi when predicting the rating given a pair of user id and movie id should we round up or round down the result to the next integer since all ratings in the training file take values and thanks,public,hw9
question about recitation at,hi sir i have a class every thursday at pm so i can't join the recitation of mock exam will you provide an online video version for people who can't join the recitation,public,exam
what would be covered in today's recitation nlp cv rs or general,what would be covered in today's recitation nlp cv rs or general,public,hw9
how many autolab submissions do we have,see title,public,hw9
mock final room assignment,hi all following up from my previous post we now have the room assignment for the mock final which is taking place on thursday may th in place of your usual recitation group a should go to ph groups b and c should go to dh as mentioned we will not be holding the mock final at any other time for more details see our previous announcement warm regards course staff,public,exam logistics
hw cleaning rs data,the hw pdf says that the training rating dat has some missing data and that we should remove rows where one of the three elements are missing do we need to clean the other three dat files the grouplens link mentions movies are mostly entered by hand so errors and inconsistencies may exist as well as some movieids do not correspond to a movie due to accidental duplicate entries and or test entries,public,hw9
cv huge gap between validation accuracy and test accuracy,hi all i am wondering whether is it possible to have validation accuracy while get only in test data on autolab as i randomly split train data to train and validation with ratio i think validation can be somewhat a fair generalization of unobserved data however i find the gap pretty huge which is unconvincing can anyone give me some hints on how to do with it thank you so much evan,public,hw9
hw reusing code from past homeworks,can we reuse code from past homeworks in homework specifically there are some functions in homework that would be useful,public,hw9
programming approach,i am aware we have never done this in the homework but is it common in ml algorithms to use an object oriented approach i have seen a few examples on github that do this do you recommend it for our homework if we know how to do so,public,hw9
recommendation system hw,do we need to use movies dat and users dat for solving recommendation system problem or data in training rating dat should be sufficient movies dat movie id genres users dat user id sex age group occupation training rating dat user id movie id rating,public,hw9
moving friday office hours,hi all i need to move my office hours this week to friday at pm best ye yuan,public,logistics
how to use rgb images as cnn input,hello unlike in hw where we dealt with greyscale images in hw we have r g and b channels as the cnn input how should we prepare the data for the first layer my gut says just to input a d matrix for cifar that would be by by and letting the convolution layer reduce it to a d image but is this a good approach what do most modern systems do,public,hw9
computer vision part of hw,hi for computer vision task of homework please consider the following as homework course policies you are not allowed to use any pre trained neural network weights for solving the task you are only allowed to use standard examples of neural networks from tensorflow keras caffe torch from the original documentation repository you are not allowed to use other private public github repository codes for the task if you choose to use one of the standard neural network examples from these frameworks you have to try different modifications of the network identify and analyze the impact of adding modifying deleting certain layers tuning hyper parameters etc and report the results in the write up using the model and the parameters as is and submitting only those results will not fetch full points if you choose to use one of the standard neural network examples from these frameworks you have to cite the code repository in the write up indicating how you used the code any public code used without citation in the write up will be considered plagiarism kind regards course staff,public,hw9
harsha's office hours cancelled,hi all i will not be able to hold my office hours this friday,public,other logistics
data format provided for rs,hi in hw write up it mentions that the data format for rs is however in the url the data format is a little bit different users dat userid gender age occupation zip code movies dat movieid title genres just to make sure that we need to assume the format is as the one in write up right thanks,public,hw9
nlp bus error in glove,my homework is nlp and i'm in the process of word vectorization i tried to use glove developed by stanford but the code they give keeps giving bus error vocab count coocur and shuffle works fine for me but when i run glove it gives build glove input file cooccurrence shuf bin vocab file vocab txt save file vectors gradsq file gradsq verbose vector size threads alpha x max eta binary model training modelread lines initializing parameters done vector size vocab size x max alpha bus error glove input file cooccurrence shuf bin vocab file vocab txt save file have you anyone encountered this problem and what should i do to vectorize,public,hw9
guide on installation of python tensorflow and keras with gpu support on aws machine,http expressionflow com installing tensorflow on an aws ec p gpu instance it's a wonderful guidance evan,public,hw9
moving friday office hours,hi all i need to move my office hours this week to friday at pm they will still be held in ghc,public,logistics
typo in rs data,in training rating data line seems to have the user id missing i assume that this is a typo but is it that we have to account for this,public,hw9
how deep should we go into reinforcement learning,i still got confused by some part of reinforcement learning and i found some useful courses in udacity about reinforcement learning and i am planning to take them during summer break but the problem is that how deep should we go into it as far as now should i finish them before the final exam,public,videos
lecture on wed,will the next lecture be a continuation of reinforcement learning or will we be covering pac learning instead prof barnabas poczos mentioned that he would continue next week,public,logistics
aws credits,can we use the aws credits for creating an instance on ec or can we use them only for specific things,public,hw9
cv how to read data bin data batch bin,hi i have trouble reading binary data into python i use unpickle function given here http www cs toronto edu kriz cifar html but it fails to read the data with errors cpickle unpicklingerror invalid load key ' ' can anyone give me some hints on how to read the data thank you evan,public,hw9
true rating from training rating results csv for computing rmse recommendation sys,for recommendation systems are we supposed to use the rating in training rating dat or the one at the corresponding index in results csv as the true rating when computing rmse also when computing the rmse based on average of all movie ratings i assume this is the sum of all movie ratings in training rating dat nonzero ratings and not the average of ratings in results csv,public,hw9
csv file provided for rs,is the results csv file provided for rs using rating mean prediction,public,hw9
how to test our code,how can autolab know how well we do i guess it only depends on the results csv file right so it doesn't matter that how we organize our code under code directory right thanks for clarify evan,public,hw9
python version,is it necessary to use python for hw,public,hw9
cnn model,can we use transfer learning instead of building the complete model on our own,public,hw9
cnn accuracy,i built a really deep cnn layers i also did data augmentation and included dropout to prevent overfitting i tried different optimizers sgd adam rmsprop in keras i tried tuning the parameters also but still i am getting a train accuracy of any suggestions on how to improve the model,public,hw9
hw rs,for matrix factorization you can try classical approach taught in class or adding non negative constraints what approach are they referencing in the writeup,public,hw9
recommendation system question about checking movie user mean prediction preprocessing,the writeup says you need to do some pre processing to ignore them we recommend first try to use movie user mean prediction to see if you have processed data correctly we recommend first try to use movie user mean prediction to see if you have processed data correctly do you mean implementing movie user mean prediction and then submit to autolab to see whether we get score to verify the preprocessing correctness if so why should we ignore them what is rating mean prediction and movie user mean prediction exactly for i don't remember the matrix factorization paper mentions these two thanks a lot,public,hw9
where is section,where is section,public,hw9
change in time for sarah's oh,hi all sorry for the short notice but i am changing my office hour today tuesday to this change is also reflected in the google calendar thanks sarah,public,logistics
reinforcement learning deterministic actions,in the reinforcement learning diagrams from lecture below for state value and action value functions it is possible to take one of a set of actions given your current state however after taking this action it then seems possible to be in any number of states intuitively i don't understand why taking an action doesn't deterministically result in a specific state in other words why is a single action capable of producing multiple states for example if i'm playing chess and i decide to move a pawn forward the board can only have one state after i take this action why then do these diagrams suggest that it is possible to have multiple states after taking an action if chess isn't a good example to explain this can you provide an example that does thanks,public,other
slight change in abhinav's oh,abhinav's office hours from am today,public,logistics
hw submission error,hi all i noticed a few students accidentally submitted homework to the homework gradescope assignment i have noted who these students are if this applies to you please resubmit your homework to the correct assignment as soon as possible i will confirm that you have not edited it from what you had previously submitted on time in the wrong place and consider it on time as long as we receive it today april thanks sarah,public,hw8
not allowed to use external library for recommendation system,hi are we not allowed to use this library https piazza com class ixs v xr cz d cid thanks,public,hw9
is it possible to extend the hw due,some of us will have an final exam on may th also another project count as final exam due may th and i just saw the due day for hw is may rd so is it possible to change the due time i mean it is very hard for us to handle everything in just week from now on,public,hw9
any hw write ups,soooo where can i find the hw,public,hw9
d separate inconsistent result from two methods,hello when solving the problem deciding whether a variable is d separate from other variable when using the two methods using definition blocked' and definition 'undirected graph for example if i want to find out which variable is d deparate from h given c using definition i will find that every variable has a path to h so none is d separate but using definition if i try every variable separately say first i remove g which is not an ancestor and draw the graph i will find that t o e is d separate from h so which is right thanks,public,hw8
explicit inference,how do we do explicit inference this time since c is in the given for some of the terms for example in the hw recitation we were able to simplify it because it was not the case for w i can't just pull certain terms out of the marginalizing summation since they are conditioned on c too thanks,public,hw8
hw recitation,for hw recitation p h is cancelled out but why isn't p i w h cancelled out it's the exact same for each is this just a typo,public,hw8
forward backward hmm,would the forward and backward algorithm give exactly the same probability also if i am understanding correctly to calculate p o o o using the backward algorithm we will need to know but the whiteboard notes says that t starts from t and goes back to instead of is there something that i am missing,public,hw8
gibbs sampling how do i go about finding conditional distribution from joint distribution,how do i go about finding conditional distribution from joint distribution of the bayes net if i do something like marginalizing over other variables i will end up with a number and not a distribution what am i missing here how do i approach this,public,hw8
question,do we assume that state matrix are time invariant,public,hw8
office hours,is the office hours going on right now and is the th floor kitchen the kitchnette,public,logistics
factorized form w common ancestor,if two nodes on a graph should you write the common ancestor once or multiple times i e in this toy example would the factorized form be p d a b p a c p c p b c p c or p d a b p a c p b c p c in the top p c is multiplied in twice but on the bottom it's only done once,public,hw8
hw gradescope grades released,hi all we have released the hw gradescope grades here is how we graded the answers q you should have submitted an image which looks something along the lines of these layer layer obviously it didn't have to look exactly like this we had a variety of different colours and funny shapes submitted the main point is you should be able to answer a b and c with them as follows q so there were quite a few students asking what the difference between a and c and b and c as such there was a lot of over lap between answers so i decided to just combine a c and b c where if you answered the following ways i gave you the marks for a c basically we wanted you to identify how you could still see the original image however the convolution seems to have exaggerated certain 'features' of the digit and almost all of them are a little different the filters are trying to capture edges of the image for b c we wanted you to identify that the only difference max pooling does is blur pixelate lower the resolution of each of the convolutions notice how our of layer in the images above is just a more pixelated version of of our layer for the images to be given marks they must have been able to show these results q we gave marks to anyone who received over most people were able to hit around which is the ideal area we wanted you in any less than this we did not reward you marks thanks course staff,public,hw7
j,how do we get this last one where there are multiple ones shown as independent to each other conditionally given some set thanks,public,hw8
gibbs sampling,can someone give me basic idea of how to approach gibbs sampling thanks,public,hw8
number of parameters,on slide of the recitation ppt i see the number of params are for p g for p w for p ph g for p h g ph for p i w h which sum up to should it not be the following instead for p g for p w for p ph g for p h g ph for p i w h summing upto be,public,hw8
computer vision of hw,i am now trying to build a convolutional neural network for the hw computer vision project can i use the existing cnn module like keras for this course project or i have to build the whole network like what we did on hw on my own,public,hw9
brute force sampling,for variables without condition for example t t we just assign sample from to as t from to as t what about variables with conditions like g e h should we sample e and h and get their values like e and h and check the cpt do the same thing to sampling of g thanks a lot,public,hw8
penalty late days on autolab gradebook,on autolab gradebook for hw and hw it shows that i used penalty late day but i did not submit late could you please check why it appears as instead of,public,logistics
how to do sampling in python,can someone tell me some idea on how to do sampling in pyhton based on cpt i dont understand how to implement in python this is in reference to inference questions,public,hw8
estimates from sampling,for the brute force sampling i tried several experiments and my estimates oscillate between or away from my calculated estimate in am i doing it right should the estimate be very close all the time or is this variation okay thanks,public,hw8
parameters,in slide of http www cs cmu edu mgormley courses s slides lecture bayesnet pdf do we know that the number of minimum parameters is because each one is binary for example if the value its theta and otherwise it's theta so we only need one for it there are one for each node in the graph thanks,public,other
late submission,what is the grading scheme for late submissions in hw,public,hw8
q and deliverables,do we have to submit a single plot for both the questions,public,hw8
q,can anyone tell me how to calculate a since here we have a and matt said in class that a start a k for all k start and for the step in our homework t so what does at end mean here should we calculate a,public,hw8
why do we need the marginals,the marginals are calculated as p y t k x frac alpha t beta t p x but if the the each observation is only dependent on the current state emission and the previous state transition why would we need to condition on the entire vector of observations for x in other words why can't we just compute p y t k x t x t,public,hw8
hw problem model or chain,shouldn't the text of problem use markov chain instead of markov model when it talks about the model unfolded in a sequence of observations,public,hw8
hw recitation date,in the course schedule it says homework will be released tomorrow april th monday and it's due may rd wednesday in the recitation schedule it says the recitation on homework will be on april th thursday would it be possible to change the recitation date to april th tuesday so that we can have more time to work on the homework after the recitation thank you,public,hw9
q end state,in the question we were asked to derive p x from the alphas but if we don't know about the end state how can we do that,public,hw8
factorized form,is it fair to say that factorized form of the joint distribution has multiple different forms depending on the ordering of factorizing for example for question like p a b c where bn is like a b c is it fair to say all three below are correct factorized form p a b c p a b c p b c p c p a b p b c p c or p a b c p b a c p c a p a p b a c p c a p a or p a b c p c a b p a b p b p c b p c p a,public,hw8
lec slide,pfa image highlighted in red shouldn't it be y t,public,videos hw8
confusion in definitions of d separation p of lecture,i am confused about definitions of d separation as they seem to sometime give me different results for example if we look at the case like below where a and b are common parents of c which is not given in the definition it seems they are d separated as only path from a to b is through c and that one is closed as it falls under the category of v structure however if i do the definition where undirected ancestral moral graph with e removed they seems to give me a result of not being d separated could someone explain how this is happening,public,hw8 videos
q,it is given if harry s professor is not evil harry is more likely to spend his time in the library studying does this mean we have to condition harry's studying in library l directly on professor being evil p which means l will be conditioned on i h and p is my understanding correct,public,hw8
bn diagram when types of structure co exist,lets say we had a diagram like below where both v shape and cascade structure is co existing between a and b i feel like when something is dependent and independent at the same time it is independent so here is it fair to say that they are dependent,public,videos hw8
code for calculating f with two files,this code will concatenate a csv file of correctly labeled data from the conll dataset with a csv of predicted labels for that data and run the perl script for calculating f score found at http www cnts ua ac be conll chunking conlleval txt which should be saved in the same directory as conllscript pl comparetwo py,public,hw9
question about,i'm really confused about the question now since we are not given a starting state or end state do we assume s is the starting state or is there a hidden starting state s which we should assume to be i'm guessing since we are given the initial probabilities there is a hidden s but if this is the case the transition probabilities from s to s would be different from the rest of the transition of states because in the homework s has initial probabilities and which are different form the transition probabilities should we always assume that alpha k forall k,public,hw8
recitation bayes net example,in the bayes net example at the end he was left with the following equation questions why he did not factor p i w h f and cancel that out did we do all that just to get that nothing else matters and the answer is simply the probability of p w,public,hw8
lec time series slide,can someone explain how the values etc came i understood the previous part but not how these values came how do we get values for each of o s s o c it says mixture model so does it mean gmm,public,videos hw8
relation between markov blanket and d separation test algorithm,hi all as far as i know we can use both markov blanket and d separation test algorithm to verify a conditionally independence relation my question is is there any relation between the two algorithm e g are they equivalent or not thx evan,public,hw8
hmm forward and backward algorithm giving same result,so theoretically both the forward algorithm and the backward algorithm should give the same probability am i right,public,hw8
relation between forward backward algorithm fba and viterbi algorithm va,hi all i want to ensure i have a correct understanding of the relation between the two algorithms please correct me if i am wrong fba is a family of algorithms that includes forward step and backward step even the number of soldier algorithm can be refered as a fba vb is a form of fba as it also includes f step and b step page of lecture 's slide shows a special fba instance where it defines alpha and beta as such so that it addresses the problem of finding value with highest marginal probability the fba instance shown in page lecture does not say anything about the most possible assignment of values vb is a fba instance that addresses the problem of finding most probable assignment of values thanks for your patience and time any related materials is appreciated evan,public,hw8
forward backward algorithm,hi all can anyone help me with the final equals formula how do we derive that thx evan,public,hw8
problem c,in problem c professor can be good neutral evil can we assume that both neutral and good are not evil mentioned in the description if so does it mean we still only need one parameter to represent this event,public,hw8
initializing,for step a where i have to initialize t c e and h is setting them equal to good enough or should i randomly sample them as well,public,hw8
q gibbs sampling,hi for the gibbs sampling why would i want to sample t e and h when i know my objective is to find probability of c and that c is independent of all others why cant i just sample c times thanks,public,hw8
can we use code for,in order to evaluate the sums in i wrote some code is this ok or do we have to do it by hand and if we do use code do you want to see our code because this is part of our 'work',public,hw8
is gibbs sampling expected to run faster than brute force,hi all i know this could be an under defined question as code running efficiency is highly dependent on implementation but i still feel surprised when i found my brute force code for runs x faster then my gibbs sampling code with samples they have very similar result after convergence which is also close to the theoretical one so i believe my code is right so i am curious about is gibbs sampling expected to run faster than brute force even though my experiments don't support that thx evan,public,hw8
minimum parameters,i am little confused about the minimum requirement in b since we can make all events always happening then we need zero parameters it seems we have some assumption about the distribution model is it always bernoulli or multinomial are we allowed to merge states when using bernoulli or multinomial,public,hw8
is that possible to relesae hw now,i have lots of projects going to due in next weeks is that possible to release hw now so that i can have time to build the model,public,hw9
d separation ancestor parents or all ancestors,hi all i want to make sure that i understand d separation check algo correctly does ancestor here mean only parents or all ancestors please clarify thanks evan,public,hw8
d separation and conditional independence,hi all i have a confusion concerning d separation according to the d separation algo matt introduce once it's d separated then conditional independence can be guaranteed however what if we cannot tell from the algo that x and z are d separated given y does it mean x and z are not conditionally independent but according to this materials mit in this case it is also possible to have numerical independence it says we can say the variables are dependent as far as the bayes net is concerned or the bayes net does not require the variables to be independent but we cannot guarantee dependency using d separation alone because the variables can still be numerically independent e g if p a b and p a happen to be equal for all values of a and b so what should we do in question should we only consider variables dependence so that if x and z are not d separated given y then we conclude that x and z are not conditionally independent given y thank you evan,public,hw8
q how can we generate random samples from conditional probability,for example how can we generate random samples for p e t c o,public,hw8
backward algorithm corner cases,hi i have some confusions for question where we are noted to generate a b but according to the formula at class if we let t then we should have state t informations to generate however we are not provided with s o data i wonder if we should just use s o as we generate if it is the case when we compute can we also assume there is a state s and use p s s a and p s s b to generate a b respectively thanks,public,hw8
evaluation using beta,according to our lecture notes the problems of hmm were evaluation marginals and decoding in hw problem we're asked to do evaluation using alpha values and in problem we're asked to do evaluation using beta values in lecture notes on forward backward algorithm it says we do evaluation only using alpha values and we do marginals using both alpha and beta values how do we do evaluation using only beta values which is asked to do in problem thank you,public,hw8
hand written version of hw,can we submit the answer in hand written version,public,hw8
gibbs sampling how can i calculate these conditional probabilities,i'm confused about the proper way to calculate these conditional probabilities can somebody confirm if this process is correct let's say i want the distribution for p e i st i take the markov blanket which in this case is the entire network p e i o t i c i h i g i nd not sure i try to obtain the probability of e having one value let's say frac p e i o t i c i h i g i p o t i c i h i g i for the numerator there is not a single cpt table with eotchg can i just multiply the values from two tables which together gather all the necessary variables formally is the following correct p e i o t i c i h i g i p e i o t i c i p e i h i g i for the denominator can i marginalize e by summing over its two possible values getting each of these values doing twice p e i o t i c i h i g i p e i o t i c i h i g i am i overthinking this is this process correct,public,hw8
in gibbs sampling how will e t affect t t,in the notes we sample t according to p t t e t h t c t o o g g b however i think e t has no relevance with t t although e t is relevant to t t the same for h t and c t so the conditional probability here is actually p t t o o g g b,public,hw8
calculating alpha for first y in markov chain,when calculating alpha k we need to know p y k y start but its not specified in the notes how to compute this particular conditional probability is it just p y k,public,hw8
q,i am confused between two methods to generate samples one of the methods would be to calculate p e p g and p h by using marginal probability summation which will be a lot of calculations otherwise we can program it in the following way generate sample for t c o as they dont have any parent based on the results above we can then use the table to generate sample for e then sample for h similarly for g because we have to know e and h before sampling g this will have a lot of if and else in the program as we have to map the whole table in the program is there any other method that i am missing or am i on the right track,public,hw8
plots,just wanted to make sure we submit one single plot that covers problems and right,public,hw8
unscaled alpha parameter,in problem part the problem asks to find the value of unscaled alpha parameters i'm confused by the wording here for example does unscaled alpha a mean p o d s a directly or are we does unscaled refer to anything else,public,hw8
q brute force sampling,hi how are we supposed to take samples for the brute force method should we use random function thanks,public,hw8
d separation question,we usually talk about whether a and b are d separated given c do we always assume that the two variables a and b are different and also do we assume that the the two variables are not contained in the evidence set i e is a and a are d separated given c always false by definition is a and c are d separated given c always false by definition similarly is a and a are conditionally independent given c always false by definition is a and c are conditionally independent given c always false by definition thank you,public,other
problem,for this problem i'm trying to use marginalization over the irrelevant variables but this leads to a very long expansion which would take a long time to calculate am i doing it right or is this the wrong way to do it thanks,public,hw8
running late to my office hours today,i will be there in minutes,public,logistics
d separation and conditional independence,in the lecture it says if x and z are d separated given a set of variables e then x and z and conditionally independent given the set e can we assume that the reverse is also true that is can we say x and z are d separated given a set of variables e iff x and z and conditionally independent given the set e thank you,public,hw8
problem true false,just wanted to make sure for problem true false questions we don't need to provide justifications and we just need to write true false right,public,hw8
ancestral graph,in ancestral graph when we say we keep nodes and their ancestors does this include grand parents grand grand parents etc too so for example if we have a rightarrow b rightarrow c when we say we keep c and its ancestors do we keep all a b and c thank you,public,other
independence,i know these questions are stupid all the techniques presented in class d separation and markov blanket talk about conditional independence it assumes that we have a set of given variable as conditions if we do not know anything about the variables what can we say about independence can i say that when variables are part of the same graph and we did not observe any of the variables they would always be dependent the only case in this graph that we can ensure independence is when we know the values of a set e that ensures the conditional independence is this interpretation correct solved the d separation algorithm provides an answer for all cases if two nodes are d separated given a set e they are independent however if they are not d separated does it mean that they are dependent or it is undetermined thanks,public,hw8
inference for hmms marginals,can anyone explain to me this equation i can't quite understand how to get this one better use the tunnel matt mention on class and the example thanks,public,hw8
how to calculate beta t k in backward algorithm,if we initialize with beta t end and use the equation in step then beta t k displaystyle sum j k p x t y t j cdot beta t j cdot p y t j y t k but we do not know p x t y t j because there is no x t how to calculate beta t k then,public,logistics hw8
problem,in problem do we consider the transacton from start state and end state too although they are not drawn on the graph,public,hw8
ambiguity in question,on the question it says harry is also more likely to spend his time studying in the library if his friend hermione lectures him to do so as harry studies more he is more likely to earn points for his house in here the study more in the sentence as harry studies more he is more likely to earn points for his house refer to the harry studying in lib or harry studying with hermione,public,hw8
brute force vs gibbs sampling,is the only difference between these two methods that in gibbs sampling we automatically discount known variables for example say p a b c p a p b a p c a b where each variable can be one of two states or our goal is to use sampling to approximate the distribution of p a c in brute force sampling we will sample a b and c from their conditional probability tables without assuming c already equals for a total of k iterations then we will count the number of times a given that c out of all the times c this is our final probability the number of times c is not necessarily k in gibbs sampling we will sample a and b from their conditional probability tables since we already know that c for a total of k iterations then we will count the the number of times a out of all k iterations this is our final probability is this correct or am i missing anything thanks,public,hw8
interesting paper on conv nets,just found this recent short paper on conv nets title deep neural networks do not recognize negative images pdf link https arxiv org pdf pdf https arxiv org abs,public,other
not d separated implies what,what happens if two variables are not d separated it looks like this alone does not imply anything thus for problem in hw how can we say false when two nodes are not d separated conditioned on a variable isn't it unknown if the two variables are not d separated but this is not one of the options,public,hw8
bayesian network how to prove that given y x is not conditional independent with z,hi i'm watching the bn lecture and tried to prove this but failed can you provide me with some hint i can only derive the answer by separation can you help me derive it using probability method thanks,public,logistics hw8
q what is a factorized form of the joint distribution,are those factorized forms of the joint distribution,public,hw8
hw dl structure,do we need to implement the hw from scratch can we use dl structure such as caffe tensorflow if we can how are we going to send the code to autolab and be graded,public,hw9
markov blanket theorem,in lecture slide in the theorem a node x is conditionally independent of every other node in the graph given its markov blanket does 'every other node' mean all nodes excluding x or does it mean all nodes excluding x and also excluding the nodes in the markov blanket of x thank you,public,other
aws credit available for homework,hi all we have aws credits available for homework note that it can be only used for this assignment for this course if you think you need request aws credits then one of the team member should create an aws account based on his andrew email and backed by his own credit card write down your digits account id under account settings then using this account using their andrew email account join aws educate https aws amazon com education awseducate he will need to fill in the account id for this don't choose educate starter account leave the promo code field blank last this member need to fill out this google form since we have limited number of resources you need to write a few sentences about why you need this credits in the form by april p m https goo gl forms s yvwwol nhxa g after we get the code which may take one two days we will send the coupon code to your email address and you can redeem it in your aws account and use it also quick notes there will be no tutorial provided for aws services it is your responsibility to figure out how to use that you need to beware of putting your credentials into code that can be seen by others for example there are criminals that search github for publicly visible credentials steal them and run up your credit card bill probably reselling the cycles the student that has this happen to them is responsible for the stolen credential use although they should change the credential report it to course staff and aws quickly and in our experience aws is pretty good about forgiving the costs incurred by such criminal activity good luck hw team,public,hw9
question about derivation of forward algorithm,hi i didn't understand the third step can any one help me,public,logistics
inference in bayesian network,in the lecture we solved the inference problem of beyesian network by monte carlo or gibbs sampling i wonder if we can just explicitly write out the distribution function according to the given conditional probability instead of doing the sampling i think this is not hard in the example of fire alarm,public,logistics
bayesnet continuous,lecture slide here the graph says the mean of c is mu c a b right then shouldn't the mean of d be mu d c instead of what's shown in the graph that the mean of d is mu d c thank you,public,other
number of parameters,this is in lecture whiteboard notes we were discussing ideas on how to express the joint distribution for the tornado example for idea naive bayes is the number of parameters needed thank you,public,other
oh during carnival,will there be oh during thursday and friday this week as normal week,public,logistics
hw tips watch the end of the lecture,hi all i am posting this to remind you that you should watch the end of the hmm's lecture here lecture after the hour matt covered hmm's in more depth in the video than he had time to during the lectures and if you would like to be successful in both hw and the final you would be wise to watch this additional content note this is mandatory content the material covered in the online video is relevant to your assignments and is fair game for the final exam thanks daniel,public,exam hw8
rui's ofiice hours cancelled today,hi all i have to cancel my office hours this week i've updated the calendar sorry for the late notice best rui sun,public,logistics
bn models of lecture,i did not really get how the y being shaded or not effected the proof of first two cases and therefor having a problem in proving case how does the difference of y being shaded or being observed effect the proof i can understand the concept but it feels like the following proofs would also work even when y is not observed,public,videos
cancelling office hours,hi all i have to cancel my office hours this week sorry for the inconvenience best ye yuan,public,logistics
a mistake of emission matrix in lecture ppt,in slide the emission matrix is a and transition matrix is b in slide it is said need to times an extra weight of emission probability highlighted in yellow but in the equation below used b as the emission matrix b pref n i think it should be a pref n right,public,logistics videos
hw part independent parameters or total parameters,given that some probabilities will sum to do we need to provide the number of independent parameters which could in theory be enough to specify a model or the total number of parameters thanks,public,hw8
oh from am am today,i am running a little late from an earlier meeting for the am oh today postponing to start at am please feel free to arrive earlier and work at the location,public,logistics
sgd momentum crashing otl,why is my sgd momentum crashing i'm using param winc and params,public,hw7
sgd momentum,why is my sgd momentum crashing i'm using param winc and edit figured it out thnx for the post on debugging crashing,public,hw7
sgd momentum,im confused as to what we're supposed to do for sgd momentum so the theta in the writeup is param winc so does that mean that equation tells us how to update param winc also equation do we use the output of equation as our derivative for equation for theta also we use equation and to update be just change the derivative to be wrt b and the alpha to be the one for b right,public,hw7
homework has been released,hi all homework is now posted you can find the pdf handout for the homework in the resources tab on piazza the homework is due on april at pm all problems on this homework will be submitted through gradescope see the pdf handout for detailed submission instructions,public,hw8
zlib error error while decompressing invalid code lengths set,traceback most recent call last file c users pedro documents machine learning hw hw handout python testlenet py line in main file c users pedro documents machine learning hw hw handout python testlenet py line in main xtrain ytrain xval yval xtest ytest cnn lenet load mnist fullset file c users pedro documents machine learning hw hw handout python cnn lenet py line in load mnist mnist dataset scipy io loadmat ' mnist all' file c python lib site packages scipy io matlab mio py line in loadmat matfile dict mr get variables variable names file c python lib site packages scipy io matlab mio py line in get variables hdr next position self read var header file c python lib site packages scipy io matlab mio py line in read var header mdtype byte count self matrix reader read full tag file scipy io matlab mio utils pyx line in scipy io matlab mio utils varreader read full tag scipy io matlab mio utils c file scipy io matlab mio utils pyx line in scipy io matlab mio utils varreader cread full tag scipy io matlab mio utils c file scipy io matlab streams pyx line in scipy io matlab streams zlibinputstream read into scipy io matlab streams c file scipy io matlab streams pyx line in scipy io matlab streams zlibinputstream fill buffer scipy io matlab streams c zlib error error while decompressing invalid code lengths set finished in s the template code is not loading the data set any hint,public,hw7
question about homework,if i read paper related to recommendation in hw could i choose do other topic such as computer vision in hw,public,hw9
max pool backward,to those that successfully implemented this function any other pitfalls to avoid additional test case ideas to try so far i've ensured that during backprop input pixel locations that are local maxima for multiple maxpool cells get the sum of its corresponding max cells' gradients for two or more input pixels with a max value tie only one is consistently selected updated with gradients basic test cases operate as expected locally i'm not getting a code crash error in autolab apparently my implementation is simply incorrect,public,hw7
visualization cannot import param,hi i tried import my lenet mat using scipy io loadmat but got the error valueerror unknown mat file type version what does it mean and is there a way to fix this thank you,public,hw7
test dataset,the speed of training does not seems to be different when i am training on fullset and non fullset i am currently changing the th line of the code by changing true to false def load mnist fullset true def load mnist fullset false save and running the training code is there anything else that i have to do in addition,public,hw7
visualization in matlab,after you complete the training you will get your trained parameters in lenet mat for matlab clear everything from the workspace load lenet mat you can double click on it to load it to the workspace initialize the layers but modify layer batch size choose a random image from training testing data i e vector take the corresponding y for that particular example run conv net m conv net output m your images are stored in ouput data and output datareshape them to d arraysuse imshow to show the images,public,hw7
display iteration,i just realized that i set the display iteration in testlenet equal to instead of the default would that be okay if i submit the testing result with displaying cost instead of i don't think there would be enough time for me to retrain the model given the deadline is midnight,public,hw7
ide cannot run scipy io loadmat,i try to load lenet mat file using import scipy io data scipy io loadmat 'lenet' this does not work for me but it works for minst all mat i really have no idea why and i have spend a lot of time on this ide issue is there any other way to load mat file or what is wrong wth lenet mat why it cannot be loaded,public,hw7
output image color,in the feature visualization are the output images supposed to be only black white or should it be colored i realized that whether i normalize the input values into range or into range affect whether the output images are in color or black white thank you,public,hw7
pool backward clarification,hi i am confused as to how to multiply output diff by the gradient i computed made up of s since the dimensions are output diff gradient any direction would be appreciated,public,hw7
debugging code crashes,there could be multiple reasons for code crashing on autolab make sure you are not doing any of the following also people who have resolved this issue can add to this as to what changes they made do not hard code any values in the code number of layers sizes of the outputs inputs etc there are some issue with broadcasting,public,hw7
feature visualization pad stride k,for feature visualization maxpooling layer what values of k pad and stride should we use for convolutional layer i chose pad stride and automatically got the value of k i should use by the formula of h out but in maxpooling layer when i choose pad stride the value of k i get from the formula of h out is too large so i chose pad stride so that the value of k is smaller but the output images of the maxpooling layer don't look like what i expected thank you,public,hw7
visualization,for visualization take a sample data point from xtest load your trained parameters lenet mat and pass your data sample through the network look at conv net output function once you have passed the data you can access the outputs using the output data structure output i data and visualize them,public,hw7
max pooling backward,i have an issue with max pooling backward and the code is doing what i expect thus i guess there must be an issue in my logic which i would like some help with so here it is given the following image h in w in and c the numbers in the first channel are positive and in the second channel are negative after we run max pooling with k and step we would get thus when we run backward we would get a matrix that is everywhere except at the indeces where there was a max i e this would be the resulting matrix assuming dc dy i for all y i is my reasoning correct,public,hw7
feature visualization not possible,hello i made a post and because of this error i'm unable to train my data i went oh today and the ta couldn't figure this out and as per the post several people are running into this same problem even though we have a full on autolab i was wondering if the instructors could allow us to do question under feature visualization without actually having run our code it seems kind of unfair that we would have to lose points for this error thank you edit also in relation i've tried everything in trying to figure out where the nan comes from but no luck,public,hw7
questions about feature visualization part,i have some questions regarding the feature visualization part once we get the output of the convolutional layer each image size by is stored as an np array of size by in what order should this be reshaped to be plotted by matplotlib for example if a by image is stored as np array of size by like this then should we turn it into to plot the image using matplotlib also when i try that way i get images that look weird and are in color are we supposed to get black white images only do we have to somehow normalize the output values thank you,public,hw7
about visualizing the different outputs,for visualization the handout says show images from each layer on a single figure file but there aren't different images coming out of conv or pooling layers rather they are different aspects of a single image so i am confused are we supposed to plot all the outputs of a single input image or outputs of different input images,public,hw7
param grad and param winc in sgd momentum,i asked this question before but i think follow ups are less noticeable than questions so kinda asking again to my understanding param winc stores the thetas and param grad stores the dl dw then by equation for each layer for 'b' shouldn't param winc i 'b' and param grad i 'b' two have the same shape why do they have different shapes for layer even before sgd momentum is called is layer the conv layer or is it a different layer that i messed up on y dosn't it match when it should why dosn't the assertion catch this,public,hw7
params dictionary,in the params dictionary loaded on lenet mat is params for the convolutional layer and params is for the maxpooling layer i'm using python thanks,public,hw7
each input image,is each input image in the mnist dataset of x size and so it has only one channel thank you,public,hw7
sgd,i am really confused about what sgd is doing how is w and b related with theta xb l w w w this only tells us how to update w but i have no idea how to update b where is b stored how to update it is the w in means params 'w' i do not know how to implement equation ans lreg l x i w i lreg wi l wi wi how to get l wi what is wi how is and related with,public,hw7
dimensions of param w and param b for ip layer,where can i find the dimensions of param w and param b since this will help me correctly format the input data for matrix multiplication,public,hw7
autograder giving zero for pooling backward,i have written code for pooling backward and tested that code with small input data i have calculated the results manually and compared it with my code output and both the results are matching but when i uploaded to autolab it is giving me zero can anyone tell me the reason for this,public,hw7
training time,my code has been running for over hours on fullset false but only completed sgd about times i counted it using putting the print something at the end of sgd here i was wondering if i this is too slow and what might be causing this,public,hw7
pooling layer backward code crash,has anyone figured out how to deal with this problem i have run the whole dataset with iterations and obtained an accuracy of yet i still get point on this part and the error message is that the code crashed there is no print command in the code,public,hw7
sgd,for the sgd momentum function we get the numbers of combinations of w and b for the params param winc and param grad what do those numbers indicate,public,hw7
multiple channels,can someone explain how max pool looks like for multiple channels i am really confused and the toy cnn didn't help since its only for channel,public,hw7
visualization,can we visualize a random image from the test set or is it necessary to visualize the exact first image from the test set,public,hw7
sgd reguralisation,do we have to do l regularization for both b and w in the,public,hw7
partial marks in sgd momentum,hi i think i've followed the steps mentioned in the write up to implement sgd momentum correctly however i'm getting only points for this function did anyone else face the same issue any idea what might be wrong here thanks,public,hw7
sgd momentum broadcast issue,hi i am getting the following error when i run my code after updating sgd momentum function operands could not be broadcast together with shapes it occurs in conv layer forward when tmp output col t dot param 'w' param 'b' any idea what might be wrong here,public,hw7
training time iteration,in the homework writeup it says under the smaller dataset it should take less than an hour for a complete implementation to get accuracies is this for training for iterations in another piazza post it says for the visualization we can do the training iteration until accuracy doesn't improve anymore i was wondering if we run the code where the number of iterations is set very large and if we 'quit' the running after we check accuracy doesn't improve anymore are the most recent params still saved in lenet mat thank you,public,hw7
dimension of pooling layer,i got confused by the behavior of autolab about the dimension of the output of pooling layer what we got from im col is a matrix of k k c h out w out what should the dimension looks like after max pooling i mean no matter i just keep the c h out w out and flatten it or keep the h out w out c and flatten it both will pass the test of autolab which one should be the correct one why both can pass will passing autolab indicate we can get full marks of autolab even there is bugs,public,hw7
runtime warning,i am running the code on the full dataset i get runtime warning divide by zero encountered in lognll np sum np log prob y np arange batch size i also get runtimewarning invalid value encountered in subtract activation np max activation axis the lines of code that are giving the error were part of the starter code due to the errors my 'cost' is equal to nan probably due to this my test accuracy is also did anyone else face similar issues,public,hw7
pooling backward,hi i'm not very sure how pooling layer backward works i'm not sure where to find all the variables to solve the gradient equation does anyone know what the values in output diff are or where to find the partial of h over h i or how exactly to calculate the partial of l over w i also does anyone know what input od is for,public,hw7
inner product backward,i still have some questions about this suppose as the testfile input is x w is x b is the gradient for input in image which is first column of input matrix should be the sum of channel which is the sum of columns of w matrix this means for each image column from input the gradients are exactly the same similarly for each channel each column of w matrix the gradient should be sum of columns which means the gradient of each column of w matrix are the same for b matrix how to get its gradient it is all or batch size since each image use it once,public,hw7
viewing error log on autolab python,hi any idea how i can view an exception traceback on autolab there's a method that is working locally but not on autolab and i wanted to print the error being thrown i tried this import sys try except print unexpected error sys exc info but it doesn't print anything thanks,public,hw7
gates machines have all the required python modules,maybe this is too late but you can ssh into one of the gates machines ghc s ghc andrew cmu edu if you can't train on you laptops they have all the required python modules,public,hw7 logistics
usage of im col,hi can we use the method 'im col conv' in any of our function definitions or does that result in a crash,public,hw7
how can i speed up slow code,my code seems to be very slow i have put print yes at the bottom line of sgd momentum function and am counting the number of iterations based on how many yes has been printed out but it seems to iterate only about times in like or hours even when i try on non full dataset is there any hints or places where i could look into to speed up my code,public,hw7
difference between full set and not full set,what exactly are the difference between the full set and non full set that we get the fullset to false,public,hw7
no of iteration,is the number of iteration in full set and in the non full set and roughly how long should they take to train each,public,hw7
test accuracy,my test accuracy is remaining constant at after iterations on fullset the training percent stays at how do i ensure this goes to update so i cancelled this model and ran it again and now it is stuck at a test accuracy of i think this is probably because of the random initialization of the weights at the ip layer due to which it is finding a local minima earlier i wonder if there is a way to make this converge at in a deterministic way,public,hw7
numpy indexing,this is going to sound somewhat silly but i've been struggling with indexing into a d array using the results from numpy's argmax function namely in the pooling backprop layer for a while can someone explain to me why indexing into an array of size k k c batch size using the output of np argmax a axis gives me an array of size c batch size c batch size thanks so much,public,hw7
parameters in sgd,for the sgd part and following equations is it right that w rate or b rate represents mu represents and decay represents,public,hw7
how do we submit the visualization stuffs,see above,public,hw7
difference between param grad and input od in ip backward,what is the difference between param grad and input od i am working on ip backward i have calculated param grad 'w' which is dl dw and param grad 'b' which is dl dbias but what do i need to calculated in input od,public,hw7
ip backward,suppose we have three index in ip layer for one image like qna they are ip ip ip how do we find out input od we only know the gradient of ip to input index is w but we know that one input index is related with multiple ip index like the input from one image cross product rows from weight matrix to create ip index how do we fin d the gradient for inputs,public,hw7
image layout,hi all i'm having some trouble understanding what the image looks like and i'm not finding solid support for this in the write up or the other piazza questions if i have grabbed just one column i e image of the input data using input 'data' n for some n would the image in this order in terms of row x col x channel assuming of each x x x x x x x x x x x x x x x x x x x x etcand then we would look at just one channel at a time so maybe form a matrix for the first channel perform max pooling for example and then the second channel etc but if the image is already in this form what would be the purpose of img col any advice will be helpful i have read the writeup a bunch of times so please if you're going to cite the write up at me be specific about what's supposed to be helpful,public,hw7
param grad dimensions in ip backward,in the starter code for ip backward the param grad 'w' and 'b' have been initialized as follows which provides only entries for a single data point param grad 'b' np zeros param 'b' shape param grad 'w' np zeros param 'w' shape the return expression is return param grad input od but this means that gradients for data point will be returned our batch size is so we need entries for data points how do we handle this,public,hw7
param grad and param winc in sgd momentum,hi to my understanding param winc stores the thetas and param grad stores the dl dw then by equation for each layer for 'b' shouldn't these two have the same shape why do they have different shapes for layer,public,hw7
image visualize error,i'm using python and i wrote a script to visualize the output of convolution layer i used the params from the fullset true iterations the module 'matplotlib' and 'skimage' are imported however the output values are out of range i tried to standardize the data into range and get the image like this is this acceptable,public,hw7
code crashed autolab,code crashed message in autolab for a particular function means an error in logic code or both please suggest thnx,public,hw7
question on the relu layer backward,since relu layer basically implements a max funtion which is not differentiable so in class when calculating the gradient we take for x and for x but what if when x should we take as well thanks,public,hw7
divide by zero error,cnn lenet py runtimewarning divide by zero encountered in log nll np sum np log prob y np arange batch size i keep getting the above error and i have no idea why this happens it's in the mlrloss function i printed the y array and in the first iteration it has no zeros but then suddenly next iteration onwards it's made up of a few 's and rest 's i traced this code to where it's coming from mlrloss is called in conv net and the 'y' corresponds to 'labels' in conv net which gets it's input from ytrain in the main function of testlenet py it seems like the computation of y is not affected by any of my code but still it has this weird behavior can any ta please help me i've been trying to figure this out for really long,public,hw7
relu backwards finite differences,hi i'm pretty sure when i implemented relu backwarcds correctly but i get on autolab i checked my code with the provided finite difference function by adding the following code input od relu backward output i output i layers i test input od finite difference output i output i if not np all np isclose input od test input od print np max np abs input od test input od when i set h or so values print out and as i decrease h smaller and smaller values print until nothing prints at all any tips on what i could be doing wrong it must be a autolab specific thing i am guessing,public,hw7
max pooling reshape format,in max pooling i reshaped the output for computation this is what i got for a channel input after i used reshape h w c batch to reshape the output back into a d matrix batch batch row channel channel row channel channel row channel channel row channel channel is this the right format i think the channel order should be instead of,public,hw7
backprop calculations in forward pass,are functions evaluated individually in autolab it seems there are several steps in which gradients can be computed in the forward pass instead of backwards relu maxpool to improve efficiency but if autolab tests each individually then that would probably give errors,public,hw7
finite different output,i'm testing my pooling backprop with finite difference and the output has different size than what input od should be input od approx is when it should be i changed relu to output layer forward in finite difference function but no other changes but that any help would be appreciated edit i realize that the output size is intended after rereading the writeup however how can i compare these values to that of my input od should i be removing values from my own input od,public,hw7
trained tenet mat,is it possible for instructors to release a trained tenet mat it is proving difficult to train on my local computer,public,hw7
gradescope marks,total marks for gradescope submission is listed as however from the handout q totals only marks points for the collaboration questions is there something else i am missing thanks edit updated the marks,public,hw7
test accuracy,after iterations i am getting a test accuracy of is that fine it is not full set thanks,public,hw7
can't run testlenet,when running the third line xtrain ytrain xval yval xtest ytest cnn lenet load mnist fullset of testlenet main i got an error message line in load mnist np random shuffle train indices file mtrand pyx line in mtrand randomstate shuffle numpy random mtrand mtrand c file mtrand pyx line in mtrand randomstate shuffle numpy random mtrand mtrand c typeerror 'range' object does not support item assignment any idea how to fix this thank you,public,hw7
confusion regarding late day policy,if i submit my autolab solutions by the deadline but submit the grade scope solutions late will i be penalized on my entire hw or just the gradescope submission,public,hw7
training time,i have a couple of questions on the training time how long should we expect for the training to finish iterations my implementation takes about seconds to finish training iteration is that normal or too slow stop conditions is the training only stop after finishing iterations it took hours to finish iterations i cannot imagine running through iterations and moreover this is not the full dataset in fact the model seems to converge earlier belows are my training results i hope i can get feedbacks from other students and ta thanks iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far iteration cost training percent running time so far test accuracy,public,hw7
error in given code,when i run the code locally it gives the following error did anyone else face this traceback most recent call last file testlenet py line in main file testlenet py line in main xtrain ytrain xval yval xtest ytest cnn lenet load mnist fullset file downloads hw handout python cnn lenet py line in load mnist np random shuffle train indices file mtrand pyx line in mtrand randomstate shuffle numpy random mtrand mtrand c file mtrand pyx line in mtrand randomstate shuffle numpy random mtrand mtrand c typeerror 'range' object does not support item assignment,public,hw7
how to break ties in pooling layer backward,there is a possibility that there are multiple elements that have the same value which is equal to max although it seems rare how do we break ties or we need not,public,hw7
question about figures that need to be uploaded,the write up says show images from each layer on a single figurefile is it fine to have two separate figures one with images from layer and one with images from layer or do you want all images to be on one figure,public,hw7
test accuracy,if we aren't getting a test accuracy of does that mean our implementation is wrong i'm getting an accuracy of around,public,hw7
secret lecture,what's up with the extra lecture that appeared on panopto is this a replacement for monday's lecture or is it an additional lecture that we need to watch or is it bonus material that will not be on homeworks or exams,public,videos
question about training error,hi sirs i have got all the points on the autolab however i found if i run code locally my cost is nan and my accuracy is very low the accuracy is always below could you please tell me how to fix my issue i think maybe there is something wrong within my implementation,public,hw7
pooling backprop,when debugging pooling backprop i encountered cases where the current pool is a matrix only comprised of 's i thought that this would never occur according to the hw faq this causes input od to have nonzero values that are not equal to h out w out,public,hw7
python implementing sgd momentum why should we return the new params and param winc,hi when implementing sgd momentum in python why should we first deepcopy the params and param winc and return the new two dictionaries instead of directly updating the input params and parma winc thanks,public,hw7
autolab pooling layer backward keep giving error,running test inner product backward py test code did not complete successfully this probably means that your code crashed stdout follows stderr is above this is the message the autolab keep giving but i cannot figure out why it seems that i didn't write any hard code about layers nor did i use np matual and i use two methods but each gave the same result any ideas by the way the code seems run well in my local machine,public,hw7
visualization,can anyone help me with visualization i'm not sure what to do to generate those plots thanks,public,hw7
how to calculate the gradient of max pooling layer,hi in the backpropagation of max pooling layer i have got frac dh i dh i and i need to multiply it with frac dl dh i however the shape of frac dh i dh i is the shape of frac dl dh i is without considering the batch size i don't know how to multiply them and get the row size of again any help,public,hw7
visualizing features,can someone please tell me how to visualize the features after training the model thanks,public,hw7
nan's in cost function input data,i'm running testlenet py and it seems that the initial negative log likelihood calculation is encountering 's which is causing the cost to be nan as well as multiple other values which is causing multiple invalid value nan errors is this a problem with my code or the way the mnist data is being read,public,hw7
autolab zero score,my code works well on my machine but when i submit it to autolab i got zero and there is an error message what does that mean what happened error message unexpected token at ' all error ',public,hw7
pooling layer backward code crashed,after trying different methods i still can't pass pooling relu layer backward on autolab and keep getting the error message that the code crashed any idea how to deal with this problem when test locally i could obtain a training percent of and cost of within epochs but i still didn't get any point on pooling layer backward and relu backward anyone facing the same situation,public,hw7
can someone explain what exactly is col im function doing,i see that it takes a parameter col which is a d matrix of size k k c h out w out but how do we make this matrix i'm not sure i have used the im col function in forward but don't know how to use the col im function in backward propagation thanks,public,hw7
sgd momentum do we need to update param grad of weight based on the weight decay,hi in implementing the function of sgd momentum we should use the regularized dl dw to compute theta do we also need to update the param grad i 'w' as the regularized dl dw thanks,public,hw7
machine option other than local laptop,hi all as running iterations with fullset true in local laptop is time consuming and very computational costly that i almost can't write other assignment at the same is there any free option to run my program i tried shark machine but i even failed to install pip on the machine as i am not in sudo list any suggestion is welcomed thanks best evan,public,hw7
sgd momentum function,i have some questions regarding the sgd momentum function in the comments given in the sgd momentum function it says returns params dictionary updated parameters param winc dictionary gradient buffer of previous step for param winc it should rather be the updated gradient buffers i e updated theta using formula in the homework writeup after the iteration that the sgd momentum function is responsible for right moreover for updating w and b in each layer the updates for w and b are done in the same way except that we use different learning rates right w rate and b rate i'm confused since i only get half score for this function in autolab although when i run testlenet it gets good accuracy level similar values of cost training percent and test accuracy as those shown in the homework writeup and i'm wondering if i'm doing only one of the two updates w and b correctly thank you,public,hw7
cost nan,hi my functions passed all of the autolab tests but when i run testlenet locally i'm getting cost nan and the test accuracy barely changes could you tell me what can possibly be wrong thanks,public,hw7
q report time taken,in question it says to run our final code on the entire full set and then report final test accuracy and time taken for the time taken do we simply check what time it is when we begin running and check what time it is when the running completes and then report the time it took i e text time when running completed text time when began running thank you,public,hw7
interpreting the output of convolution layer,can someone please help me understand the format of the output of the convolution layer in the homework in the homework the dimensions of the conv layer output is but suppose it was height width channels num suppose the output data is then is the following interpretation correct output of channel is output of channel is or is the following interpretation correct output of channel is output of channel is,public,hw7
im col vs col im,should this be the other way around,public,hw7
pooling layer,when the task says implement pooling layer does it mean max pooling layer if not what kind of pooling should we implement thanks,public,hw7
usage of scipy,can we import methods from scipy for maxpooling etc does autolab support it,public,hw7
question about sgd momentum,hi sirs i am implementing about sgd momemtum and found i got zero points on autolab however i don't know what's the root cause in my implementation is it related to inner product backward if i didn't get full score on inner product backward will i get zero point on sgd momemtum what i am doing is update w gradient by decay weigh params i 'w' update theta of w b param winc i 'w' param winc i 'b' update w and b by theta params i 'w' params i 'b',public,hw7
unsuccessful training after i pass autolab,hi i got full score on autolab but my cost starts out at around and never comes down the test accuracy stays at even after training for a long time i double checked my code for bugs but couldn't find anything so far does anyone have any idea what could have gone wrong thanks,public,hw7
weights bias in loss layer,according to the starter code the loss layer also has weights and bias elif layers i 'type' 'loss' t params i 'w' scale np random rand h w c num scale params i 'b' np zeros num t but isn't the loss layer simply taking log of the output of softmax what is the use of weights bias in this layer,public,hw7
l regularisation,on behalf of implementing the sgd momentum function do we have to make the gradient with l regularisation in other words for the below equation's dl dw do we use the dlreg dw from the below equation,public,hw7
visualization q q fullset or not,when answering q and q in section should we use fullset or not how many iterations do we need,public,hw7
why columns,could you please explain why organize the data in columns instead of rows in python numpy operations return the one dimensional outputs as vectors operations of vectors and rows are natural while operations with columns end up in broadcasting in the end there is a lot of extra work just to keep the col shape,public,hw7
question about autolab crash,hi sir i am meeting an strange autolab problem when autolab testing my inner product backward i think my implementation for inner product backward is correct and my code will not crash locally i wonder that what's the root cause for this crash here is my autolab error log test code did not complete successfully this probably means that your code crashed stdout follows stderr is above,public,hw7
pooling layer forward and backward crashing,any reason for this running fine locally,public,hw7
how to get feature visualization,for the feature visualization part how do we get the images when we do training does pickle save our output images for each layer during training in the lenet mat file then do we have to load the output images saved in lenet mat file into python thank you,public,hw7
im col conv,the example for one channel works a i am expecting original data begin bmatrix end bmatrix input data begin bmatrix end bmatrix for k s h out w out i get output data begin bmatrix end bmatrix however for channels it does not make any sense original data channel begin bmatrix end bmatrix original data channel begin bmatrix end bmatrix input data begin bmatrix end bmatrix for k and s i get output data begin bmatrix end bmatrix what is wrong with my example or my interpretation i think the correct output should be output data begin bmatrix end bmatrix or output data begin bmatrix end bmatrix,public,hw7
layer group and layer number,what is the difference between layer group and layer number,public,hw7
cnn toy example derivatives,i'm a little confused about the expected output of the pooling layer backward and inner product backward functions suppose the input for the max pooling layer was and as in the qna example then the output is and so what's the derivative of the output with regard to the input suppose the input for the ip layer was with w and b as in the qna example the output is what's the derivative of the output with regard to the input what's the derivative of the output with regard to w to b,public,hw7
question on conv layer backward,in conv layer backward line i see the param grad b is updated using the sum of all the elements in tmp data diff may i ask why do we add up all shouldn't we only sum in a column wise manner treat each of the parameters of b individually,public,hw7
col im not doing what i thought it did,i thought col im was a re shaping of an array but didn't actually modify any given values however i am giving col im an array of 's and 's and getting out an array with 's in it is col im more than just a re shaping of an array in which case isn't it not the opposite of im col then which is certainly just a re ordering of an array,public,hw7
inputs to the programs,are the inputs to the programs row major ordered thanks,public,hw7
questions about sgd momentum function,i have some questions about the sgd momentum w rate b rate mu decay params param winc param grad function is this function responsible for one single iteration in the sgd the arguments w rate and b rate are the learning rates that we will use for now so we don't have to worry about using get lr function right the w rate and b rate are already the results of get lr is the argument decay equal to the lambda in the writeup section about sgd thank you,public,hw7
hw what is the scale variable in convolutional layer and ip layer,hi in the function of init convnet layers what does the scale variable signify in conv and ip layer why is it computed as scale np sqrt h w c thanks,public,hw7
inner product forward backward autolab crashes,in autolab for both inner product tests my code doesn't complete successfully giving me a score of for both the output is as follows running test inner product forward py test code did not complete successfully this probably means that your code crashed stdout follows stderr is above running test inner product backward py test code did not complete successfully this probably means that your code crashed stdout follows stderr is above however there is no stdout or stderr output to help me debug for all other parts of autolab i receive full credit on my own computer running testlenet py runs smoothly and gives high accuracy as expected additionally i have run small examples using just these functions on my own computer and receive expected output neither nor address the cause of this problem i use the transpose of the weights as advised by no broadcasting is used any advice would be appreciated thank you,public,hw7
office hours on the weekend possible,can we please have more office hours for this homework maybe in the weekend the coding complexity for this homework is much more than the past homeworks there are more office hours scheduled for today but unfortunately i can't make it to either of those can we have any office hours on the weekend,public,logistics
visualization of features,hi how to create a figure file in python do we have to use something like the pil package,public,hw7
autolab submission error,i know that someone posted this issue already but there's no response yet ta please help us to check this error i copied the required files into hw folder then use command tar cvf hw tar hw then submit file hw tar then i got the same error messages as followings i tried a couple of times already thanks,public,hw7
queue is closed,hi all i found queue for today is closed does it mean i won't be able to ask ta a face to face question today thx evan,public,other
about batch in learning w,i have question regarding inner product backward is it right that we get the gradient of 'w' by taking a mean of all the gradients of 'w's over the batch in other words do we have to run thorough all of the datas in the batch in order to computing the gradient value of 'w',public,hw7
weight matrix representation in homework,according to is the weight matrix let's say size a by b for example by matrix in the toy example represented as a b by a matrix i e the transpose of the a by b in the data for our coding assignment so for the toy example param 'w' is a by matrix thank you,public,hw7
broadcasting issue in given code,in the python code i find out that there is a broadcasting issue in the given conv layer forward function in line i think the param 'b' is broadcasted because the shapes of the two operands of the plus operator are different should i modify the code,public,hw7
how is inner product forward supposed to work,hi i just wanted to clarify the action of the inner product layer on an input with more than one channel i can't seem to find anything definitive in either the slides or whiteboard on the exact way the linear transformation occurs for example take a vector representation of an image with only channel apply convolutions to this image and flatten the vectors produced into a single vector now if this long vector is now the input into the inner product layer do we simply multiply this vector by a weight matrix and then add the bias or does our weight matrix have smaller dimensions such that we are supposed to transform the vectors separately and then flatten them together the thing is that i don't know the exact relation between the num variable in inner product forward and the dimensions of input thanks,public,hw7
ip layer backpropagation,in the toy example during the ip layer each entry in the ip input a vector of entries meets with entries in w since w is size matrix how should i express frac d text ip output d text x entry should i add those entries of w,public,hw7
question about implementation,hi sir i am implementing the function inner product backward and feel confused about param grad 'b' if i didn't misunderstand the purpose of this function we should update both w x and b however how should we update b i don't know what kind of data should be used to update b,public,hw7
question with conv layer backward,hi everyone in the conv layer backward function i am confused about line what is the output 'diff ' i didn't find this element in the forward function thanks,public,hw7
what are some advantages of svm over neural network,in lecture neural network is introduced as the universal function approximator does it mean that generally speaking neural network is the best ml algorithm for classification if so why svm say with rbf kernel is still used today what are some advantages of svm with rbf kernel over neural network how should we choose the right algorithm under certain condition thanks a lot,public,other
question about backward codes,for the function such as pooling layer backward and inner product backward they take in output as well as input is this output the output from the corresponding forward function of the same iteration,public,hw7
how to update param 'b',in backward propagation of ip layer according to the formula what should param grad b be like should it be a vector of,public,hw7
autolab submission permission denied,i tried three times to submit my hw tar file but i got results like this i have no idea why this happened but can you exclude these submission from the submissions,public,hw7
harsha's office hours,hi all i would be moving my office hours to pm pm for tomorrow and can extend it till pm if needed thanks,public,hw7 other logistics
sgd momentum not get full scores in autolab,hi all i have trouble finding bugs in my code it looks working well and achieve ok test accuracy after and iterations cost training percent cost training percent cost training percent cost training percent cost training percent test accuracy cost training percent cost training percent cost training percent cost training percent cost training percent test accuracy however my code only get out of in autolab what i did in sgd momentum are iterate over all layers except for the data layerextract theta from param winc extract gradient dw and db from paramupdate gradient dw with weight decay formula update theta with formula update w and b with formula put updated theta back into returned valueput updated w and b back into returned value could you please correct me if i miss anything thank you so much for your help thank you best evan,public,hw7
how to improve the training percent,this might be a silly question but i can't improve my training percent and they are of extremely low value like only any suggestion for how to check the code to see where might go wrong,public,hw7
how to interpret the output of im col when there are multiple channels,according to the documentation the output is like col shape k k c h out w out when there is only one channel the output is obvious when there are two channels which one should be the correct output format a or b,public,hw7
confusion about k value,in the writeup table of lenet example k value of convolution layer is but k value of max pooling layer is there are five output matrices of convolution layer should we use same k value of max pooling layer why can we use smaller k value of max pooling layer i am so confused,public,hw7
gradescope,is it okay to have everything on page when submitting i also have the collaboration questions at the top of the page and feature visualizations underneath thanks,public,hw7
visualize using lenet mat,how i can visualize the output with my trained model saved in lenet mat please give me some more details than you,public,hw7
homework qna solutions up,they can be found here in the resources section in the tab above,public,hw7
inner product forward num,in the inner product forward function in the code handout it says output 'channel' num here num is basically the number of entries in the bias vector right so in the ip layer context is channel really each entry of the resulting vector after the linear transformation for each batch i e for each input image,public,hw7
homework logistics,hi tas its just weeks for the final exam may hw is scheduled to get wrapped up in next days could i please get a ballpark of the homework schedules for hw hw as my schedule is crazy for these last weeks of the semester also is it really possible to finish more homeworks with the exam so close,public,logistics
qna finite differences,i worked out the solution to q using finite difference i incremented f from ' ' to a value of ' ' and the loss changed from to so according to finite differences the derivative wrt f should be i expect this to be a little off since the rate of change isn't instantaneous but qna says it is can someone please explain where i'm going wrong,public,hw7
im col,is the im col conv function supposed to handle a single batch with multiple channels at once or should we use the function for each channel i've used a simple example to see the output of the im col conv function i got the expected result when i use it for one channel where i set the input channel to but when i use it for channels where i set the input channel to i get an output matrix but not expected entries thank you,public,hw7
how data is stored,when we have an input one batch of channels where each channel is a x matrix then is the data in this homework a column vector of entries where the first entries are the entries of the first channel matrix and the latter entries are the entries of the second channel matrix and when there are multiple batches each column corresponds to each batch,public,hw7
q c what does the question mean by observation,in question we need to compare different layers and explain the changes we find then there is a question that says c points explain your observation how is this is different from what we described on a and b,public,hw7
q q visualize the first image of test set or randomly select one i th,in writeup section page it says that we want to visualize the output of the i th data point i d the first image of test set i don't quite get it does that mean we need to visualize the first image of test set or we need to randomly select the i th for visualization is it okay to use the first image in test set thanks,public,hw7
hw qna due tonight,hi all just a reminder the qna questions are all due tonight at pm anyone who submits answers after this time will receive a on this question be sure to submit early so you do not get caught out by this as there will be no 'i only submitted minutes late' exceptions the solutions to these questions will be up tomorrow morning good luck with the rest of the homework daniel,public,hw7
v structure how to prove x and z are not conditional independent,i know how to prove p x z p x p z how to prove that p x z y p x y p z y,public,other
feature visualization,for visualization the write up said refer to vis data m i can not find it can anyone tell me where it is,public,hw7
sgd momentum,am i right in understanding that we have to update params of all layers one by one in this function by pulling them out of the array of structures,public,hw7
channel size batch size,in the writeup it says output channel stores the channel size of feature maps and output batch size stores the batch size of feature maps what exactly are channel size and batch size,public,hw7
autograder error,can someone please tell me the cause of this error in autolab,public,hw7
qna how to find derivative,for the qna questions should we find the derivatives analytically i e do the differentiation symbolically by hand and plug in the point or should we use the finite difference method with the step size finite difference method would be with the equation f' a frac f a h f a h where h taken from wikipedia thank you,public,hw7
questions on inner product backward,my implementation works well locally and can reach test accuracy after k iterations on small data it runs well without exceptions however when submitted to autolab everything goes well except inner product backward which is said my code may have crashed i think though not exactly i did not use broadcast in the function why does it crash on autolab running test relu forward py 'relu forward' running test relu backward py 'relu backward' running test inner product forward py 'inner product forward' running test inner product backward py test code did not complete successfully this probably means that your code crashed stdout follows stderr is above running test pooling layer forward py 'pooling layer forward' running test pooling layer backward py 'pooling layer backward' running test sgd momentum py 'sgd momentum' scoreboard scores inner product backward relu backward sgd momentum relu forward pooling layer backward pooling layer forward inner product forward,public,hw7
qna,do we have to consider the values of the image which are related to the filter value f,public,hw7
subderivative of max function,in lecture we learned that the for y max a b the subderivative is frac dy da if a b and otherwise suppose y max a b c then is the subderivative frac dy da if a max a b c and otherwise,public,other
loss function,in the loss function formula what exactly is y k thank you,public,other
q,our softmax layer gives an output of probabilities say y y y and our loss function j log pj is p y p y and p y dj dy y dj dy y dj dy y are these correct for dj df do we need to follow paths where each path of derivatives starts with dj dy dj dy and dj dy,public,hw7
how to use decay in sgd,there is no much description on how to use decay in sgd momentum in the writeup can someone tell me how to apply it into the function any help is appreciated,public,hw7
are the auto grader tests graded on functionality as well as performance,hi i am passing every test on autolab but my inner product backward is graded by the grader does this mean that there is something functionally wrong with the implementation or is the code slow and losing out on performance points,public,hw7
training accuracy,there is a weird thing that my autolab get full credits but the training accuracy seems not going up quickly but if i add weight decay to bias terms then the accuracy goes up above quickly of course then the autolab will give me for sgd momentum can anyone explain this to me,public,hw7
inner product forward programming,hi the weight matrix of the inner product forward program is just the transpose of the weight matrix for example in the toy example the weight matrix is x when the output of ip is sized vector in the same way in the program we are given x weight matrix but as ip output is x we just need to take the transpose of this matrix right thanks,public,hw7
derivatives in max pooling,in the question of the following note https piazza com class ixs v xr cz d cid the ta mentioned that if there are several maximums in a single block of the matrix for the max pooling we need to consider the derivative of all the matrix elements corresponding to those maximums however in another note https piazza com class ixs v xr cz d cid the ta said we only need to consider the far right value of the pooling i wonder which convention should we use,public,hw7
linear layer ip layer,is linear layer the same thing as ip layer thank you,public,hw7 other
loss in qna,should i use formula or formula to calculate the loss i am confused about the whether i should sum up all the losses of all the output nodes or just care about the node that the output needs to be close to one,public,hw7
hw gradescope,we don't have to point out the pages of each of the questions for this homework when i submitted my pdf on gradescope it seems there's no such choice this time,public,hw7
order of different layers for qna,what relative ordering should we follow for the different layers to answer the qna questions should the layers be arranged in the same order as listed in the writeup table conv maxpool ip relu softmax loss the recitation slides seem to show a different ordering and the background material provided for cnn from the stanford course also follows a different order,public,hw7
bias term in convolutional layer,i saw several piazza posts saying there is no bias term included in the convolutional layer for qna this is a general question what would the convolutional layer look like if there is a bias term how would the bias term affect the results e g do we add the bias term to every entry of the output matrix thank you,public,hw7 other
softmax layer,i think the number of output for softmax layer depends on the objective of the cnn itself as the number of the example came from its objective to determine the decimal what is the objective for the toy cnn example and is it fair to determine the length of softmax output from there,public,hw7
input to ip,is row major format equivalent to move in the first matrix then second matrix etc where for each matrix we go from the top row to the bottom row and for each row we go from left to right,public,other
submission error,after i submitted hw tar i got such message from autolab may i ask why,public,hw7
autolab error message when submitting codes,did anyone received this error and know the solution error message unexpected token at ' all error ' ls cannot access hw py no such file or directory ls cannot access hw m no such file or directory make all error,public,hw7
input of inner product forward,hello i am a tad unsure of the dimensions we should expect from input when using inner product forward also i'm working through the math of the output of the second pooling layer isn't each output x of that if my math is correct the output of each second convolutional layer is x making each output of maxpooling to be x how do we get a number of x outputs of a maxpool to multiply cleanly with a n inner product layer also while writing the code how do we access all of the pooling outputs in order to concatenate to multiply by the matrix of parameters should we assume that the input 'data' is already in a column form or do we have to some form of im to col if so how is that accessed in the dictionaries thank you,public,hw7
qna,in my formulation the cumulative derivative from the filter until softmax results a vector with values the derivative of the loss in respect to softmax is a scalar a scalar multiplied by a vector results in a vector but the final result should not be a vector,public,hw7
reshaping in im col,when i was reading the im col function i found that the data are being reshaped into im np reshape input n 'data' h in w in c isn't the first index depth in an ndarray so shouldn't this be c h in w in instead i'm asking the question because i ran into problems with the shape when i'm testing my function using some synthetic data thanks so much for the help,public,hw7
training percent is increasing and decreasing,when i try to run my cnn the training percent is decreasing instead of increasing cost training percent cost training percent cost training percent cost training percent cost training percent what might be the reason for this to happen,public,hw7
should we flip the filters for the convolution layer,the wikipedia page linked from the writeup specifies that the filter should be flipped along both axes before multiplying and summing but this results in answers for subsequent questions which don't make sense if i don't flip the filters i get answers that make more sense but this is in contradiction with the definition of the convolution operation as cited by the handout,public,hw7
im col conv,what is the size of the output of im col conv based on the writeup it should be k k c h out w out but the line col col would make the shape k k c h out w out thanks,public,hw7
qna apply relu layer before softmax,the table in the writeup table toy cnn architecture implies that there is an relu layer before softmax however in section the softmax layer takes wx b as input so should we do the max wx b before applying softmax function,public,hw7
cnn softmax,in cnn for classification do we simply choose the class that the softmax gave the largest probability thank you,public,other
qna how to approach,i attempted questions to of the qna but i cannot think of how to approach questions derivative of loss function wrt different parameters in q i obtained value of loss how can i now differentiate this value a scalar wrt to the parameters can someone please give some pointers hints,public,hw7
backward propagation of maxpooling,in backward propagation of max pooling if a input of this layer for a max pool are all zeros what should the differential output of this unit i e begin bmatrix end bmatrix max pool rightarrow begin bmatrix end bmatrix which should be the max of this example the differential output should be what,public,hw7
configuration of the toy cnn example,in the homework cnn example s for the pooling layer does this mean that stride for pooling i thought that for pooling there is usually no overlap so stride would be equal to k n for the ip layer does this mean that there are units in one hidden layer or does it mean that there are hidden layers the rows in the w matrix are applicable to the three units of the ip layer respectively that is w is for unit w is for unit and w is for unit right,public,hw7
cnn padding,in cnn why do we need paddings around the input image,public,other
autolab sgd momentum function crash,when i run the autolab all other function passed but the feedback tells me that sgd momentum function crash like this running test sgd momentum py test code did not complete successfully this probably means that your code crashed stdout follows stderr is above what does this mean,public,hw7
lecture linear layer,in lecture whiteboard notes' last part for linear layer it says see nn part which part is this referring to thank you,public,other
neural network activation function,hi i am quite confused with this slide what does the lr mean does it mean that use logistic functions and is the colorful lines in the picture indicating the value of the logistic function i e the probability thanks,public,hw7
qna notation clarification,i'm a little confused by the notation w i think the w represents n in the fully connected layer but am unsure about what signifies thanks for the clarification,public,hw7
qna clarification,how are filters used for the convolution layer shouldn't only filter be applied,public,hw7
qna cnn,ip does happen before the relu correct also in convolution do we follow the standard convolution where it is reversed in the sense that you multiply the first element with the last element in the window and move from there to sum up or do we just do it in order so that the first element of the filter is multiplied with the first element of the window thanks,public,hw7
readings clarification,could you elaborate more on this example that explains equivariance in the goodfellow book e g what's the convolution function for example let i be a function giving image brightness at integer coordinates let g be a function mapping one image function to another image function such that i' g i is the image function with i' x y i x y this shifts every pixel of i one unit to the right if we apply this transformation to i then apply convolution the result will be the same as if we applied convolution to i' then applied the transformation g to the output could you explain more on the following sentence in the reading we can imagine a convolutional net as being similar to a fully connected net but with an infinitely strong prior over its weights this infinitely strong prior says that the weights for one hidden unit must be identical to the weights of its neighbor but shifted in space thank you,public,other
flip kernel,can someone explain what flip the kernel for cnn means intuitively thank you,public,other
yongjin's additional office hours,hi all i am holding additional office hours on friday april for am pm this has been updated on the google calendar exact whereabouts can be checked from course website calendar yongjin,public,other
ties when backpropagating through maxpool layer,if there is a tie for the max value in a feature window do we backpropagate through both max values or just arbitrarily pick one to backpropagate through,public,hw7
sarah's office hours,hi all i am moving my office hours for today april to pm this has been updated on the google calendar sorry for the short notice sarah,public,other
confusion on softmax layer,hi all i modify my question i mix up relu with softmax before i know softmax function softmax x frac e x j sum j e x j and i also find in writeup that softmax layer assign probabilities to each class given input feature map and we have the formula p softmax wx b my questions are in formula p softmax wx b is x what called input feature map in softmax layer of toy example don't we simply do softmax x frac e x j sum j e x j where x is output of relu layer and input to softmax layer it seems no parameters w and b is involved in softmax layer here is my understanding correct so p softmax wx b is simply a combination of inner product layer and a simplest softmax operation which is not what is used in the toy example thanks for clarification evan,public,hw7
debug forwarding locally,is there a way for us to debug the first part forwarding functions locally i'm trying to use the toy example in the writeup as input but it took a long time for me figure out all the variable settings,public,hw7
feature visualization using fullset or partial set,for question q and q do we need to use the model trained by fullset or partial set,public,hw7
qna,i am lost here i understand that we need to minimize l log p j in relation to y as y is the output vector of the softmax is is p j y j our objective function is only dependent on the label j of the current example to select the proper p j therefore there are two solutions conditioned on the coincidence of j with the label with but there is only space for one answer in qna,public,hw7
question qna length,what do length refer to exactly does it refer to the dimension of the output from my perspective it is obvious that these output a real number i e dimension so is it actually referring to the number of outputs of the layer given that the layer may have more than one relu neuron,public,hw7
qna,in the answer should the derivative include sign,public,hw7
max pooling for odd dim array,hi i think i have understood something wrong can some one guide please if my convoluted layer has dimension x any odd numbered filter size x i cannot have max pooling after that max pooling takes max out of every non overlapping x block right we cannot have non overlapping blocks for odd dim array where am i going wrong thank you,public,hw7
qna grading concerns,hi i've just checked the qna grading for hw and it seems that they deducted points for collaboration questions and the 'time spent' question even though i answered them ahead before the hw deadline how do i resolve the issue get back the points thanks,public,hw6
autolab problems about max iter and display interval,i see in the code that max iter and display interval so it will print the cost f training percent sentence for times and test interval so test accuracy sentence will be print for times,public,hw7
what's vis data m,what's vis data m in feature visualization and how can i show the image of a layer thanks,public,hw7
finite difference function,how do we have to use finite difference function it is written that the input od approx is of size input data but the way it is implemented it is of size output data how to make sense of the input od approx result that we get,public,hw7
confusion about i j k,row major format i e i j k entry in output of max pooling layer is i cols j k row s cols entry in vector input of ip layer my understanding is that i represents which row j represents which column k represents which channel then k only varies from to the number of channels is my understanding correct solved,public,hw7
decision tree coverage,are decision trees going to be covered in this class i was asked about them in a recent internship interview and didn't know about them,public,logistics
question indexing,is question indexed or indexed edit its indexed as specified on page of the writeup,public,hw7
ip layer n,what is the meaning of n in ip layer is it the number of filters if it is we only have filters,public,hw7
how to do backpropagation,hi i'm still confused about how to do backpropagation in cnn especially in the convolutional layer and the max pooling layer must we need to derive an expression so that we can get the derivative is there a simple way to do that for the toy example say just according to the specific matrix thank you,public,hw7
qna,is the given w matrix the weight of the single layer or two layers,public,hw7
qna,i am lost in the examples the slides show a max pooling layer converting z x and z x to mz x and mz x but qna requires a coordinate for mz that has only coordinate,public,hw7
how can i see structure of input parameters,how can we see shape and structure of input parameters in functions for example def pooling layer forward input layer how can i know shape of input and layer,public,hw7
qna and,when you say length are you referring to the number of outputs depth in the example,public,hw7
expected test accuracy,what's the expected final test accuracy after iterations the handout says it should be about but i only achieved is it acceptable,public,hw7
array shape,is the d array taken as input for pooling layer forward in row major order i e if i j k represents the entry in the ith row of the jth column of the kth channel then the corresponding position of this value in the input data for pooling layer forward is i cols j k row s cols,public,hw7
suggested readings,there are two readings suggested in the writeup deep learning cnn chapter mlp chapter but will reading those be helpful after reading the chapter from neural networks and deep learning or will most of the things overlap,public,hw7
how is the output 'data' in the conv layer forward function organized,i am trying to debug my program to do that i am using the small toy example used in the qna i sent the input matrix to conv layer forward function and i am using the same filters used in the qna inside the conv layer forward function when i print the tmp output i get the same results i got when doing the exercise manually they are stored in a x matrix the st column has the values from the st filter ordered row wise and the nd column has the values from the nd filter st question is this ok should i be getting a x matrix here after that the function is calling tmp output flatten which is intertwining the values of the two columns nd question in the next layer max pooling how am i supposed to handle the input 'data' array is this an array organized row by row column by column or other because after the intertwining it seems that my data is not ordered by either,public,hw7
collaboration questions,where do we have to write if we collaborated for qna questions,public,hw7
row major format and numpy flatten,hi all according to write up input to the ip layer is the output from the max pooling layer vectorized using row major format i e i j k entry in output of max pooling layer is i cols j k rows cols entry in vector input of ip layer where row s and cols are the number of rows and columns in the max pooling layer output respectively so if rows cols we have if this is correct then i want to flatten a d ndarray into a vector this is what i do here i construct a d data just like what we get from a cnn layer with th depth slice and th depth slice what i want to get from a flatten operation is a d vector where first elements are from st slice and last from nd slice d np array reshape d np array reshape print d flatten print d flatten d np zeros d d d d print d flatten c however according to numpy tutorial https docs scipy org doc numpy reference generated numpy ndarray flatten html parameter c means flattening to row major order can anyone help me with this issue or do i understand anything wrong thank you evan,public,hw7
good materials to understand lenet architecture better,hi all you may be curious about why c c etc take a look at a slide would solve your problem http www cs cmu edu aarti class spring slides deeplearning pdf hope it helps evan,public,hw7
qna q,when you say entry in the convolution matrix are you assuming that the matrix indices start from as opposed to same question regarding the formula i cols j k row s cols here i j and k start from or,public,hw7
intuitive interactive toy to help you understand what convolution is actually doing,hi all i found a website that visualize the convolution process with easy to interact tools it's amazing http setosa io ev image kernels evan,public,hw7
bias for convolution in qna,just wanted to confirm if we have to take the bias for convolution for qna,public,hw7
max pooling and relu,which of the layers appears first the handout says pooing ip relu and the recitation slide said relu pooling please find attached images for reference,public,hw7
another question in pooling backward,in the pooling backward if several elements in the output matrix are from the same index in the input matrix then when back propagating the gradients do we need to sum all the gradients of these in the output matrix together to the same index in the input matrix thanks,public,hw7
qna why are we taking partial derivatives with respect to ip weights,in the qna the question is asking about the derivative with respect to w however in the recitation slides we always only take the derivative with respect to the previous layer output mz ef k and considered the weights as constants frac partial fz partial theta ab k frac partial fz partial mz ef k times frac partial mz ef k partial theta ab k slide am i missing something should i be taking both derivative with respect to the weight and with respect to the previous layer output,public,hw7
what are w and b in the example for qna,is w the width of a convolution is it x is b a bias term,public,hw7
need to consider padding in pooling layer backward,in the write up it says we can assume padding is in pooling layer forward then do we need to consider padding in pooling layer backward thanks,public,hw7
qna,what is y in qna is it the input or output of softmax transformation,public,hw7
linear layer gradient,in class matt said to look back at the nn part to find the gradient for a linear fully connected layer could someone point me to exactly the part he is speaking of does this part include both the linear gradient and the sigmoid gradient or only the linear gradient see the notes below where he makes this comment thanks,public,hw7
qna last question,for the last question of the qna is f the top left value in the filter or the top left value in the output of the filter acting on the input matrix because theta is used to represent the values of the filter in the recitation slides and f is used to represent the filter output in the recitation slides,public,hw7
are we supposed to run iterations,hi i think iterations are not necessary to get a fairly good result iterations are good enough,public,hw7
will there be any sample code for us to visualize the figure,hi the write up said we should refer to vis data m but there is no such file in the handout for python users thank you,public,hw7
is state of the art deep learning semi supervised,in hw we are given labels for all training examples but in the paper i reviewed yann lecun cvb the author was able to train the network with fewer labels than the number of training examples i am trying to understand if we always need some quantity of labelled data for training or is it possible to do so in a completely unsupervised manner say by randomly initializing the cost function to some value which the algorithm then tries to minimise,public,hw5
math behind the equation,in lecture matt explains these equations for back propagation does anyone know how these were derived how they came up please see the orange box in the attached image,public,videos hw7
calculate gradient of bias in conv layer backward,in conv layer backward code for calculating gradient of bias is however i think the second line should be param grad 'b' np sum tmp data diff axis because if not specifying axis np sum will sum all elements in the array and return a scala in this way every element in vector b will be the same in fact b is a vector of size num tem data diff is a matrix of size h out w out num summing tem data diff along axis gives a vector of size num and then adding the sum to b updates b elementwise which seems make more sense,public,hw7
what's the form of the cross entropy function,i've found two forms of the cross entropy function from http neuralnetworksanddeeplearning com chap html we need to divide it by the total number of input items from bishop p we only need to sum all the losses and we're provided a form of loss function in write up are we supposed to use that one in the homework thanks,public,hw7
latedays,the deadline displayed on autolab may not correspond to the actual deadline for this homework since we are allowing late submissions as discussed in the late submission policy on the course site autolab can be configured to have latedays i know this is probably too late into the semester for it to matter but still,public,hw7 logistics
loss function,in our class matt gave the loss as cross entropy in our cnn what we need to do is to maximize the probability over all input images which is j sumlog pj so l j and this j should be the actual loss function we care about am i right,public,hw7
write up confusion,in the write up there is one sentence hence the dimensions of the output feature map are h p k s xd w p k s xd c since we have n filters in a convolution layer the output feature map is of size h p k s xd w p k s xd c xd n since each filter outputs for each of the c image channels and n filters are stacked together in the mnist datset we will use the images are black and white and therefore the number of channels c is i think this may cause some misunderstanding for some students from my understanding the output of the convolution layer should be h w k where k is the numbers of filters not as it mentioned the write up as h w k c where c is the channels of images in fact if we have a h w input image and k filters each filter will be h m and during the convolution process these three channels dot product are summed and add one bias to form the output hope matt could clarify these details in class i think this is crucial,public,hw7
question in pooling layer backward,i would like to know if in the input feature window of pooling layer backward there are multiple maximum values that are the same then we should update which one thanks,public,hw7
qna,do we consider bias term when answering these questions if so what values should be used for the bias,public,hw7
qna are all bias terms,for the qna part of hw should we default all the bias terms are in cnn thanks,public,hw7
when will the peer reviews be made available,when can i see the feedback on my review,public,hw5
debugging code,i think my code is correct i have tested it against all possible test cases that i can think of but still i am getting a zero score in two functions here is the screenshot showing that i am able to get an accuracy of around iterations any tips on how to solve this,public,hw7
code required for qna,do we need to implement the code to be able to complete the qna part or are we supposed to manually find the answers,public,hw7
question about sgd momentum m,in this function we need to update w and d in all layers should we regard the total number of layer as known or unknown information or will this affect the judgment of autolab actually i am trying to figure out why the function fails,public,hw7
what is the meaning of tensor,what is the meaning of tensor does it simply mean input features,public,hw7
qna,there is some inconsistency in the notation when you say the configuration of ip is n does that n stand for the number of ips in the architecture or the number of rows of the weight parameter as stated at the bottom of page,public,hw7
question about mini batch gradient descent,i think for this homework we should use mini batch gradient descent so should we use the mean value of n batch size gradients of the batch we get as the gradient we will use when updating parameters,public,hw7
what is meant by batch size in numpy array,i got the first input arguments intuition in height xd width xd channel batch size but what is meant by batch size,public,hw7
qna subderivative,hint if two values from the convolution layer both take on the max for a certain pooling use the subderivative with respect to the far right value that is the value that corresponds with the instead of the i googled subderivative and still don't understand exactly how to derive one and how to apply it to question i'm really lost on how to take the derivative of a max function as well from the max pooling layer is there anyway the ta's or professor can expand beyond the hint,public,hw7
is there any template for gradescope submission,the writeup mentions using the template provided could you please provide the link to the template i failed to find the link in the writeup and on piazza thanks,public,hw7
qna not accessible,i am not able to access the qna for hw,public,hw7
backpropagation question,in the right side backpropagation how do we compute the bigtriangledown x j in the bottom also isn't our ultimate goal to compute the bigtriangledown alpha j that will be used as the gradient for sgd which we already did in the for loop thank you,public,other
chain rule,according to how the variables are defined and the derivative formula on the right should the picture in the center not contain the layer consisting of w and w,public,other
mlp function tensor,the reading says that a large mlp can represent any function but might not be able to learn that function what exactly is the function here is it the function of the input x's i e f x it says backpropagation is used for tensors too what's a tensor thank you,public,other
reshape matlab,reshape in matlab works differently than how we reshape images to vectors or vice versa figured it out the hard way,public,hw7
hw qna example,hi in the qna questions we were asked to compute the outputs of several layers based on an example image on page of the writeup it says the following example image of digit out of possible output digits however the actual image includes values and are these and valid entries of the image thanks never mind i just figured what those output digits refer to,public,hw7
qna indices,when we have the i j k element of a d array for the qna problems what does i j and k correspond to for example say we have the output from two filters acting on a dataset thus we have two d arrays also known as a d array is k the depth i e whether we use the first output from the filter or the second i the row and j the column or is i the depth j the row and k the column or is it something else thanks,public,hw7
lec doubt,please see the blue circle in the attached image from slide in lecture could you please explain how did it come up,public,videos
loss function and objective function,can anyone describe the difference between loss and objective function is simple terms i do have a basic idea looking for more intuitive explanations,public,other
on pre processing of data,in lecture matt talks about pre processing the data so that we can better learn a logistic regression decision boundary since our decision boundary is based on training data which has been pre processed the decision boundary is also specific to the case of that pre processing and for our decision boundary to do good on the test data the test data should also be pre processed in the exact same manner i had a doubt on this would we have the time opportunity to even pre process on the real life test data how do you pre process the the unknown test data,public,videos
autolab error message,i tried to verify gradient and they seemed to work well i also ran my network on my own computer it ran very slowly several seconds for one iteration but accuracy rose to over after hundred of iterations however i only got points on autolab and debug messages were not helpful how am i supposed to debug my program i even received from relu forward thanks a lot,public,hw7
qna,about the cross entropy formula used in hw should we calculate the average for example in qna should it divided by,public,hw7
question about cross entropy loss,the cost function of the example in recitation use j y log y y log y but according to the wikipedia the cross entropy is defined as so why isn't the cost function in recitation add a negative symbol,public,hw7
ignore,figured out this problem please ignore,public,hw7
order of layers in cnn,in the recitation slides it appears the order of the layers is convolution relu maxpooling fully connect output but in the hw it appears the order of the layers is convolution maxpooling fully connect reu output,public,hw7
cnn recitation annotated slides uploaded,i have added annotations to my slides and uploaded them to the resources section of piazza i would recommend using the annotated version in conjunction with the originals as the annotation breaks the flow a little thanks daniel,public,hw7
homework helpful information,hi all we wanted to let you know now that in homework you will be allowed to work in groups of we hope that letting you know now will give you ample time to find a partner you may also work individually if you prefer you may not work in groups of more than also we encourage you to work on the same topic that you chose in homework but it is not required if you do switch topics you must read at least one of the recommended papers from homework related to your new topic before beginning the assignment course staff,public,logistics
hw review,for review of each section i write excellent quality for this section which means but i forget to assign points to them what will happen,public,hw5
pooling layer forward function matlab,why is h out and w out for this function defined as outputs of convolution layer this format of h and w out comes when we are performing convolution operation i think they should be something different,public,hw7
more literature about deep learning,hi all just thought it might be useful to watch the lectures on deep learning and cnns by prof kayvon from spring these lectures give a short but informative overview about convolution backprop and also a systems perspective view of how large scale neural networks are trained in parallel http courses cs cmu edu spring lecture dnneval http courses cs cmu edu spring lecture paralleltraining,public,hw7
code of finite difference does not match with documentation,it seems the function is not finished yet there may be several problems data should be accessed using 'data' the function use relu forward so it may only work for relu layer parenthesis for calculating input od approx is put in a wrong place,public,hw7
homework changes and faq's,faqs q should we apply weight decay to bias terms as well a usually weight decay is not applied to bias terms since they are not regularized q will you provide a latex template for uploading solutions to gradescope a please use a blank latex template to answer each of the theory questions and upload them there are very few of them in this assignment our latex has a lot of extra stuff with pages and some people fill in the answers in the latex we provide and upload the entire pdf for each question which makes it difficult for the grader because they have to skim through so many pages to get to a tiny answer we want to avoid that q can you debug our code if we post it as part of a private question on piazza a no we cannot it is much more difficult to read and understand complicated code than it is to write it it is even more time consuming if there might be errors in the code as such we cannot debug your code for you please work through the toy cnn example to completely understand and reinforce concepts use the asserts in code handout to check if your return values have the correct shape and use the test script testlenet to run the code and see if test accuracy increases with iterations q in max pooling if there are multiple values in a window that correspond to the maximum should i pick just one of the values or all of the values while propagating gradients in pooling layer backward a in practice this should happen rarely our initial test provided a constant matrix input to your function in order to avoid the above dilemma altogether we now provide random integer matrices as inputs to your implementation and our reference implementation and compare the results as for your implementation i would suggest using all the values that correspond to maximum if there are multiple values corresponding to maximum in a feature window since there is no reasonable way of knowing which particular pixel actually led to the max pool output value q how do i use im col conv and col im conv for coding my functions a you do not apply im col conv and col im conv to the entire image you apply im col conv to each feature window of the input and stack the resulting columns in a matrix before proceeding further similarly you use col im conv to convert the column to a feature window shaped matrix and add it at the appropriate position of the resulting image please read their descriptions in the pdf and in the code handout to clearly understand what they do they will reduce your work and any errors drastically in coding the pooling layer forward and pooling layer backward functions once you have figured out how to use them in this context changes qna updated question to read frac dj dy and updated question to reflect code handout code for finite difference updated in handout on april pm,public,hw7
cnn recitation slides,hi all i have added the recitation slides to the resources section of piazza as discussed in the recitation i will add an annotated version maybe tomorrow or saturday which tries to explain things in more detail thanks for showing up good luck with your homework daniel,public,hw7
im col conv why do we need to give h out and w out as parameters,hi all i think in im col conv input n layer h out w out function in cnn lenet py h out and w out shouldn't be parameterized as they should be calculated as h out h in pad k stride w out w in pad k stride i hope someone can clarify or correct me if i am wrong thx evan,public,hw7
kernel flipping for convolution layers and how to use w,questions about the qna are we supposed to do the computations involving the convolutional layer with or without kernel flipping is w the weight matrix for the ip layer of the two filters concatenated so do we use the first columns for the results of convolution and max pooling with filter and the next columns for filter if not the x dimensions are a bit confusing,public,hw7
homework qna question change,hello all there was a bit of an issue in the last question you should have got a case where values from the convolution layer both take on the max for a certain pooling in this case when you differentiate you should take only the sub derivative of the far right value of the pooling position as your frac d df that is the value not the value in practice the odds of this happening are impossible since you randomize your starting weights but it occurred this time since we gave you a simple example thanks daniel,public,hw7
nielsen book chapters,just wanted to check chapter of nielsen's book is about neural net chapter is about backpropagation and chapter is about cnn right thanks,public,other
output batch size,hi all i used to think of convnets as a special case of classifier that given an input image it outputs its score for each candidate class and i find output batch size parameter in writeup does it merely mean the convnets can be given batch size images in one time and outputs scores for each input image thanks for your help evan,public,hw7
momentum of sgd,what is the meaning of momentum in sgd is it the same as learning rate,public,other
bias in ann,i thought that we have bias term in input layer and not in output layer the highlight part in online reading assignment confuses me can anyone explain this to me thank you in advance,public,other
homework released today at,hi all homework will be released tonight at pm you will find the handout and the writeup in autolab after this time in homework you will be implementing sections of a cnn and applying the material learned in the last lectures the homework has sections and it is important to note that one part is due at a different date than the other two section qna this section is due at pm it must be submitted by this time otherwise you will receive for this question no extensions will be given for this section and we plan to release the answers on the so you can use the answers in this segment to help you test your programming you have been warned we will not accept any excuses regarding not knowing about the due date of this section link homework qna autolab gradescope these sections are due on at pm submissions received after this time with be subject to the usual late penalties this assignment will take you a long time to do and as such we highly recommend starting it as soon as possible do not assume you can finish this homework the day before it is due even the most efficient code is expected to take hours to run as a consequence of this debugging will be exceptionally difficult for the ta's so you should make sure you know what your code is doing at each section and practice debugging your code locally you only have submissions so you should not use autolab to debug your code i daniel will be holding a cnn recitation tomorrow at pm pm in the usual recitation room i will be going through a toy example different from the one on your homework and answering any queries you have regarding nn or cnn's i will post my slides for this example after the recitation good luck thanks course staff,public,hw7
can i give a non integer overall score on peer review,i would like to assign a grade between and i was wondering if i can grade a paper as,public,hw5
paper assignment of a paper that i didn't read,hi staff i was assigned a paper to review that i never read i'm not sure if i am supposed to review it or not i did the netflix paper while i was assigned a charu c aggarwal paper summary all in recommendation systems can someone get back to me on whether i am supposed to do this thanks,public,hw5
review post time says april th,i just revised a review and it marks its submission time as april th even though it is still the th i just want to make sure that won't cause a late day issue,public,hw5
can the tas releast homework,please release the hw my next week is hectic and i want to start on the homework early,public,hw7
deep neural network cnn,we talked about neural network in the past two lectures is deep neural network just the name for that neural network we've talked about for the past two lectures if there are more than one hidden layers and convolutional neural network which we talked about in today's lecture is a different thing from neural network aka deep neural network when there are more than one hidden layers,public,other
useful learning materials for students who use chinese,hi all it's always lucky to learn using mother language i found a few chinese translation of famous learning materials on web and i want to share them with you notes for stanford cs n https zhuanlan zhihu com p michael nieslen's neural network and deep learning https www gitbook com book hit scir neural networks and deep learning zh cn details bengio's deep learning book https github com exacity deeplearningbook chinese for general machine learning topics like why we solve dual problems in svm strongly recommended hsuan tien lin's mandarin videos and english slides would always clear most of the confusion you might have http www csie ntu edu tw htlin mooc hope it helps evan,public,other
loss function backpropagation,in general is loss function a function that we want to minimize and examples are mean square error or error itself actual our computed value moreover in today's lecture when professor gormley explained backpropagation example in the for loop when he wrote multiplication he sometimes used cdot and sometimes used x can someone explain why,public,other
peer tutoring,hi all please remember to contact your group asap and enter your group's regular meeting time and location into the google spreadsheet given in our peer tutoring post this should be done no later than friday april th if you are having difficulties contacting your group see best brynn,public,other
probabilities of different log reg on lec,on lecture from page to page there are some logistic regression decision boundaries with probabilities what are those probabilities and what do the decision boundaries separate respectively since gaussians mean categories to separate thanks,public,videos
explain the test error plot on lec,on page of lecture matt mentioned top layer vs bottom layer but i did not get it could someone tell me what they are and explain their importance thanks,public,videos
recitation deep learning,could you please arrange to record this recitation i have classes on thursday evenings due to which i am unable to attend recitations held on thursdays and this will perhaps be the most important recitation i am sure that there are more students who also have schedule conflicts recitations are very important in this course especially for getting to a good starting point on the homework and there is a lot of talk going on about homework being the toughest one i think if the recording is available it would be really helpful,public,other
midterm exam recitation solutions,could you please upload the solved paper during recitation on piazza we werent able to note down everything as it went fast,public,exam
do we need to deduct point for wrong paper title at the beginning of summary,dear tas one of the summary assigned to me is using wrong paper title as convolution networks for visual applications i don't think we have any paper exactly titled with this please correct me if i miss this paper anywhere do we need deduct point for this also do we need to deduct point if the summary contains pii like the student's name thank you,public,hw5
abhinav's office hours today,hi abhinav do you still have office hour at pm today,public,logistics
peer tutoring logistics,hi all some students have told me that they have not received any response from their peer tutoring group the following protocol has been created to help you to resolve these issues tutors who haven't yet contacted their groups should do so within the next h to arrange a meeting if tutees have not heard from their tutors by pm on april they should email the assistant instructors with their name andrew email and group number tutees are expected to respond within h of receiving an email from their tutor if no response is sent from a tutee within h the tutor may proceed to arrange a meeting time and location with the rest of the group please update the spreadsheet with your group's meeting information by midnight on friday april the meeting time and location on the spreadsheet should be that which is agreed upon by all members of the group you should not meet without first filling in the spreadsheet peer tutoring group information warm regards brynn see for more information about the peer tutoring program,public,other
hw when will hw writeup released,hi all as instructed in hw writeup we are supposed to build an end to end system on a specific dataset e g cifar i want to know the requirements soon so that we could start early because personally i don't have any experience in designing architecture for neural networks getting familiar with framework such as tensorflow tuning the architecture and hyperparameters more importantly reading papers cost time so is it possible to release the writeup for hw soon thank you so much for your time evan,public,other
expectations in the paper reviews,hi all in the paper evaluation we are supposed to assign a score and submit a review i wanted to know if there's any specific format for this review do we have to answer some specific questions in the review and explain the score how detailed should it be,public,hw5
subreviewer section,i just checked that in it says to leave the subreviewer section blank but i filled in my own name in the subreviewer section for my peer reviews and submitted them few hours ago will this be problematic should i resubmit them by clicking 'revise' with the subreviewer section blank thank you,public,hw5
scoring confusion for peer review,for the peer review i read a summary which is pretty good in all the sections data description task description etc but it looks like the author misunderstood an important concept of the paper because of this misunderstanding of the important fundamental concept i think the overall evaluation should be but everything else is good and i feel like that an overall evaluation score of will make the summary look worse than how it actually is could the instructors please let us know how these scores that we assign will be used because there is no way to give a score of is it okay if i give it and explain further in the evaluation report,public,hw5
subreviewer,do we fill in our own name for the subreviewer section on easychair when we are performing our review or do we leave this blank,public,hw5
qna,i calculated the principal components using the normalized data do i have to find the projection of the normalized data or the original data for finding the reconstruction error do i find the difference from the original data or the normalized data,public,hw6
qna convergence,i don't remember him saying in lecture that it might not converge and i couldn't find anything about that in other resources but i also don't remember anything about guaranteed convergence are there situations where it might not converge or even without specific situations can we not assume convergence,public,hw6
q qna can we use more than pc,can we use more than pc to modify the original dataset i intend to use the first pcs,public,hw6
qna use unbiased variance here,in qna we are asked to use biased covariance if nothing is mentioned in qna should i use unbiased variance,public,hw6
qna,the output of pca has to be in lower dimensional space i remember in lecture professor says although in most case dimension is lower but it may not be always lower however in the pca frequently ask question thread it says output of pca in qna is always in lower dimensional i am wondering which statement we should use,public,hw6
python error on kmeans cluster,did anyone come across this error on running kmeans cluster function with 'kmeans ' as argument typeerror 'numpy float ' object is not callable more specifically its in the line sq distances i min sq distances i sq dist to ix i haven't modified the method any hints on what causes this i'm running it on python jupyter notebook thanks edit never mind i resolved it,public,hw6
qna do we make judgement based on experience,i tried using different examples to get my judgement is there any mathematical way to prove the common distribution on different principal components,public,hw6
qna do we need to use the sequence of coin flips hthh,we are only supposed to find the expectation of zij for coin given a flip came out to be heads i think i can solve this using simple probability would we need to use the sequence of coin flips anywhere am i missing something that i should take care of,public,hw6
office hours pm today,hi all to make up for edwards cancelled office hours today at pm i will be hosting office hours in my office ghc thanks daniel,public,logistics hw6
neural net vs other classifiers,so neural network kernelized svm knn etc can handle non linearly seperable data as shown in lecture slides then what's the special thing about neural network that makes it better than other classifiers that can hande non linearly separable data such as kernelized svn knn thank you,public,other
lloyd's iteration convergence,how is the convergence defined here is there a threshold or it has to converge to the absolute zero thanks,public,hw6
update assignments compute the distance,hi should i use the euclidean equation to expand and compute the squared difference of each feature from each data point and the assigned cluster center or apply the dot product to the vector forms of the difference between the data point and the cluster center i obtained different results from the methods so i'm not sure which one is right please help thanks,public,hw6
neural net width,in neural network do all of the layers have to contain the same number of units,public,other
lost cell phone,hi all someone left a cell phone in class today i'm taking it now to the scs lost and found at ghc you can pick it up there at your convenience matt,public,other
objective function and updating centers,for the objective function for k means do we simply subtract the each point from the center they are assigned to and add up the distance like if point x with coordinates x x is assigned to center c with coordinates c c do we just say the objective functions is equal to x c x c,public,hw6
office hours queue,how long before the office hours does the queuing system open i am here now but the queue is closed so i cannot add myself in there's about more minutes before the office hour starts,public,logistics
qna biased variance,the question says for computing variance use biased variance formula not the unbiased variance formula what is bias here,public,hw6
goal of pca,i had the idea that the ultimate goal of pca is to find the intrinsic structure of data in terms of the principal components i am now confused after solving qna are we choosing principal components based on the components that best represent the data maximum eigenvalues and vectors and see if it does good on the future task in hand or do we choose those components that help us achieve better results on the future task in hand like classification k means clustering,public,hw6
qna,can i use one line of code which is a function within sklearn decomposition pca xb to get the original center of cluster or do i need to explain more,public,hw6
can i discard leading pcs and keep the others,if i want to discard to remove one or few of the leading pcs and to keep the rest instead of keeping the leading pcs and discarding the rest can i do that in pca,public,hw6
pca fit transform error,hello when i try to use pca fit transfrom in python it keeps giving me the following error valueerror n components must be between and n features with svd solver 'full' any ideas thanks,public,hw6
q determining whether pca can accurately classify data,i can see draw the principal components in these graphs but how can i determine if these principal components can accurately classify the data or not in class we did not look at using pca for classification so i am really confused about how to approach this are we supposed to see if the data is linearly separable in the new dimensions obtained after pca,public,hw6
q finding center of clusters for original dataset,could someone explain this question i'm not understanding what it's asking exactly thanks,public,hw6
a great intuitive explanation for pca,found this webpage and thought it is great cleared my questions about pca and variance http stats stackexchange com questions making sense of principal component analysis eigenvectors eigenvalues,public,hw6
why do not normalize standard deviation in recitation hw slide,for the normalization of pca data we should both normalize the mean and standard deviation why we only normalize mean for the data set,public,hw6
qna,is the first assignment of points and updating of centroids iteration or,public,hw6
how to approach q estimate zij for the coin flips,q asks us to estimate the value of zij are we supposed to use the likelihood function we derived in q if not how do we approach this problem,public,hw6
qna mnist x dimension,the writeup says each row of the data matrix represent a xd figure the values of features is the intensity of pixels reading this gave me the impression that each row of data will have x size but the writeup again says this will introduce a xd matrix mnist x where each row corresponds to a figure in the mnist dataset what am i understanding wrong,public,hw6
eigenvectors of the covariance matrix for pca,when trying to do pca i'm confused as to which direction the eigenvectors face when determining the axis of highest variance i feel like there are different sets offset by degrees that make sense is there something i am missing for generating the first and second principal components from data,public,hw6
q how can we find a generic value for,in question clustering we are asked to find the value of when n but won't these values depend on the actual data points will there be a particular and value combination that will work for all possible data points for example in d if my data has s s and so on upto s then the best answer will be k and center of each cluster in that case but if the data has s s and so on upto s then best value of k and center of each cluster in this case am i missing something can someone please explain,public,hw6
cannot run kmeans obj,when i submit to autolab i'm getting a cannot run function kmeans obj error my code is very simple so i'm confused where this might be coming from in fact the only functions i'm calling are ones that i used in other parts that are passing fine the only remaining thing seems to be a step where i use indexing is there any difference in the indexing between versions of numpy that might be throwing off my code,public,hw6
explained variance,i have a question about the attribute explained variance in sklearn decomposition pca i have tried the following calculations the matrix in the second line is data matrix x and the result is however the eigenvalue of x t x is as we can see the first two values in the answer of pca explained variance is of the first two eigenvalue of x t x while the third component is something different i wonder why the third component in pca explained variance is not which is of the third eigenvalue of x t x,public,hw6
qna whiten true or false,do we need to whiten the component vectors,public,hw6
pca dimension,is it necessary that pca always needs to be reduced to lower dimensions can they be computed in the same dimension,public,hw6
qna,for this particular question i want to find just pc can this pc be not the best pc the one that doesn't maximise variance,public,hw6
pca,hello prof in the pca lecture you mentioned that pca is not necessarily used for extracting lower dimensional data but can also be used to find a higher dimensional space in qna can we assume that we can use higher dimensional data in such cases,public,hw6
calculation to find eigen vector,hi when i am calculating the eigen vectors from the eigen values i am only getting the ratio in which the eigen vectors should be and not the exact eigen vector i wanted to know how i could calculate that thank you,public,hw6
question about recitation slide,should covariance matrix be calculated based on original dataset or the zero mean dataset it looks like the covariance matrix written on the slide is based on original dataset then why do we care about zero mean dataset,public,hw6
is the peer review anonymous,we don't know the authors of the summaries we review but do authors know who review their summaries,public,hw5
qna,hi all according to we are free to choose dimension when applying pca is that correct also it asks whether we can use pca representation of data to create a classification rule that has accuracy on train data to create a classification rule does it mean we should give a linear classification boundary thank you evan,public,hw6
qna q,for questions on pca especially questions do we need to consider kernel pca as well,public,hw6
qna why multiply,in qna all the choices show two multiply one over i to n we know this comes from maximum likelihood equation the second multiply over j to k my question is why this one is multiply not sum as what we learn from course,public,hw6
hw sumary review points for each sub section,after we write the summary review words and give an overall score do we also have to score each of the subtopics i remember that the hw handout said that we need to give a score to each subsection do we still have to do it if yes where,public,hw5
programming part the variable 'd',for the input data x a n x d matrix could someone explain what the value 'd' is for 'n' here is the number of sample points,public,hw6
biases in neural networks,does each neuron have it's own bias or does each layer have a single bias in the nn w hidden layer and hidden units the former case is true since both z's have their own bias but in the arbitrary feed forward network the latter is true since each level only has one bias,public,hw6
lloyd's method autolab grading criteria,i know we shouldn't rely on autolab grading to debug our code but i am wondering does the autolab grading base on accuracy of the cluster i kept getting of the grade and had no idea how should i improve my code i created a small test set consisting of points and clusters and obtained the correct results when i ran my code locally,public,hw6
in experiment,by report the mean of the k means objective value returned by kmeans cluster x init over runs do you mean run kmeans cluster x init times and then take the average of each objective value given,public,hw6
choosing k for kmeans,in class we talked about how we can plot k versus the objective for kmeans in order to find the elbow of the graph to choose as the proper value of k however sometimes this elbow isn't very clear or it almost seems like there are multiple elbows how do we choose k in these scenarios,public,hw6
cardinality case for update centers x c a,i'm just running some tests for my code do i have to worry about the case where none of the coordinates in x is part of a cluster c i if so what should the new cluster centers be taking the average of points will yield division by since there is no point in this cluster,public,hw6
gmm the variable z,i didn't quite get from where did the variable 'z' come into the picture gmm being unsupervised learning algorithm we do not know the labels so what is the significance of z pfa image,public,hw6 videos
can we import scipy package,hi i use python to do the coding part but sometimes i got i wonder can we use functions from scipy if there are some other packages that cannot be imported please let us know thanks,public,hw6
kmeans lecutre slide,cam someone please explain the k means algo refer the image,public,hw6 videos
lecture whiteboard file not found,in the schedule section of the course website the link for the lecture whiteboard is up but when i click the link it says file not found the site configured at this address does not contain the requested file could you re upload the lecture whiteboard notes please thank you,public,other
what's the difference between k means and lloyd s method,i'm confused about how those two method differs to each other could someone give some explanation,public,hw6
qna prob,for which observation coin flip i are we evaluating e z ij x i theta the question just says evaluate that when x i heads which is true for the st rd and th coin flips and j does the theta imply we're evaluating for the first coin flip i,public,hw6
no office hours tomorrow,hi all i need to cancel my office hours tomorrow morning friday at am they will resume as usual next week,public,logistics
python sklearn fit transform,i ran python sklearn's fit transform for the same dataset several times and i realized the reduced dataset is slightly different every time is this supposed to happen according to how python sklearn's fit transform works,public,hw6
paper review overall evaluation detailed comments,i can't find where to give the overall evaluation to the paper and where to write my comments and scores to each section,public,hw5
hw solutions released,hi all the solutions for homework are released you can find the hw solution tar ball on piazza resources page best,public,hw4
the evaluation of paper summary,as a summary i think we should and were told to keep the summary short however i find summaries that are three pages long and contain a lot of details equations and even graphs i wonder if i should deduct points because it does not look like a summary i am also afraid that someone will deduct my points because they write very long and detailed summary themselves,public,hw5
recitation for midterm exam solutions is scheduled,hi guys the midterm exam solution recitation is scheduled on next tuesday april pm at ph the recitation will focus on those questions that appeared in the midterm exam and a significant number of students got wrong on the schedule is also updated on the course website,public,logistics exam
paper not read,i found the review papers assigned to me are about papers that i haven't read does that mean i have to read those papers to understand,public,hw5
forget to add a name suffix when submitting my summary,what should i do i forget to add a suffix to my name when submitting my paper summary i didn't receive any review assignment,public,hw5
review assignment,we have assigned summaries to every student to review please log in your easychair account as a pc member and check you can review summaries if you cannot find your assignment please send an email to ssdu cs cmu edu including the following information first name same as your easychair account last name same as your easychair account email address same as your easychair account,public,hw5
qna,when you say you can use the principal component representation do you mean we can choose any of the eigenvectors or only the st eigenvector,public,hw6
progress check meetings,tomorrow is the last day for progress check meetings please go to if you still need to sign up,public,logistics
kmeans obj,for the programming part kmeans obj x c a i am confused what we are supposed to do do we calculate kmeans obj by finding the error between each training example in x and the center in c that it has been assigned to by a or do we use lloyd iteration first to get a resulting c a and then find the error between each training example in x and the center in c that it has been assigned to by a if so why is a initially passed in,public,hw6
what does num restarts signify,hi can someone explain what does num restarts signify in question in qna thanks,public,hw6
biased unbiased variance,can you give an illustration on biased and unbiased variance and why is it biased,public,hw6
missing notes,at my office hours today i was speaking to a few students about em and showed them some notes i had solving mixture models in d i think somebody must have walked out with them because they are now missing could whoever picked them up please return them to my office as soon as possible thanks brynn,public,other
vector representing the projection,in lecture notes and end of lecture video it says but a x cdot cos theta vec v t vec x x cdot v cdot cos theta we only need v in order to have a vec v t vec x why we need x,public,logistics videos
qna k means,for qna k means the options given are talking about right after the first step updating cluster assignments of the steps in the iteration right thank you,public,hw6
qna question,do we need to normalize 'the first principal component' do we need to make,public,hw6
qna prob,in qna problem is the first option the maximum likelihood estimates do not exist because there are latent variables in the likelihood function saying that there is no closed form for the mle thanks,public,hw6
pca dimension reduction normalize eigenvector,i was working out an example of the dimension reduction for pca using this which is in the lecture note where i use the eigenvectors right away when i used python sklearn decomposition it gives different projection values from what i found although the covariance matrix is the same as what i had and i think it's because python sklearn normalizes the eigenvectors i e make it have length before using as pc's for dimension reduction is normalizing the eigenvectors necessary for qna problems and do we have to normalize the eigenvectors or do we have to use the eigenvectors themselves,public,hw6 other
model v s objective functions,it's still unclear to me how models and objective functions are different could someone explain thanks,public,videos
easy chair review summary,while reviewing the submissions of other students i have written lines for every section describing how well did they explain complete the task but the review is nowhere near word range what else should i write in my review,public,hw5
elements of a integers or floats,should the elements of a be integers or floats,public,hw6
question about how to break ties,what does the first occurrence mean exactly so when ties occur should we remain the assignment as the previous one or change to the new one,public,hw6
pca output features,what exactly are the pca features is it the eigan vectors or is it the projection of the data onto the eigan basis and are these pca features considered the output of pca i thought the output could be many things a compressed image labels to test data ect thanks,public,hw6
paper assigned,i've been assigned two summaries in easychair and one of them is not the summary of the paper i read before am i suppose to review these two summaries,public,hw5
feature value,in qna problem what is a feature value thank you,public,hw6
pca with max number of pc's,for a m dimensional space if we use pca with m many pc's i e use all the pc's will the data points projected into those pc's look the same same locations as the original dataset in the original m dimensional space,public,other
lloyd's method performance gaussian,for k equal sized gaussians pr each initial center is in a different gaussian why is each cluster called a gaussian what are the features or properties that a gaussian has but a normal cluster of points does not thanks,public,videos
gmm meaning,what exactly does mixture mean in gaussian mixture model,public,other
qna problem,in qna problem does you can use the principal component representation of the data to create a classification rule that has accuracy on the train set mean that if we project the given training data points in dimension into the first pc defined by how pca works i e into dimension then in the new dimension space the training data points are linearly separable,public,hw6
please make sure the last name of your submission is correct,hi all i noticed that many of you do not have prefix before your last names in your submissions please take a minute and make sure you have the right prefix as in to change your last name you can go to update author thanks,public,hw5
peer tutoring,hi all for those who are interested we are going to offer a peer tutoring program anybody who signs up to participate as tutors tutees in the program must commit to meeting once per week at a publicly disclosed location time for min a week to be eligible as a tutor you must have received an official pessimistic letter grade of a or above if you are interested in the peer tutoring program you must sign up by friday march if you are interested in being a tutor or tutee please complete the form below tutor tutee sign up warm regards brynn edmunds,public,logistics other
questions about pca,in the example in this slide how many pc's would we decide to use let's say we have an original dataset with m dimensional space and we decide to use d many pc's d m suppose we computed the d many pc's then how do we achieve our ultimate goal of projecting our original dataset which is in high m dimensional space into the lower d dimensional space i e what do we do to each of the data point in our original dataset using the d many pc's,public,other
progress check meetings update,hi all there has been broader demand for the progress check meetings than expected while it'd be great if we could meet with each of you individually there just isn't time to do so our primary goal with these meetings is to chat with students who might be falling behind to figure out how we can help them and discuss their options particularly with the pass fail and drop deadline coming up next week i'd like to emphasize this priority two updates if you received a b or higher on your official pessimistic midsemester grade please refrain from signing up for a progress check meeting thanks for your understanding we just updated the sign up sheet with new availability for the next few days see for details note that the assistant instructors brynn daniel and sarah are full time staff in the machine learning department they are great people to chat with cheers matt,public,logistics
k means attains o logk approximation,k means always attains an o log k approximation to optimal k means solution in expectation can someone help me intuitively understand what this line means what does in expectation mean it's in the lecture slides,public,videos other
cannot understand what the auto grader is displaying,hi my program for updating assignments is working on my octave and i have uploaded it correctly but autogravder is giving me an error as below what should i do about it thank you bad cannot determine your programming language from your source files hint did you write your answers in the same programming language and name them properly traceback most recent call last file grader py line in main file grader py line in main raise exception submission error exception submission error make all error score for this problem,public,hw6
efficiency of code,will we be graded on efficiency of our code can i have for loops in functions like update assignments or do i have to do everything with numpy in built functions thanks,public,hw6
requiring explicit agreement to policy everytime for autolab submission,can instructors take a look at autolab it's asking me to agree to the hw policy everytime for submission i see where it is coming from but pretty annoying and unnecessary anyway,public,hw6
autograde for lloyd itr,for autograder for lloyd itr function i keep on getting about correct but are they scoring me on vector a or matrix c or both of them,public,hw6
lecture em pca,why does x have to be for the length of projection only the vector v needs to be a unit vector proj overrightarrow x on overrightarrow v overrightarrow x cdot widehat v,public,videos
order of updating centres and assignments,in implementing lloyd iteration x c should we update centres first then assignments or should it be the other way round that would change the result right,public,hw6
initializing c,hi when we testing the functions using the script file x could be imported from the csv file but what c should we use since different c will give us different output thanks,public,hw6
qna what does it mean by saying represent them in the original d space,does it mean the reconstructed points are points that are projected to single line by the original points,public,hw6
update centers,in updating the centers shouldn't we divide the sum of points in cluster i by total number of points in cluster i instead of c i,public,hw6
problem about gda,hi all in the lecture professor compared gaussian naive bayes gaussian discriminant analysis and gaussian mixture model as for the model of gaussian discriminant analysis it is a joint distribution but as we studied before midterm we just need marginal distribution as the model of gda another question is the method to train gda professor mentioned we can use close form but as for one of discriminant analysis the logistic regression we can not use close form so i wonder how to determine whether we can use close form or not,public,hw6
lecture em pca,if we use x mu k p instead of euclidean distance in em algorithm e step and increase p we will end up with the k means model for gmm right,public,other videos
easychair invitation as a pc member,we have sent invitations from easychair system please check your easychair account to see if you can log in as a pc member if not please send an email to ssdu cs cmu edu including the following information first name same as your easychair account last name same as your easychair account email address same as your easychair account,public,hw5
cannot run function lloyd iteration,hi all i submitted the hw python file to the autolab it gave me the feed back like this step start running your program running update assignments running update centers running lloyd iteration cannot run function lloyd iteration running kmeans obj step start checking the correctness however the lloyd iteration function is running correctly on my laptop i have the initial cluster center input like c np array and the function can output a reasonable c and a how can i do with it,public,hw6
gaussian naive bayes decision boundaries,i have few pointers to make about the decision boundary for gnb and logistic regression please correct me if i am wrong if there is only one feature x the decision boundary for gnb will be linear perpendicular to the x axis but might not be the same as logistic regression if there are multiple features x xn but the probability distribution with respect to all except one feature is same for all the classes the decision boundary of gnb is still linear same as case i e perpendicular to the x axis but might not be the same as logreg say p x i y j g mu ij sigma ij then that means that mu ij mu ik and sigma ij sigma ik for possible values of j and k and for all i n if sigma ij sigma ik for all possible values of i j and k i e shared sigma the decision boundary of gnb is linear and exactly the same as of logreg for any other case the decision boundary for gnb is non linear,public,other
wednesday whiteboard note,hi i was wondering when the whiteboard note for wednesday lecture about em and pca will be posted thank you,public,logistics
error in kmeans py,the function kmeans cluster outputs no such module if an incorrect init param is passed however in python calling print no such module throws an error the call needs to be made with parenthesis print no such module this is a small issue but figured it was worth pointing out the question i have is should we be using python or python for this assignment,public,hw6
lecture whiteboard,the whiteboard for lecture is not posted on the course website but would be very helpful when completing the homework is it going to be uploaded,public,hw6
question,why is the gaussian naive bayes able to perfectly separate the data shown i am confused because i thought that naive bayes was a linear classifier in the feature space and i see no way in which the presented data would be linearly separable unless you augment the feature space thanks in advance,public,exam
variance covariance matrix in class video,in the class video should the variance covariance matrix below be n xx t since data in x matrix is defined in column,public,videos
submission query for hw,hi in hw its mentioned that we can only submit times on autolab if we reach submissions than only the last submission will be considered for scoring is it possible to score on the maximum score received from any of the previous submission rather than only considering the last submission thanks,public,hw6
aws credits,can we aws credits by the end of this week so that we can start learning how to use cloud services and how to train models on aws i will be working on how to use cnns for image classification computer vision,public,other
midterm and,the answer to question is not shown in gradescope what should be the correct answer and in question why knn is a probabilistic model,public,exam
hw unsupervised learning,hi all homework has been released and is due april at pm the handout of which you can download from autolab and piazza resources the assignment consists of parts a qna section and an autolab programming section read the instructions carefully and be sure to submit everything to the correct place there will be a recitation covering materials in this homework next tuesday on march at pm in ph also be sure to fill in the collaboration questions found at the end of the qna questions too good luck,public,hw6
midterm,in question in midterm when the svm for n points has exactly support vectors why adding a new point leads to n support vectors and why this is the most possible case thanks,public,exam
keywords,the keywords should simply be keyword keyword keyword right or am i supposed to use actual keywords from my report,public,hw5
can we submit the summary paper late on easychair,i wanted to know what is the late policy for this assignment,public,hw5
hierarchical clustering,did we learn and so have to know hierarchical clustering,public,other
progress check meeting,will there be any more progress check meeting available from now on https docs google com spreadsheets d b nsutex am so rrto vuvc wknx paeemze m y edit gid,public,other
changing categories from hw to hw,this is a question to instructors suppose i write about an nlp based dataset and review a paper in this domain can i work on say a computer vision problem in hw,public,hw5
midterm exam score,where can i check the score for my midterm exam,public,exam
em algorithm,i was a bit confused when we talked about the em algorithm in today's lecture in each of e step and m step what exactly is updated the overrightarrow theta or overrightarrow theta ' thank you,public,other
submitting hw pdf query,hi could you please confirm we can just write the summary in a word document then save it as pdf and upload it to easy chair or do we have to submit it using latex,public,hw5
question about the name of the pdf file,could i use hw summary as my name of pdf or is there any required format for naming our pdf file,public,hw5
office hours today,i am running a few minutes late for my office hours today due to a meeting sorry for the inconvenience best brynn,public,logistics
matt's office hours this week,hi all in order to make more time for the progress check meetings i will be canceling my usual office hours this thursday feel free to drop in on any of the other tas during their office hours if you have questions about course material cheers matt,public,logistics
recommender systems,what is the difference between neighboring methods and latent factor models,public,hw5
question about the length of the summary,hi sir could i write my summary in two pages it is very difficult for me to write all the stuff within one page will i be deducted any point if i write my summary more than page,public,hw5
error accessing computer vision paper,i'm having trouble accessing computer vision paper sun database large scale scene recognition from abbey to zoo when i try to access the page it's giving me connection reset and connection timeout errors i get the same errors when on campus network through vpn is anyone else experiencing these errors,public,hw5
k mean algorithm initialization in clustering,does number of the clusters centers depend on how you initialize the cluster when using k mean algorithm and the algorithm itself can't determine the k value in the example of lloyd's method shown in the class why do we choose centers instead of or or other numbers,public,videos
late day penalty,hi in my gradebook in autolab i see a late day penalty for hw final score i dont understand whi it is there as i didnt take any late days thanks,public,logistics
how can i ensure my understanding of the material is at the expected level,my math background is really weak and often i don't know what level of understanding i should achieve for the covered materials could someone give me hints on what type of things i should pay attention what are the signs that xx section is really important for the course plus what level of granularity i should know millions of thanks in advance,public,other
progress check meetings correction,hi all the original hyperlink for the google form included an extra parenthesis here's the corrected version fill out the progress check meeting form https goo gl forms tjmki bvp lwixma see the rest of the instructions here also just a reminder that these meetings are not required cheers matt,public,logistics
progress check meetings,hi all if you are interested in a one on one meeting to discuss your progress in the course and performance on the midsemester grades please sign up using the two step process below fill out the progress check meeting form https goo gl forms tjmki bvp lwixma at the end of the form you will obtain your progress check meeting code for use in step the form should only take you a few minutes please read through and before filling out the form schedule an appointment by selecting an open time on the progress check meeting sign up sheet https goo gl f o eg be sure to include your andrew email and your code from step this one on one meeting will either be with me matt or one of the assistant instructors brynn sarah daniel as indicated in the sign up sheet we've already received a large number of requests for meetings so we're keeping these to minutes initially of course if for some reason minutes isn't enough to address your concerns don't worry we'll just schedule a second one we'll post only limited availability initially and add more slots as the schedule fills up and the forms come in below i've included a few broad categories of progress and how it fits in with these meetings cheers matt category a your midsemester letter grade was the grade you want or close to it keep up the good work there's probably no need for us to meet right now however i strongly encourage you to consider signing up to be a peer tutor your contribution there could really benefit others details to come category b did well on homework did poorly on midterm exam if you're keeping pace with the homework my hope is that you'll be able to improve your performance on the final exam most likely our first question will probably be how did you do on the background test if you didn't do well i'd encourage you to spend some extra time brushing up on the prerequisite material as i noted in this seems to be absolutely essential if you did well on the background test then we should discuss studying strategies and how you can better prepare for the final exam category c did well on the midterm exam did poorly on the homework if you demonstrated a strong understanding of the material on the midterm exam we are optimistic that you have a strong grasp of the material most likely our first question will be what aspects of the homework are giving you trouble do you struggle with the programming problems do you struggle on the written qna portions is your course load too heavy to allocate sufficient time to the homework for this course hopefully you can figure out now how to ensure that you improve your performance on the remaining assignments and then do just as well on the final exam category d did poorly on the midterm exam did poorly on the homework we certainly want to chat with you if you fall into this category as with category a we'll probably want to check in with you about your performance on the background test however we'd also like to know whether there's something else that's holding you back this semester it'd be good to get the bigger picture of what aspects of this course have been challenging for you as i noted in monday's lecture if you are still in the course at this point we really want you to make it to the end successfully however we might also want to chat about alternative options such as taking the course pass fail or auditing please be sure to keep an eye out for the peer tutoring sign up which will be coming out soon category e did so so on the homework did so so on the midterm exam whether you'd like to meet now to chat about your progress is up to you we would certainly like to prioritize students in categories b c d but we're happy to meet with you as well to see how we can make this a successful semester for you,public,logistics
hw citar,i should write about this dataset in section one but i am wondering whether should talk about format if both python verison and binary version since after i write binary version the total number of words is more than on space for question sections thanks a lot,public,hw5
question on the word limit,does the word limit on the summary include the words in the dataset description for hw as well i think a detailed description of the dataset might itself take up over words just to answer the questions about the dataset in the handout so i am a wondering whether to discount the dataset description word count or reduce the detail of the dataset description,public,hw5
optimistic midsemester letter grades,hi all as mentioned in class on monday and in your official midsemester letter grade was a pessimistic projection of the possible letter grade you might achieve in this class the lowest quartile of the grades were most affected by this choice a contrasting approach to assigning letter grades would be optimistic by assigning you the letter grade that you would receive if today was actually the end of the semester and this was all the grade information we had both approaches are deficient in their own ways however you could perhaps view the two letters as a narrow confidence interval around our estimate of your letter grade you can now view these two versions of your midsemester letter grade in autolab go to your grade for the assessment midsemester grade then click the numerical value to see the feedback this will show a pop up with a message such as pessimistic letter grade b optimistic letter grade b for about of you these will be identical but the rest may see some difference for a few of you the range may be very large if that's the case i strongly encourage you to take advantage of the progress check meetings which i'll be announcing in a subsequent post cheers matt,public,logistics
access to movielens dataset paper,i am unable to access this paper describing the movielens dataset in detail maybe it is because i am not on campus are others able to access it is there someway i can access it from outside campus http dl acm org citation cfm id,public,hw5
summary questions about the paper,is this subsection compulsory to be written because i did not have any particular questions about the methods experiments used in the paper also the review grading does not talk about grading this particular section it talks about overall readability instead please let me know thanks,public,hw5
question about reference,hi sir i am writing the paper summary and found there is a line in the template in the data description if you want to cite some papers what is the purpose of this line if i only reviewed the paper provided by the hw pdf do i need to write anything about citing paper,public,hw5
chunking with support vector machines related,hi for hw do i have to implement svm on the data or can i treat the svm as a blackbox like using the software package tinysvm thanks,public,hw5
parameters are coupled,i heard the expression parameters are coupled in naive bayes logistic regression on lecture and and parameters are coupled in marginalization in unsupervised learning on the slide of learning a mixture model on lecture what does being coupled mean under the models does being coupled determine the type of solution that the estimator would have also on the slide of learning a mixture model on lecture the parameters decouple mentioned under supervised learning why here the parameters decouple but supervised learning methods i e naive bayes and logistic regression are mentioned to have parameters coupled earlier could someone break down the coupling and decoupling for me thanks,public,other
understanding the dataset,i have properly understood most parts of the paper and am working towards the summary but when i went through the dataset i found it a little confusing come hw will it be possible to take help of tas for getting more intuition on how to actually use the dataset thanks,public,hw5
how to interpret my grade,i have got a b in midterm however people from my dept have got a b and b how do i interpret my grade then,public,exam
how specific does this summary need to be on the mathematic model,as the title says how deep do we need to go in the context of mathematic model or algorithm,public,hw5
questions about matrix factorization techniques paper,hi in the part of additional input sources i didn't quite get the idea of the normalization of the sum of x i besides why sum of y a doesn't need normalization thanks,public,hw5
hw frequently asked questions,hw importants updates and frequently asked questions faq note these are regularly updated list of questions that might be helpful to know q for questions and on qna do we need to normalize the principal components a yes q for question on qna do we assume that all points are distinct a yes q for q q q what do we mean by pca representation a by pca representation we mean that you have the principal components of the data you can use them in any form to come up with a linear classification rule for instance projecting data onto the principal components can be one such form q for q what do we mean by pca output a by 'output of pca' we mean the original data on which you computed pca in the lower dimensional space q what's different between principal component pc and principal component representation a principal component say the st principal component is the eigen vector of the covariance matrix with the largest eigen value and for principal component representation let x in mathbb r k be a single observation in our original dataset say that we chose to use the first pcs to represent x i e x p pc cdots p pc for questions and we are using the first pc alone hint why are we using only the first pc,public,hw6
syllabus for final exam,would the final exam have pre mid term syllabus or only the post mid term portions,public,exam
recommender systems,hello i hoping someone could clarify what should be included in the results section for the review of these readings since they are from a textbook and not a journal article thanks,public,hw5
hw is using latex mandatory,hi so the homework mentions that the summary submission has to be in the pdf format and that latex is recommended i was wondering if it was absolutely compulsory to use latex or we can write our summaries using something else and then submit it as a pdf thank you,public,hw5
office hours postponed,hi all my office hours today at today have been postponed and will now take place at am on wednesday i am sorry i have to cancel so abruptly i have a meeting with matt thanks daniel bird,public,logistics
questions about matrix factorization techniques paper,i am reviewing the nd recommender system paper matrix factorization techniques for hw this paper uses netflix prize dataset but hw is about movielens dataset so in question data description i should describe the movielens dataset not netflix dataset right in the rd question method should i present the equations that they developed in the th question results they have not reported results like accuracy precision recall etc they just said that they were able to do better than netflix so what should i discuss in the results the paper has some charts figure which are helpful to explain the intuition method results can i include these charts in my report or am i supposed to create my own charts if i want to include,public,hw5
mid term exam regrade request,is there a deadline before which we need to submit the regrade requests if any for midterm papers thanks,public,exam
hw recommender systems mean centering,in recommender systems chap mean centering is performed in both user based and item based neighborhood methods in user based method to mean center the mean rating of the user is subtracted from all his ratings similarly for item based methods the text says the average rating of each item in the ratings matrix is subtracted from each rating to create a mean centered matrix however in the example following this description section for item based methods table is used in which the mean centering is performed by subtracting the user mean rating as in user based method instead of subtracting the mean of an item as in item based method will this have any impact on the results or am i misinterpreting anything,public,hw5
data set in hw,i want to write a summary about the sun paper although i have viewed the question about data set in computer vision but the data set cifar what we should use in hw is not related with scene classification at all i am wondering what is the problem we should solve in hw with this data set what will be the challenge using such a data set it seems to me that using this data set we can only solve the problem classify the picture with this categories,public,hw5
does anyone meet this error when compiling latex,traditionalbuilder engine pdflatex invoking latexmk could not compile attempted command latexmk cd f pdf interaction nonstopmode synctex hw template texbuild engine traditional builder i have just installed mactex and try to use sublime to compile the latex file however i met this problem and i don't know how to resolve it does anyone see this issue before,public,hw5
grade statistics as of midsemester,hi all below are some detailed statistics about the background test homework midterm exam and midsemester grades for some of you seeing these detailed statistics may be an additional source of stress this is not my goal rather i am hoping that by better understanding your standing in the course and some trends across the our incredibly varied student population you'll have more insight into how to improve your learning of the material going forward hopefully it will also facilitate any advising conversations we have more on this to come importance of prerequisite material first let's highlight two key observations performance on the background test was predictive of performance on the midterm exam the pearson and spearman correlations which measure linear and rank correlation respectively were both in the moderate range see the scatter plot below by contrast performance on the homeworks exhibited only weak correlation with midterm exam grades these two observations are in retrospect not too surprising regarding if you have a strong grasp of calculus linear algebra probability discrete math and computer science then you have several advantages first you are more likely to keep pace with the lectures themselves when i write out some tricky formula you are able to see past the complicated math and understand the new idea or insight related to machine learning second you are less likely to get stuck on the exam if you can't recall how to apply the chain rule of calculus or probability you might not be able to complete an otherwise straightforward problem for which you did understand the machine learning regarding the homework distribution is strongly left skewed and thus contains comparatively little information about the how well you'll be able to quickly recall and apply the material thus it's not a great predictor of midterm exam performance i make this point to in order to again emphasize the importance of the prerequisite material put another way time you spend reinforcing the basic and advanced concepts from the prereqs is time well spent midterm exam an observation most of you guessed this year's midterm exam was very challenging last semester the midterm exam in b was shorter last year mins this year mins but the median was about percentage points higher last year this year we take this into account when assigning letter grades that is we do adjust to account for the difficulty of assignments and exams the histograms for various grades are below letter grades for the midsemester letter grades i did not give you the letter grade you would have received if these were all the grades we had for the whole semester instead i decided to give a pessimistic projection of the possible letter grade you could receive the lowest quartile of the grades were most affected by this choice if i were to summarize the distribution over midsemester letter grades had a heavier tail i e more cs ds and rs than i expect for the final semester letter grades i'll say more about this in a subsequent post so you can hold off on questions for now there's a lot of details here but i hope it's helpful nevertheless cheers matt correlation between homework average and midterm exam pearson weak moderate spearman weak correlation between background test and midterm exam pearson moderate spearman moderate stats about the background test these aren't new just reiterated for reference max median mean stddev stats about the first homeworks avg max median mean stddev stats about the midterm exam max median mean stddev stats about the midsemester weighted grades max median mean stddev,public,logistics
page limit or word limit,is there a limit of one page or words on the review in the template given words goes a little above the one page limit of we have say equations are we penalized for going above page or words or either or is it a soft limit,public,hw5
citing,how often do we need to cite the paper we are summarizing if we are to have citations for every summary point it looks like we would have to cite every line because we are summarizing one paper which seems like over kill and would just clutter the text thanks,public,hw5
update hw importants updates and frequently asked questions,note these are regularly updated list of questions that might be helpful to know q do i need to read the paper of the summary assigned to me a no but if you are assigned to a summary of a different topic please let us know q should i deduct points because the summary is too long a hi all i hope you are enjoying your spring break a hw latex template is uploaded in resources https piazza com cmu spring resources q what if i forgot to add a prefix code when i create the account a you can change your last name at easychair top bar my account you only need to make sure when you submit the summary your last name has the prefix code you can change the last name of your summary sunmission through my submissions information update authors in the google doc form you filled out your last name has the prefix code if you forgot to do you can simply submit another form q do we have to use latex a it is not mandatory the template is for your convience q can we change the latex template a yes q is citation mandatory a no q is it ok that my summary has more than words more than one page a yes that is a soft limit we wouldn't count your exact words it is fine that you leave some space between sections and give us a two page summary but if you have two closely typed pages and it is clearly over words you may want to make it shorter,public,hw5
forget to add prefix code on lastname during applying the easychair account,hi i forget to add prefix code on lastname during applying the easychair account and i have click the confirm email now the system say that you have previously made attempts to create an account it is possible that you did not receive a previous mail from easychair please read the following information carefully so what should i do now thank you,public,hw5
recitation schedule changed,the recitation originally scheduled for march is moved to march location and time are the same the schedule on the course website will be updated as well soon thanks and have a great spring break,public,hw6
recommender systems pdf access,hi how are we supposed to access the charu aggarwal pdf for recommender system do we have to buy the textbook to have the access or there is some alternative i am missing to access the chapter reading,public,hw5
questions for mid term,are we allowed to discuss mid term exam on piazza now,public,exam
question about hw computer vision task,in the first question data description what is the dataset you will use for hw it's asking the dataset i will be using with respect to the homework requirement i will use cifar but this is a paper review and the paper i choose might not use this dataset instead they are using mnist in a more specific case in the third recommended paper improving neural networks by preventing co adaptation of feature detectors it's using both cifar and mnist so i am wondering which dataset i should describe for this answer,public,hw5
final grades,will the final grade be an addition of all hws exams and then curved or will it be mid sem grade curving of the remaining hws final exam,public,exam
results of convolutional networks and applications in vision paper,i don't see them mention the method that they proposed in the results on object recognition generic object recognition using caltech dataset handwritten digit classification using the mnist dataset connection with other approaches in object recognition sections am i missing something the method they proposed was psd but i don't see that mentioned in these sections they do mention that supervised fine tuning consistently improves the performance and results on abs and normalization which were also proposed solutions but they don't mention the specific method that they proposed am i missing something,public,hw5
hw latex template,can we have a latex template for hw report submission,public,hw5
hw hw continuity same topic,if we choose nlp for hw do we have to do the nlp task for hw or can we swith over and do the recommender systems task for hw,public,hw5
midterm test grade distribution,hi could you give the mean median of this midterm test thank you,public,exam
mid sem grade components,i just wanted to confirm this is our hw score a component of our mid sem grade edit i see that it has been answered sorry for the redundancy,public,other
grades on autolab,hi all grades for total homework score total homework score and mid semester have been released on autolab your mid semester letter grade is in the feedback of the mid semester score assignment course staff,public,other
sio grade,does the sio grade include the hws so far as well or is it just the mid term exam,public,exam
qna,i think the points in kernel space will look something like this where the red points represent and the greens represent how is this data linearly separable with only one decision boundary,public,hw4
midterm solutions,can someone post the solutions for the midterm exam,public,exam
total homework scores midterm calculation statistics,hi where can i see the total scores for each of the homeworks till now my gradescope does not show the scores for homework have they been included in the calculation for grades also will the mean median statistics be published for this midterm to have a better idea of the marks thank you,public,exam logistics other
midterm score statistics,is it possible to see the midterm score statistics i mean the statistics for the actual mark of the midterm paper as this test is very difficult i kind of have no idea whether i did well or not even after reviewing my paper in the gradescope it will be even better if it is possible to see the statistics for each question thank you,public,exam
grade distribution,just out of curiosity matt mentioned that day in class that usually he assigns a's to half of the class and b's to the other is this standard applied to this class as well will we be informed of the average of the midterm,public,exam
curving for mid sem grades,i read that mid sem grades were curved were undergrads and grads curved separately becuase i have read somewhere that grads and undergrads are graded separately,public,exam
where can we view our midterm grades,question in heading,public,exam logistics
exam paper viewing,i see that our grades are out in sio when can we see our exam papers,public,exam
midsemester grades,hi all midsemester grades will be released by monday at pm students who are registered with either a pass fail or audit letter grade option may receive their letter grades earlier these letter grades are one mechanism for us to give you feedback about your standing in the course in general my attitude towards midsemester grades is that i would much rather have you say uh oh about your grade now while there is still time to do something about it rather than at the end of the semester in addition to the official midsemester letter grade we will also post additional aggregate grades on autolab more details about this to follow ultimately i want you all to succeed here at cmu if you do not receive the grade you were hoping for i encourage you to consult with me before simply dropping the course in particular i plan to follow up individually with students who seem to have fallen behind there are other options such as taking the course pass fail or for audit that may be a good fit for you and ways to get additional units via mini courses if you do need to drop lastly i'd certainly like to have your feedback on how we could have better prepared you for this challenging course to those of you who are excelling in this course of course we also want to hear your perspectives of course you are always welcome to drop by my office hours to chat thanks to those of you who already have cheers matt p s some important dates related to grades course add drop deadlines etc are below march mid semester grades out by p m march spring break no classesmarch mini course add deadline april semester course drop and pass fail grade option deadline assign withdrawal grade after this date,public,logistics
do we have server for us to train algorithm for hw and hw,i find that computer vision problem needs deep learning algorithm and most of time it is time consuming i just wonder will we run our algorithm in our own laptop or we have other servers for us to train our model,public,hw5
hw researching applications of machine learning,hi all homework has been released and the first part is due at pm and the second part is due the handout is in piazza resources the assignment consists of parts for the first part you will read a paper and submit a summary via easychair see for the second part you will write reviews of peers' papers details of submission format can be found in the handout update we provided a latex template in piazza resources good luck,public,hw5
cannot find hw,hi i cannot find hw at https www cs cmu edu mgormley courses s coursework html has that been released thanks,public,hw5
matt's office hours thu,hi all my office hours tomorrow thu will be am am am pm cheers matt,public,logistics
do not discuss midterm answers,hi all please do not discuss answers or content from the midterm on piazza until the grades are out as some students have yet to take the exam thanks,public,exam
allowed to share cheat sheets,can someone else use my cheat sheet,public,exam
map and mle generative and discriminitave,from p y x theta p yx theta p x can we say that discriminative is the map version of generative,public,other
perceptron mistake bound,theta k sum y i cdot x i only if the perceptron has made mistake on every example right,public,other
optimization do all these algorithms give us a global optimum in all cases,linear regression logistic regression l regularization l regularization svm with a valid kernel,public,exam
support vectors,is any point which has a non zero slack variable considered to be a support vector in the svm algorithm in particular are misclassified points considered to be support vectors,public,exam
convergence hw,in hw we are asked the number of epochs for the different algorithms to converge however no definition of convergence is provided i have assumed the float precision of python on my machine i e convergence means two consecutive identical loss readings with python float precision why is this not correct,public,hw3
bayes optimal classifier midterm,will the content covered in lecture about this be on the midterm it isn't on slide topics for midterm of the midterm review slides,public,exam
how to determine a kernel is not a valid kernel how to tell whether it's linear separable,i wonder if i can ask for solutions of homework qna question and but if not what is a general approach to solve these kind of problems i know if we can rewrite it as the dot product of some transformations of the two vectors it means it's a valid kernel but if we cannot come up with such transformation we can't say such transformation doesn't exist then how to show the function is not a valid kernel,public,exam
class video questions,i have watched the review video for yesterday's class i have some doubts about a sample question picture below i think that naive bayes makes the assumption of conditional independence and that p x x y p x y p x y p y and the answer is true however the professor omitted the p y and came up with the answer false can anyone tell me why below is the picture highlighted part,public,exam
mock test,if a and b are disjoint are they independent or dependent events,public,exam other
definition of a validation set,i think i know what training error and test error is but i don't really understand what exactly is validation error i guess it means the error rate calculated from validation set but then what is validation set is it a random subset of the training data set thank you,public,exam
lecture slides,hi everyone in the comparison of naive bayes and logistic regression in lecture 's slides i am a little bit confused by the meaning of x and y axis what does m represent for and how to define the error here thanks,public,other
l regularization is l regularization even used,it says subset selection can you give an example as to where it might be being used,public,exam
l regularization where does subdifferentiability pose a problem,we are able to obtain l regularization for both logistic and linear regression q so then where exactly does the subdifferentiability pose a problem q do we use regularization in non linear models as well how is it possible to add regularization to naive bayes i guess via the prior or svm via the c or gamma parameter,public,exam
do we need calc for midsem,do we need calc for midsem,public,exam
invitation to guest lecture on pac learning,hi all this friday a visiting lecturer nakul verma will be giving a self contained minute lecture on pac learning and sample complexity this is a topic that we will get to later in the course but i suspect you will all really benefit from seeing the material taught from a different instructor please rsvp using the google form below if you would like to attend the nakul verma's guest lecture on pac learning friday march th pm pm the location will be announced to those who are definitely able to attend note that there is limited seating available so depending on how many people would like to attend i might have to ask only a subset of you to come sorry in advance if that happens https goo gl forms alswzwqekwstyvbf if you are not interested no worries you don't need to fill out the form cheers matt,public,other
hard vs soft margin svm,shouldn't c infinity correspond to hard margin instead of c because c infinity will force the slack variable to be hard margin constraint,public,other
lecture,hi could anyone please tell me why the standard kernel space being k instead of because of absence k thanks shouldn't we consider the absence characters as well i thought we were going to consider all combinations,public,exam
the past question,will the argument maximum number of mistakes will decrease as the r gamma decreases apply to the svm too and will it get me full credit for this question screenshot eskmnj png,public,exam
s midterm exam problem b,i think the third case that the margin doesn't change only happens when all slack variables are which means the data is linearly separable however it is mentioned in the question that the data are not linearly separable as a result i think the third case cannot happen is there any example that when the data is not linearly separable such that the slack variables are not all the margin is still unchanged when we modify c thanks,public,exam
kernel perceptron online vs batch,in the lecture note it says kernel perceptron in online learning is homework says the kernel perceptron for batch learning is for the input of the sign function in online learning is there a reason we don't include the y r that we include for the batch learning,public,other
lecture learning theory,i have two questions regarding this graph shouldn't p y x p y x can you give me an example where given p y y x p y y x we still predict y y we for sure don't do this in naive bayes logistic regression,public,other videos
question about residue in linear regression,hi i think the residue down in the screenshot below is not correct in blue line it should be red lines instead am i right thanks from whiteboard b,public,other
can naive bayes incorporate discrete and continuous features,hello i know we have bernoulli naive bayes and gaussian naive bayes is it possible to let naive bayes incorporate both discrete and continuous random variables where p x y gaussian and p x y bernoulli by the way i assume logistic regression can do both discrete and continuous features at the same time since we are just training on a weight vector thanks,public,exam
hw solutions,isn't the last time to turn in hw for credit tonight on the th yesterday today tomorrow qna says it's due tomorrow night and it would be really helpful if the solutions to the qna questions were available tonight can you change the deadline,public,hw4 exam
is true error validation error,what exactly is true error,public,exam
can we have the video for today's review lecture posted,the video for today's lecture is not yet posted,public,exam
what exactly is a closed form solution,its been used often but what does it exactly mean,public,exam
bias variance tradeoff,we have not covered the concept of bias and variance in class would i need to study these topics for the exam,public,exam
extra scratch paper during exam,will we be provided with additional scratch paper will i be permitted to bring blank sheets for rough work,public,exam
sample midterm q c d,in the recorded lecture matt marked the answer for d as false but the sample solutions say d is true i am not sure what the right answer is can someone clarify this p x y x p x y p x y p y this is the simplification that matt used in section b whereas he did not multiply by p y in section a i am a little unfamiliar with this property is it chain rule should i assume the method used in the recorded lecture to be incorrect,public,exam
why would you want a sparse solution,uses l regularizer leads to sparsity why would you want this,public,exam
big o notation question,can anyone explain the correct answer with reasoning to me all of the options seem correct,public,other exam
sample complexity,have we learnt sample complexity i saw it on one of the slides but not on another slides,public,exam
linear regression x tx non invertible,what should we do when x tx is non invertible thank you,public,exam
practice test b and c,hello i have two questions on the practice exam solutions b i thought this would be false as we do not know if the kernel is symmetric and positive semi definite is this just a requirement for kernel matrices not kernels so the only criteria for a kernel to be valid is that it's a dot product of two feature transformations c why is the boundary not slightly askew such that the only support vectors are x and x the radius would be the same but there are instead of support vectors thanks,public,exam
midterm recitation slide,in midterm recitation slide it says random variable a and a can indicate the same thing is this just saying if we define our new a as of our old a then of our new a becomes equivalent to our old a thank you,public,other
does the midterm cover any topic from lecture,do we need to know anything from lecture for the midterm thank you,public,exam
a mle and map convergence,can anyone explain the solution provided for the mle and map convergence problem i know the answer and i understood the explanation given by tom mitchell fake tosses is it because log map log likelihood log prior and as number of training examples increase likelihood log likelihood dominates over log prior,public,exam
b midterm exam,for test error to not be significantly different from training error the class composition should be similar in training and test data right for example if training examples have a class ratio of say men women then test data examples should also have a similar distribution,public,exam
correction tape,we were told that our answers in the exam should be written in pen may we use a correction tape to erase out our answer during the exam thanks,public,exam
qna,can anyone help me with question and on hw qna i don't really get how to interpret y and p is p the wrong probability and how does the data set y relate to data set x,public,hw2
knn leave one out cross validation,i don't quite understand how to calculate the knn leave one out cross validation error which was mentioned in today's class say k and the blue one in attached figure is left out for validation when calculating the error should we just look its nearest points a point can be its own neighbour but when doing validation we should don't know the point's own label so we only need to check its nearest neighbour in sum the validation error of k will be is my understanding correct,public,exam
question about hw q solution,hi the solution of question a shows the probability as however in the lecture notes i feel like the exponents of y i and y i in the solution should switch can someone take a look thanks,public,hw3
regularization tradeoff,can someone explain intuitively how regularization represents the tradeoff between fitting the data and keeping the model simple,public,other
will there be a timer during the exam,since we cannot use cell phone to check the time i wonder is it possible to show the time by projector to remind us the time during midterm exam thanks,public,exam
will today's lecture be recorded,today march th,public,videos
solution for lec,hello can anyone provide the solution for the sample question in today's lecture in page i didn't get the point how to derive a formula for i when the objective function achieves its minimum and not sure about the plot it is the last sample question in today's lecture thanks,public,exam
how long will the midterm exam be,can the instructors confirm what the duration of the midterm exam will be,public,exam
parameters are probabilities,hi all in the differences between nb and logistic regression one statement is parameters of nb are probabilities and the other one is not what does parameters are probabilities mean thanks,public,other
maximizing likelihood for logistic regression,i need some help understand conceptually why we cannot maximize the log likelihood using mle for logistic regression in the lecture dr gormley says that this is because we don't have a joint model p x y as we did for naive bayes and that we could do this for linear regression because we could have a conditional log likelihood but i don't get it could someone elaborate on this thanks,public,exam
svm,why is svm originally non convex optimization when we minimize gamma over the constraint left w right and how does factoring in w' w prime w gamma transform our objective function from non convex to convex thanks,public,other
gradescope submission,can we have the ta's names who have graded the hw theory part by problem,public,hw3
learning theory quesions from the sample mid term,in the spring mid term that we have been provided section is on learning theory and asks about vc dimension and sample complexity a lot have we covered this in class,public,exam
midterm exam,will we have extra credit questions like last semester's midterm,public,exam
kernelized svm,did we learn about kernelized svm svm in which kernel is used,public,other
are we expected to memorizing distributions,are we expected to memorizing distributions like their pdf cdf expectation and variance,public,exam
almost surely convergence,what does this mean this is with regards to a learning method being consistent or not in lecture,public,exam
spring midterm question c,consider the case with binary features i e x in d subset mathbb r d where feature x is rare and happens to appear in the training set with only label what is hat w is the gradient ever zero for any finite w why is it important to include a regularization term to control the norm of hat w i don't understand how to approach this problem,public,exam
how to find the decision boundary of svm,hello when doing the c in last years' mid term i am confused how to find the decision boundary of the svm why is thanks,public,exam
how will the decision boundary change after moving samples,hello i don't understand how will the decision boundary change after we removing samples from svm model there exist many conditions any help thanks,public,exam
q help needed,the values in the lagrangian dual form of svm objective corresponding to support vectors and non support vectors from the original data are different i really don t understand this statement as the lagrangian dual is not covered in lectures in my opinion any insights please,public,hw4
notation question,i have noticed professor gormley switches between semicolons and pipes when indicating a distribution is parameterized by some variable for example x i y i sim p x y theta instead of x i y i sim p x y theta is this intentional or just another way of saying the same thing i have read that semicolons are the standard way of indicating parameter relationships also does it matter which notation we use on the exam thanks,public,exam
custom exceptions,sorry posted on the wrong forum,public,hw4
hw solutions,would we the hw qna solutions before the exam,public,hw4
why rbf kernel for the homework kernel perceptron problem,i have problem understanding which suitable kernel we should use in general for example in homework we were asked to use rbf kernel but how do we know that for a given xtrain the rbf kernel based perceptron is going to give us the linear decision boundary we did vary the tunable parameter sigma and chose the best value of it but then what if there exists a better kernel than this,public,other
map convergence to mle,in hw we saw that as the amount of data increases a map estimated computed with a non zero prior will converge to the mle what does the 'non zero prior' mean here will map converge to mle for all possible priors or are there certain kinds of priors for which this will not happen,public,other
uniqueness of a kernel for different phi functions,from what i understand a given kernel representation like k x z x z is not unique that is the same kernel function works for phi x x x sqrt x x and x x x x x x x so how do we decide what phi function is being performed implicitly for the kernel i know that the final result is still the same but is there a way to find out which phi are we using ps also note that one phi maps into dimension and other one maps into dimensions,public,other
choosing the nth dimension,suppose that the data is not linearly separable in a given space and we choose to use kernel methods to map it into a higher dimension space in this scenario how do we decide the which dimension we should map to also talking about linear separability how do we decide whether a given set of data is linearly separable just run the perceptron algorithm would that be enough,public,other
string kernels lecture,in lecture when we were discussing string kernels what we were actually trying to achieve what was the 'y' variable here were we trying to classify text based on the presence absence of certain characters strings if yes what were the classes can someone please explain,public,other
lecture notes,should the green part be p y vec x theta cdot p vec x theta,public,other
why don't we drop the generative model and try to learn this hyperplane directly,hi apologies if this question has been asked already still after replaying the lecture video and going through the slides for lecture logistic regression i was not able to find the answer towards the question also in the same lecture's slides i am also confused with the other two questions why should we define a model of p x y at all and why not directly model p y x they were raised during the lecture but i did not get the answers i would appreciate if someone could address those questions more explicitly thanks,public,videos
definition of valid kernel,what is exactly the way to tell a valid kernel i see different definitions in whiteboard and slides is it k x z phi x cdot phi z or k x z phi x top phi z,public,hw4
s mid term sample what does this sign mean,is p x p x just want to confirm thanks,public,exam
are the scores on gradescope final,i can see my score on gradescope right now since they haven't been officially released are they final,public,hw3
linear regression,in linear regression in y i vec theta t cdot vec x i is y i the observed value and vec theta t cdot vec x i the expected value,public,other
how will the decision boundary change when removing the support vector,hi all i am wondering how will removing support vector change the decision boundary shift toward the point removed shift away from the point removed or even does not change i think the result just depends on the situations if i am wrong please correct me,public,exam
problem about hw,hi all in hw question there is one choice saying setting c will not give the maximum margin separator of the data if the data is linearly separable is that correct actually i know it is wrong because i am certain other choice is accurate however why this statement is wrong here is one example in this picture i think the dataset is linearly separable with small c we can get large margin just like the left graph with infinite c we can only get the right graph with smaller margin that can prove the statement if i am wrong please correct me thanks,public,exam
when is it necessary to add n in front of j w or l w,i am confused that when is it necessary to add n in front of j w or l w i see in white board that there is no n for gd for linear regression but yes for gd for logistic regression,public,hw3
overfit for linear regression with basis function,i don't know the meaning of basis function and how does it will cause overfit for linear regression,public,logistics
solution for q,could you please correct the solution for q in hw b and c need to properly separated and the solution given as c should be d,public,hw2
qna on hw map estimate clarification,screenshot of the problem for convenience https gyazo com d e b bb c d c could someone explain how to arrive at the answer wouldn't you have to use the prior and multiply that by the original probability of the event to find the map estimates for each case for example for the any case you have a probability of that the prank day is sampled from that set then multiplying your prior you have a map estimate of similarly for the powers of case we get which is greater than thanks in advance,public,hw2
kernel perceptron,i am confused with online learning and kernel perceptron perhaps i am missing something in the update rule of kernel perceptron we wrote a summation from to n however in the case of online learning do we know this number 'n' before we start learning,public,other
hw qna q q bayes' rule for medical diagnosis,i got this wrong on the homework and i want to understand why for i thought this would be indicates positive test result and indicates negative test result p cancer p cancer p cancer p now here p cancer p cancer p cancer they are conditionally independent p cancer is given to us in the question p p p p p and cancer p and cancer p cancer p cancer p cancer p cancer and indicates intersection and indicates not or complement p follows accordingly where did my logic go wrong thanks,public,hw2 exam
what is criteria to decide convex functions,hi all in lecture professor says that j theta theta is not a convex function but if we take log of it it becomes convex how is that note i tried using criteria that function is convex if f'' x but for both theta theta and log theta log theta f'' criteria is not met,public,exam videos
lecture learning theory for midsem,concepts taught in lecture also appear for the midterm,public,exam
convergence curve,i want to ask why the two methods have very different mse at the beginning is it because the first point is drawn after the first epoch so sgd has updated many times to lower mse what does uninformed initialization mean,public,exam
homework solutions,hi can you please upload homework solutions before midterm exam this will help us to prepare for exam thanks,public,hw4
time taken for assignment,i have no clue why i got a zero for answering hr to this question is the grading final and correct are you not allowing any late submission this time,public,hw4
problem about kernel motivation,hi all in lecture professor mentioned about kernel motivation in the point there is one concept named linearity restriction what does that mean and why memory based methods will lead to kernels thanks,public,exam
qna clarification,in previous questions it has been noted that we do not have to recalculate multiplication of same values such as a b we only have to calculate with addition and multiplication does that apply to different terms that contains in part the same multiplication i e we have a b c and a b d then would that be multiplications or,public,hw4
qna,for these qna problems i noticed that when zooming into the right subplot not all slack variables appear to lie on the negative positive hyperplanes however they appear to lie perfectly on these hyperplanes on the left subplot is this a limitation of the gui,public,hw4
qna,is it correct that support vectors will always have a slack variable of zero or it can be greater than zero and less than one,public,hw4
hw grades released,hi all grades for hw have been released on autolab these scores include both the autolab and qna portions of the homework and late days have been penalized as outlined in the course policy course staff,public,hw2
hw easychair instruction,welcome to s machine learning for fun conference here are the steps for you to enter the conference instructions for submitting review start date march th note that you will not be assigned to papers until march th due date april th accept the email invite to join the litreview program committee the email should be from noreply easychair org and titled invitation to litreview program committee check your spam folder if you don't see it in your inbox log into the main conference site https easychair org conferences conf litreviewthen click to enter the site as a pc member you can change your role at any time by hovering over litreview clicking change role hover over reviews click my papers click the plus sign under add new review fill out the review form choose a score for overall evaluation and write your comments in the box below please do not attach file instructions for submitting summary start date march th due date march th we will use the easychair system for peer reviewing please follow these steps to do so create an account on easychair by going here https www easychair org account signup cgiwhen entering your last name please begin with your paper code found in the table below following the hyphen e g if your last name is lastname and you reviewed the paper convolutional networks and applications in vision your last name should be cvb lastnamethis will simplify our review assignment papercodechunking with support vector machinesnlpanatural language processing almost from scratchnlpbneural models for sequence chunkingnlpcsun database large scale scene recognition from abbey to zoocvaconvolutional networks and applications in visioncvbimproving neural networks by preventing co adaptation of feature detectorscvcchapter of recommender systemsrsamatrix factorization techniques for recommender systemsrsbalgorithms for non negative matrix factorizationrsc enter your name use your last name with prefix andrew id and email address here please this information will be used to assign reviews to you so everyone in the class should fill out this form https docs google com forms d e faipqlsdukrtfuqdegctjau hvu aq ezee laqkc ywt mgcj mjea viewform log into the main conference site https easychair org conferences conf litreviewthen click to enter the site as an author you can change your role at any time by hovering over litreview clicking change role click new submission and fill out the submission form write your topic natural language processing computer vision recommendation system in titleplease use keyword keyword keyword as keywords then upload your pdf file do not include any personally identifying information in the pdf after you make a submission you can make changes to it by clicking submission on the top bar and you will see a menu on the top right side of the page,public,hw5
qna question,is there a typo in q is it supposed to be max n,public,hw4
qna the indice begin from or,when counting the indice the first point is or,public,hw4
graph about l theta lambda,hi all in the lecture the professor mentioned l theta lambda and showed the graph but i am still confused about the graph how to get the curve like the picture,public,videos
general question on svms,please tell me if these are true slack for non support vector datapoints is when it comes to predicting the label of a test data point the location of the test point with respect to only the support vectors needs to be calculated as they define the location of the separator consequently on the same training and test data set prediction of test labels would be faster for svm than perceptron as you'd have to calculate the kernel between the test point and only the suport vectors in the case of svm while you'd have to calculate this between the test point and all training data points in perceptron svms cannot be operated in an online way as you need fixed support vectors to predict the label of any test data point follow up question i understand that if the points are not linearly separable we have no feasible solution space if there was no slack concept however instead of this why can't we use some kernel like we did in perceptron to make the data linearly separable,public,other
question the definition of training error,question the training error is the number of error or the rate of number of error to whole dataset,public,hw4
svm support vectors,my understanding of support vectors is that if there is a hard margin the hyperplanes must lie on the support vectors if the margin is soft the support vectors can also be within a user defined distance from each of the hyperplanes in the svm experiments we performed any point on the opposite side of its associated hyperplane is considered a support vector is it possible to have a scenario in which a point on the opposite side of the hyperplane is not considered a support vector thank you,public,other
qna weight factor initialization,should we initialize the weight factor to be all zeros or all 's it does make a nontrivial difference on the final error rate with different initialization,public,hw4
qna rates or actual number of error,should i give rate of error or the count of error,public,hw4
midterm recitation,hi all we recorded this weeks recitation since it was a midterm preparation recitation here are the links part https www youtube com watch v u lpb msqi part https www youtube com watch v okylwnk wqe,public,exam
exam on tuesday,hi all for tuesday's exam all solutions must be written in pen your exams will be scanned into gradescope and often solutions written in pencil don't show up therefore you should bring a pen to ensure that you get full credit for all questions on the exam reminders electronic devices will not be permitted you are allowed one page of front and back notes you must write your own page of notes you are not allowed to collaborate with others when writing your page of notes warm regards brynn,public,exam
question regarding function rbf kernel,how is the matrices x and x calculated in this question are these just mapping the data given in xtrain into another domain also i was wondering if someone could shed some light into what exactly is the difference between x and x is x same as xtrain thanks a lot for the help,public,hw4
qna use kernel perceptron as classifier,hi all i find non kernel perceptron and kernel perceptron have different update rule when training according to the write up my question is after we get a weight w from num epoch of iterations what should we use for prediction should we simply apply w 'x as the decision function or should we use kernel perceptron predict a xtrain ytrain x sigma can anyone explain which one to choose and why thx evan,public,hw4
vectorize,i'm vectorizing as much as i can for rpf kernel i only use one for loop and for kernel predict i only use np matrix functions for kernel train i use for loops idk how to be more efficient what can i do,public,hw4
q q what is training error defined as,what is training error defined as can i assume it to be no of mistakes total number of data or should i take some distance metric also into consideration also does training error mean error calculated on the training data using boundary calculated from learning from training data am i thinking right,public,hw4
installing scikit learn on one of the mac clusters,i am using one of the mac clusters my laptop crashed yesterday and am trying to install pip in my home directory so that i can install scikit learn i run into the following message does anyone know how to install stuff without running into administrator permission issues in the clusters or any cluster that may have scikit learn pre installed easy install pip install dir afs andrew cmu edu usr mreddygu error can't create or remove files in install directory the following error occurred while trying to add or remove files in the installation directory errno permission denied ' library python site packages test easy install pth' the installation directory you specified via install dir prefix or the distutils default setting was library python site packages perhaps your account does not have write access to this directory if the installation directory is a system owned directory you may need to sign in as the administrator or root account if you do not have administrative access to this machine you may wish to choose a different installation directory preferably one that is listed in your pythonpath environment variable for information on other options you may wish to consult the documentation at https pythonhosted org setuptools easy install html please make the appropriate changes for your system and try again,public,hw4
absolute value,what did those absolute value with on its right mean again,public,hw4
problem question programming,i have got the concept and logic of predicting kernel perceptron but i dont understand why we need the test data sample x as the input can anyone please tell why do we need it currently i am taking x in k x i x r from xtrain itself is that correct,public,hw4
how to use grace day,can anyone tell me how to use grace day for homework,public,hw4
will lagrangian dual be covered in the midterm,it seems that it was not covered in the lecture,public,exam
margins and generalization error,hello i have some confusion about generalization error and margins i think the errors depends on different data set but not the separator's margin any ideas thanks,public,hw3
rbf kernel error,after inserting code to catch and handle errors in my rbf kernel function i get the following errors x shape x shape rbf kernel error inappropriate argument value of correct type operands could not be broadcast together with shapes operands could not be broadcast together with shapes it looks like the function is being called on two matrices x shape and x shape but i thought this is not possible because we need the two feature matrices to have the same number of columns or features am i understanding something incorrectly to clarify these values are printed after the included matrix resizing code provided in the rbf kernel code,public,hw4
slide for review recitation,when are you releasing the slide for today's review recitation thanks,public,exam other
difference between batch v online perceptron,what's the difference our perceptron train implementation is supposed to be batched but i simply treated each datapoint in xtrain sequentially as if online and got full score accounting for epochs of course i don't understand prof gormley's comment about the batched perceptron's alpha i in thanks,public,hw4
polynomial kernel of features how to calculate that,hi all from slides polynomial kernel produces n d choose d features can anyone prove that thx,public,other
can i let two different data points with exact same features have different labels,for example in the fisher iris dataset two different flower spices may have exact same sepal length and sepal width so i think this situation may happen in real life that two different data points with exact same features may have different labels,public,hw4 logistics
qna,our indice sum will differ based on whether we used octave because it's indexed by or python are both answers acceptable,public,hw4
qna can we assume no contradiction in training set,the problem says any i can construct a contradicting training set containing only two data points xi yi then i think there is no way to linear separate it since there is a contradiction it seems that we should assume no contraction in training set,public,hw4
hints to vectorize,i'm using python and am losing marks for efficiency any hints on how to improve efficiency for the functions,public,hw4
clarifying the error rate in the experiment questions,hi i found there's a potential confusion in calculating the error rate in problem after iterating the dataset for ten times there are actually kinds of understanding of error rate the first is that i use the final w trained in previous epochs predict the label of the data points over the training data set and calculate the error rate for this single epoch the second understanding is that i use the total misclassified data points in previous times as the numerator and total iteration numbers as denominator to calculate which is the correct understanding thanks,public,hw4
qna,suppose i have ax by without the square there are multiplications and addition for squaring should i add just more for multiplication or add more recalculate ax by,public,hw4
autolab breakdown,is our autolab breakdown again,public,hw4
valid kernel,suppose we build a new kernel and we know this kernel is semi positive definite on our data set but not on another data set can we still use this kernel on our dataset,public,hw4
autolab perceptron train issues,my perceptron train function can locally achieve error but i'm not getting any points on autolab strangely checked the autolab feedback and there's no runtime errors or anything that'd suggest a logistic issue e g dimension mismatch anyone else experiencing this tas is there something wrong with my implementation thanks,public,hw4
qna question,should we treat sqrt as a constant or something need one time of multiplication,public,hw4
qna,what is the meaning of implement a or function with perceptron what is the input and output with the perceptron,public,hw4
qna,there seems to be two correct answers here it is my understanding that making c large weights smaller slack variable values and does not give the maximum margin is this wrong,public,hw4
hw qna solutions posted,hi all solutions to the hw qna questions are now posted in the resources section of piazza https piazza com cmu spring resources,public,hw2
synthetic data,what does 'synthetic data' in lecture mean intuitively,public,other
import run svm error,hi i just followed the instructions but when i import run svm it has some errors i have already upgraded scikit learn numpy scipy and pandas but the errors still show up could you please provide some hints thanks,public,hw4
qna what does x x x means,hi can anyone explain what does x x x mean how does this phi function project d data to d space thx evan,public,other
positive semi definite,hi i'm really confused as to what the positive semidefinite matrix is and how to prove it can someone explain what it means in basic terms without symbols and stuff,public,videos
qna how to classify given the kernel function,the kernel is a function of two data points in the data set how do we know how to classify the label y sign of sum of product of wi yi k xi x how is kernel related with the classify function and how can we know whether they can be separated with a line,public,hw4
whiteboard note for wednesday's lecture,hi can someone post the whiteboard lecture note from wednesday thanks,public,logistics
sklearn error,i get nameerror name 'sklearn' is not defined but i have already installed sklearn and scipy when i run run svm py it also works,public,hw4
qna,shall we consider and count x as a multiplication while we do the mapping process,public,hw4
request for homework solutions,i don't always have a chance to go to office hours could homework solutions be posted prior to the midterm so i am able to ask more detailed questions thanks,public,logistics
qna,in question does support vectors are farther away from the decision boundary mean support vectors in case a are farther from the decision boundary than in case b or support vectors are farther from the decision boundary than non support vectors where case a is removing a support vector and case b is removing a non support vector,public,hw4
validity of a kernel,in the recitation slides for the positive semidefinite check of the k matrix the values of x and x have been assumed however just because it is positive semidefinite for these values can we assume it will always be,public,hw4
qna,for this problem can you consider the additive term exp norm x exp norm z a constant because for any x and z it's constant or is this not what we mean by constant does it need to literally be a number like a real number that stays fixed for any x z thanks,public,hw4
svm experiments,for q are we simply supposed answer using visual analysis of the graphs or do we have to look at the actual data how do we account for the fact that the total number of support vectors did not change even if the actual data points being used as support vectors changed or can we ignore which data points are used as support vectors and just check if the number of support vectors changed or not for q we already deleted th row in the last question q why are we suggested to use np delete again in q what does this mean run svm after removing th row of x and y is removed for q it seems both decision boundary and number of support vectors are unchanged but why is this not an option provided in the answer set for q slack variables i want to confirm that my understanding about the lines and colors is correct in the right subplot color does not indicate correct mis classification right also if a point correctly classified there will be no slack right,public,hw4
qna perceptron experiments,in q does 'linear perceptron' in the perceptron experiment questions refer to the function perceptron train w xtrain ytrain num epoch that is the one without the pbf kernel in q after training when we call the kernel perceptron predict a xtrain ytrain x sigma function to get predictions should we pass xtrain ytrain or xtest ytest,public,hw4
svm experiment,what does the left and right graphs signify in the svm experiment is the left graph prediction and the right graph the actual classification,public,hw4
qna kernel validity and linear separability,hi how does one verify a kernel's linear separability without access to its mapping function phi mathbf x this was asked inpost but instructor wei ma's response was to check recitation slides which leads me to think that linear separability and kernel validity are equal but this doesn't seem correct for the the linear kernel with identity mapping phi mathbf x mathbf x we don't achieve higher dimensionality which means no linear separability if the data wasn't so in the first place is my thinking correct here thanks,public,hw4
qna is there a typo,in qna this section seems weird how can min range from i to n is this a new expression or this should be a sum or this symbol means choose the minimum from i to n,public,hw4
qna collaboration policy questions,for qna collaboration policy questions if my answer for is simply no can i just write no in,public,hw4
grades for homeworks,when will the grades for homework and be posted like the qna and written parts i was thinking it might be helpful to review those for the exam,public,logistics
slack variables for blue variables on the hyperplane,i viewed previous post saying that those between boundary and hyper plane has slack variable between but the blue spots for qna are on the plane so is that or larger than,public,hw4
qna,is generalization error test error,public,hw4
perceptron in seperable data,hi all in slides for perceptron it mentions that for linearly separable and inseparable data we can bound the number of mistakes is there a theorem other than navikoff's that shows that for inseparable data of mistakes is also bounded thx evan,public,other
slack variables,i ma confused about the slack variables used in svm py and the one defined in assignment this xi looks like the distance between point and decision boundary but it is defined as slack variables and used for drawing the red 'blue' and 'black' points for the left subplot it loos like that the definition in the assignment define the slack variable as the distance between the margin and the classified point on the wrong side of the margin can anyone help me solve this confusion i am more convinced with the second definition but it seems that the way to plot the right subplot and qna choices lead me to the first definition,public,hw4
svm experiment question qna q,the th row means index from x and y right i run experiment with and the decision boundary changed a little for index almost changed nothing for index is we removed index i can hardly find any changes in boundary with pure eyes shall we remove x y or x y,public,hw4
slack variable question,i'm confused about the equation associated with slack variables given in lecture if we have a point that lies directly on the correct hyperplane that it is being classified as is our slack variable or my interpretation is that if it lies on the correct hyperplane the slack variable is if it lies directly on the decision boundary the value is is this correct thank you,public,hw4
can we get the solutions of the hw before the midterm,also when will the grades of hw be posted,public,hw3
python install scipy,i also have problems with this how do we run python on windows i tried pip install scipy it does not work,public,hw4
python install matplotlib pyplot,i have already install matplotlib through pip install matplotlib but it still says there is no module called matplotlib plot what else should i command or do i need to delete all the plotiing code,public,hw4
left and right subplots,for the svm experiments when we draw the plots we get a left subplot and a right subplot does the left subplot show the true class of every training data and the right subplot shows how each support vector is predicted,public,hw4
problem why am i getting out of in this question,can someone tell me where i might be wrong,public,hw4
what is yr in this algorithm,screen shot at pm png can anyone provide an intuitive explanation of yr why do we include the yr term in the batch version but not the online version,public,hw4
question of proof of mistake bound,in the lecture of perceptron i found the following piece of proof i think the equal sign in the red circle should be greater or equal since not every data point can acquire the minimum margin gamma,public,other
experiment q,with this experiment are we supposed to train the data by running the kernel algorithm on the train data twice using each sigma and then once on the test data or should we not be using the train data at all i'm a little confused,public,hw4
can someone provide a more intuitive explanation of svm,during monday's class we only took little amount time talking about svm and for student like me it more seems like by playing math tricks we get svm but only an equation is not easy to understand why we need to come out a classifier like svm what is its strong point and weakness whats does support vector mean why these support vector can work actually i know by using support vector we can reduce the calculation we need no more calculate all the data samples only pick some near the margin but i didnt see any intuitive explanation from the equation we got the reason i ask this question is that for student like me i dont have that strong background of math it is a little hard for me to sense things behind math so most time if i want to know how to use a classifier at least i need first understand why we need it what do all the parameters mean how to derive the equation is something we can consider as homework,public,hw4
last year's midterm posted to resources,hi all the midterm from spring has been posted in the resources section you can view it on the course page https piazza com cmu spring resources you can use this as a practice midterm please try to solve it before we post the solutions in a few days course staff,public,exam
qna,experiment in problem does not mention the value of sigma that we must take in order to compute the test error can we compute the error rate using sigma as an arbitrary value such as sigma,public,hw4
is there any limitation for autolab upload,hi sir could we submit our code to autolab as many times as we want or is there any time limitation,public,hw4
qna does question has a correct answer,hi according to the definition of slack variable defined in i really don't think there is a correct answer here does anyone feel the same actually question is barely selectable i think,public,hw4
question about autolab,hi sir i met a problem when i submit my code to autolab the following are the error message cannot run function rbf kernel running kernel perceptron predict cannot run function kernel perceptron predict running kernel perceptron train cannot run function kernel perceptron train i can execute the above three function successfully so i don't know why the piazza show this error has anybody met this problem before,public,hw4
are we going to have the answers to hw before the midterm exam,hi just wondering if we allow late submissions as before then since the deadline for this assignment is friday are we still going to have the answers for this problem set in time before the mid term thanks,public,hw4
lec intuition in the gaussian prior,i have understood the mathematical derivation in the figure below whiteboard from lecture can someone explain the intuition behind why do we take the variance as a function of lambda what will happen if we keep the variance as a function of something other than lambda doubt variance lamda png,public,hw4
th row,when they ask me to take the th row out on the problem question and do we refer to the first row as st or th or in other words will the row that we have to take out be the matrix or matrix,public,hw4
lecture,we replaced theta by w by dividing it by gamma and removed the constraint that theta does that mean theta gamma,public,other
kernel perceptron train k i r,so i'm doing the kernel perceptron train function so for i n yprediction phi sum alpha r y r k i r in getting k i r i would use the kernel perception predict function the predict function takes a xtrain ytrain x sigma as parameters so for parameter x should i use xtrain i,public,hw4
qna questions,do we limit our scope to mercer kernel only for all questions under kernel also for the pic below do we assume that x and z are always positive,public,hw4
autolab test cases,so from a previous piazza post a ta confirmed that the test cases used to grade our hws are independent i've been submitting code with an incorrect rbf kernel function that receives full credit on everything else however any attempts at fixing rbf kernel results in 's in kernel perception predict kernel perception train testing i don't have much to work with from autolab's feedback and i'm unsure which function is causing this behavior any help would be appreciated edit thanks for the reply i believe autolab only tests rbf kernal for cases for when m,public,hw4
argmax max,are underset w argmax and underset w max same things i e underset w argmax text some function of w and underset w max text some function of w have the same value of w,public,other
can someone help me with the link of lecture monday,hi i cannot find the link for lecture on monday can someone help me with it thanks amrit,public,videos
possible ui improvement of qna,hi if i may i have a suggestion of qna ui improvement the right side bar of qna does not scoll down when user scroll to toward to the bottom of the page like the screenshot below that makes it impossible to get navigation of every question thanks,public,other
warm start techniques,in hw section it says you can't use warm start techniques for training each model out of curiosity what does this mean,public,hw4
how to time code segment in python,hi all i was a matlab user but i want to exercise my python skill in this course in matlab's editor there is a run and time function and tic and toc that allows me to time code segment and check the efficiency of each part is there an elegant way equivalent to the matlab's run and time function to time my python code except for using the clock function and calculate the time difference myself thanks,public,hw4
qna,the question asks us to report the sum of indices of the new support vectors how do we get the indices is there some function i don't know of any hints,public,hw4
kerenel function and potential decision boundaries,when determining error of a classifier on a specified kernel function we can assume that the decision boundary does not need to pass through the origin right,public,hw4
how many ways to decide whether a function is a valid kernel function,according to piazza and recitation at least i saw two ways to decide whether a function is a valid kernel function the first one is whether k x z can be written as phi x t dot product phi z the second one is whether this function is symmetric and whether its gram matrix is positive semidefinite are these two ways mean the same thing usually which way should we use by saying this i mean sometimes it is not that easy to see by the first way,public,hw4
qna,are x and x' defined as integers or real numbers,public,hw4
what is the general method for checking whether a kernel space is linearly separable or not,what is the general method for checking whether a kernel space is linearly separable or not thanks a lot,public,hw4
can't open up hw on piazza,is piazza offline i can't open up hw on piazza,public,hw4
are we allowed to bring cheat sheet to midterm,are we allowed to bring cheat sheet to midterm,public,exam
svm classification step,what is the classification procedure for an svm in the lab the w of the model has dimensions of n x and each x has dimensions of x in the slides lecture slide the decisions seem to be made by taking the dot product of w and x however these dimensions don't match up so i seem to be doing the decision the wrong way what is the proper procedure to do the classification,public,hw4
ioerror when trying to run experiements,hi for some reason i cannot run rs get data on my local machine or on my linux terminal when i ssh this is the error message i get when i try to run it on my local machine something with ioerror all the way at the bottom i have scipy and scikit and numpy all properly installed could anyone please help import run svm as rs x y rs get data hw data mat traceback most recent call last file line in file run svm py line in get data data sio loadmat path file users sarahmallepalle library enthought canopy bit user lib python site packages scipy io matlab mio py line in loadmat matfile dict mr get variables variable names file users sarahmallepalle library enthought canopy bit user lib python site packages scipy io matlab mio py line in get variables hdr next position self read var header file users sarahmallepalle library enthought canopy bit user lib python site packages scipy io matlab mio py line in read var header mdtype byte count self file reader read full tag file mio utils pyx line in scipy io matlab mio utils varreader read full tag scipy io matlab mio utils c file mio utils pyx line in scipy io matlab mio utils varreader cread full tag scipy io matlab mio utils c file streams pyx line in scipy io matlab streams filestream read into scipy io matlab streams c ioerror could not read bytes thank you,public,hw4
aws is out,we can't watch lecture videos,public,videos
couldn't open the video site,hi i'm unable to open the class's video website i don't know wether there is a problem with it,public,logistics videos
svn experiments classification accuracy,for the svn experiments how can we obtain the classification accuracy for a given model i am using matlab and don't see a field in the model struct containing accuracy should we count the data points by hand on the plot or is there an easier way to do it,public,hw4
difference between left right subplot,what exactly is the difference between the left and right subplot in the svm portion of hw it looks like some points which are classified as red on the left subplot are blue on the right subplot which is confusing me as to what exactly they are plotting,public,hw4
alpha in kernel perceptron algorithm,based on the lecture note below the alpha in the algorithm is assigned by y t in the homework the alpha is an increment value which records the number of mistakes for each training examples what is the difference between this two definitions,public,hw4
can we get the explained solution for the previous homework,since we need to prepare for the mid term exam can we get an explained solution for problem in qna only the correct number can not help thanks,public,exam
format of the midterm paper,what will be the format of the midterm paper will it be multiple choice or writing answers also can we get a sample practice paper for the midterm,public,exam
why can we get rid of theta constraint in optimization,max gamma is equivalent to min w due to the constraint theta why can we get rid of that constraint and still have the min objective function,public,videos
time complexity for updating perceptron,i think the time complexity for naive method for simple perceptron should be m o m so does the time complexity for naive method of kernel perceptron should be o t sigma m,public,videos
no module named sklearn,hello when i try to set the environment for hw i got the error no module for sklearn any ideas thanks,public,hw4
autolab feedback,i have used autolab in several other courses and the feedback is usually a little more descriptive than what i am seeing on this homework not complaining i just want to limit my submissions also i would like to point out that there is some inconsistency between the homework handout and the perceptron py script regarding variable dimensions for example the handout specs state ytrain ytest should be n vectors however the script states that they are n vectors also perceptron predict states w is a d vector however perceptron train which calls this function takes input w which is specified to be a d vector i am not sure why we don't just stick to one convention when dealing with vectors in python and assume they are all n column vectors just like most ml textbooks state i know this has given a lot of students trouble because many numpy methods can do very different things when given n vs n vectors autolab would not even run perceptron train if i returned a d vector yet perceptron predict requires a d vector again not complaining i just feel that if autolab feedback is minimal then the specs should be consistent across homework materials,public,hw4
autolab error message,i ran my perceptron train and it worked locally but autolab told me that it cannot run the function so i'm not sure what happened did anyone encounter the same problem also my rbf kernal scored but there was no error message associated with it i clicked on the score but still wasn't able to find anything,public,hw4
how to decide whether a kernel is valid,hello i am not sure how to decide a kernel is valid i heard that kernel functions must satisfy mercer's condition but i am not sure whether we should compute it each time or there are other ways to decide this thanks,public,hw4
svm slack variable,would you please confirm my understanding of slack variables is correct slack variable is computed during svm training if a datapoint is misclassified then its slack variable if a datapoint is between the decision boundary and the correct side of hyperplane it will be if a datapoint is under the correct side of hyperplane it will be if my understanding is correct then how to interpret a datapoint which is misclassified and laying on the correct side of hyperplane at the same time i saw this kind of data in hw thank you,public,hw4
whiteboard notes,whiteboard notes of today's lecture is still unavailable on the course website can someone post it thanks,public,other
regularization and sparsity,hello i do not understand the relationship between regularization and sparsity very well can anyone explain more about this thanks,public,other
qna how to count powers,how do we take exponents into account for example a cdot b a cdot b cdot a cdot b multiplications c a cdot b c cdot c multiplications,public,hw4
inconsistency in kernel implementation,if my understanding is right the first n is equal to num epoch the second n is xtrain shape if that's the case why the two n are in the same notation,public,hw4
midterm make up,when will the times for the make up midterm be announced thanks,public,exam
confusion regarding the counting vector alpha in kernel perceptron predict,i am trying to understand why we have been given alpha or a as an input parameter to kernel perceptron predict alpha keeps track of the errors over n so it is when a point is misclassified and otherwise although in class today matt mentioned that we can assign the value of yr epsilon to alpha when it is misclassified and otherwise are these two situations equivalent in online kernel perceptron i understand that we are responsible for assigning the value of alpha we check whether a point is misclassified or not and then update the value of alpha so i am wondering that if we are given alpha what does that vector signify am i given a vector that states the points that are misclassified,public,hw4
cancelling office hours,hi all unfortunately i have to cancel my office hours this week i apologize for the inconvenience warm regards brynn,public,logistics
kernel perceptron predict,to generate the rbf kernel we used two matrices x of size n x d and x of size m x d in kernel perceptron predict what are the input arguments to the rbf kernel function we are given xtrain which is a n x d matrix but x is a single instance and has size x d since this is batch kernel perceptron algorithm i thought we need to compute the entire kernel matrix first before we predict any value am i to compute the kernel function for each instance of xtrain with the same x over all n points of xtrain does it make sense to compute a gram matrix in this case,public,hw4
kernels and svm,here is one answer i found on quora that explains kernels and svm in very simplistic terms https www quora com what are kernels in machine learning and svm answer rahul a srid nlpe,public,hw4
qna problem,regarding the prediction function y h sum i x i ast w i b is b within the summation or outside it update adding reference to question as well,public,hw4
hash map and suffix tree for runtime of kernel perceptron,in class matt mentioned the use of hash maps and suffix trees to reduce the number of parameters and calculate sparse runtime complexity for standard perceptron and kernel perceptron can someone explain this further or provide a resource to help me understand it better,public,hw4
qna prob kernel space,in qna problem what is a kernel space,public,hw4
whiteboard notes in lecture,the notes of lecture in i think it should be geq rather than based on previous theorem,public,videos
dimensions of the output of rbf kernel function,in the implementation of the function of rbf kernel function if n m after the summation k will be a matrix right how can we output a n m which is matrix,public,hw4
string kernel example,in the string kernel example in today's lecture what is the form of each parameter also why is the number of parameters for standard perceptron o text num of alphabets k i e o k,public,other
kernel trick,based on last wedensday's lecture i was under the impression that the kernel trick is simply taking x t z however from what i've been learning the kernel trick actually maps our x and zs to higher dimensions what exactly is the definition of kernels and the kernel trick,public,videos
syllabus for midterm,could you please tell what topics are included for the mid term do we also have the cs fundamentals from hw,public,exam
autograder times out on kernel preceptron predict,when i submit kernel perceptron predict on autolab my code times out and i receive this error message an error occurred while parsing the autoresult returned by the autograder error message unexpected token at ' ' autodriver job timed out after seconds however when i run it locally using hw script my method returns the correct value of either or i have full points for all previous functions on autolab i was wondering why this seems to be an issue because i only have one for loop in that function and that doesn't seem to be causing the timeout issue,public,hw4
q what sigma should we use,on the problem question what is the error rate of the trained perceptron on the xtest dataset after iterating the xtrain dataset times what value of sigma should we use,public,hw4
what is kernel perceptron train correctness,there are two functions called kernel perceptron train correctness and kernel perceptron train efficiency in autolab detection but we don't have them in homework statement and the given files can anyone tell me what i am supposed to do with the two functions,public,hw4
kernel perceptron predict score reduces when i vectorize,i got full score for kernel perceptron predict and train functions but when i tried vectorizing the inputs for efficiency i got a score of out of for predict and for train this means that the predict function is slightly off and of course because of this train is off as well but there are no error messages that i can use to debug because the score is so close to full score i don't think that the logic is incorrect is anyone else having similar problem any idea what the issue might be,public,hw4
valid kernel,hi all the course materials say that k x z is a valid kernel when k x z transpose phi x phi z but how do we find the phi and check the validity of k is there any standard process for finding the phi thanks,public,hw4
question,in order to consider data linearly separable must the line pass through the origin thanks in advance,public,hw4
autolab error for perceptron predict and perceptron train,i tested locally and got the results i want but autolab says that it has problem reading the output of the function i don't think there is an error in my code anyone have any idea what this message is referring to thanks,public,hw4
experiments problem,for the experiments the alpha returned trained from kernel perceptron has the same number of rows as the training data but we are supposed to test it on xtest which has a different number of rows,public,hw4
theta star,what is theta star and how does it relate to theta k,public,videos
kernel efficiency,in class we discussed the efficiency of using kernels however i'm uncertain as to whether this efficiency describes computational time and or space efficiency in time every time we evaluate a kernel k x z for two instances x and z we perform a dot product between two feature mapped vectors comparing these vectors for similarity will always require an operation like the dot product however transforming these vectors into the feature mapped space using the function phi x may need to be and often will be done multiple times for the same instance over the course of training if feature mapping the instances were done to all instances prior to training there would be no need to compute phi x more than once thus it appears as though using kernels decreases efficiency in overall computation time efficiency in space here the benefits of using kernels are more obvious as the feature mapping need not be computed for all instances at the beginning of training but only insomuch as they are needed i e when the similarity between two specific instances is calculated in conclusion does this efficiency in space really make up for what seems to be an inefficiency in time if so how,public,hw4
kernel perceptron predict,from the homework it seems we find the sign of sum r n alpha r y r k i r but isn't k i r a matrix how do we find the sign of a matrix,public,hw4
what defines a kernel,similar to in class we talked about how a kernel is a function k x z phi x cdot phi z where phi x is a feature mapping function of any form explicit or implicit that takes input x of dimension m and outputs x' of dimension d where d m the kernel function must always be represented as a dot product inner product such that it runs in o d time while performing this dot product on the mapped features of dimension d why is it then that some kernels are not represented as the dot product of two implicit feature mapped vectors for example the radial basis function described in hw below k x z exp frac left x z right sigma can this radial basis function be written as a dot product if so why don't we write it as a dot product what are the rules that guide our choice of writing a function as a dot product or not as a dot product furthermore if we happen upon arbitrary functions that aren't explicitly dot products as above for rbf how do we know if they are indeed kernel functions in other words what isn't or cannot be a kernel function,public,hw4
summing indices of support vectors,just wanted to confirm that we need to sum the indices of the support vectors for the second svm problem not their row the support vector we had to remove was given to us as a row not a based index thanks matt,public,hw4
increase code efficiency,how to make the code more efficient any hint other than what is given in the assignment thanks in advance,public,hw4
kernel perceptron predict and update rule,while predicting hat y is y r representing the labels from the training data ytrain i'm also confused what that is doing there because some other online kernel perceptron resources don't seem to have it image of the relevant handout portion below,public,hw4
perceptron train w xtrain ytrain numofepochs,i could print the result as a array on my terminal but autolab told me cannot run function perceptron train my terminal result with w shape 'per pertrain ' array,public,hw4
qna question and clarification,we are asked to count the number of multiplications and addition should sqrt sqrt also count as a multiplication should we consider optimal number of multiplications ex save result of x z if this multiplication is used more than once,public,hw4
kernel clarification,the definition of kernel says k is a kernel iff there exist phi rm rd such that k x z phi x phi z is the range of function phi r d allowed to be infinite dimensional real space i e d infinity,public,hw4
autograder score,before i implemented kernel perceptron predict and kernel perceptron train i got out of but after i submitted my work with these two functions implemented i got a straight could you please look into it is this because that the time complexity of my code is too high job timed out after seconds,public,hw4
in kernel perceptron predict method when summing up from r to n can r be equal to i,when predicting hat y i varphi displaystyle sum r n alpha r y r k i r can r be equal to i i think r i should be excluded when summing up r,public,hw4
perceptron on recitation,in lecture slides if the predicted y is different from the true y we update the parameter theta omega but why the parameter is not changed on recitation slides on p and p,public,other
qna indices start from or,in svm experiment question we are asked to delete th row and in question we are asked to report the sum of indices i was wondering indices should start from or in this case,public,hw4
recitation slides,i was looking through the course website and i noticed that the recitation slides aren't posted on the course website can we get access to this,public,logistics
error with autograder,there is a problem with kernel perceptron predict in the autograder the grader gives me points for a blank file and zero points for the correct solution,public,hw4
sparsity,what does it mean for a solution to be sparse with respect to regularization,public,hw4
pip install u scikit learn,i'm a windows pc user and for this course's homework i downloaded anaconda and use spyder i have import numpy and import scipy working i e if i write those two in the ipython console in spyder i don't get any import error in the scikit learn website it says where should i write the pip install u scikit learn line e g on the top of the py code file or do i just have to write that line in the spyder ipython console once thanks,public,hw4
non linear features motivation,question on lecture logistic regression nonlinear features why do we want to turn a linear input e g x x into a nonlinear one e g x x x x log x what's the general motivation of creating non linear features thank you,public,other
hw frequently asked questions,faq for problem svm experiment q what do i need to do for the problem a please read instructions and documentations in q can i use octave a we are sorry but we are only supporting python and matlab for this section of the homework q i got an import error for sklearn when i import run svm py a you have to install scikit learn and scipy in order to run the provided python script you can find installation documentation from http scikit learn org stable install html q i only have windows machine and don't have matlab installed a there are several options available you can connect to virtual andrew machines which has matlab installed or go to actual computing clusters e g wean clusters on campus to run scripts q i have matlab on my machine but i still can not run the run svm m script a the fitcsvm function used in the script is only supported after matlab a if you have a matlab with lower version we suggest you to use the virtual andrew machine or install the latest version matlab at the following link matlab download andrew id required q when running the run svm method from python the script hangs and no plot appears what should i do a try starting python with the command 'pythonw' instead q why i can not install scipy or scikit learn a this situation should be discussed case by case but here we can provide a universal solution which is directing you to install anaconda anaconda is a combined python platform which has most of scientific packages installed after your installation of anaconda you can get most of the python packages very easily faq for other problems q which sign function should i use a the one from the homework not the lecture see matt's caution in q which algorithm for kernel perceptron should i use online or batch a the one from the homework batch not the lecture online see matt's caution in q i am confused with the coloring scheme of svm experiments asking slack variable values of red blue and black points in the right plot a please read note these are regularly updated list of questions that might be helpful to know,public,hw4
kernel perceptron and hw,hi all two quick cautions for hw caution what is the sign of zero from a mathematical standpoint zero is neither positive nor negative so we say that it does not have a sign for the perceptron algorithm however it's convenient to arbitrarily define sign or sign but which one you choose is arbitrary on hw be sure to follow the definition of sign cdot stated in the homework not the arbitrary choice in lecture caution whenever we talk about perceptron it's very important to distinguish between whether we are talking about training in an online setting where examples stream through one at a time and we see each example only once or a batch setting where you are given a fixed set of training examples up front and might cycle through them multiple times in class i presented the kernel perceptron algorithm for the online setting whereas in hw you'll be implementing it in the batch setting be sure to make careful note of the distinctions between the two versions of the algorithm if you weren't careful and implemented the online version from class you could get the wrong result despite their differences the two algorithms can obtain the same results consider the two datasets below mathcal d y mathbf x y mathbf x mathcal d y mathbf x y mathbf x y mathbf x y mathbf x notice that d is simply two copies of d if you ran the batch kernel perceptron algorithm on d for two epochs it would be equivalent to running online kernel perceptron on d where i'm assuming that the online version stops at the end of d finally notice in the batch version alpha i in but in the online version alpha i in the simple d d example above shows how these two counting schemes can be equivalent hopefully this will save you all some time cheers matt,public,hw4
reminder required feedback form due pm today friday,hi all this is a reminder for you to submit the required course feedback form which is due by pm today friday feb your participation in this form is graded and worth points it should take under minute to fill out the link is repeated again below https goo gl forms vggxshyrd pylfg thanks to the of you that have responded so far our original post from monday is cheers matt,public,other
qna kernel,does x' means transpose of x,public,hw4
x for positive semi definite matrix,the condition to check if the kernel matrix is positive semi definite is given by x'kmatx so to generalize for n training examples what would our x be,public,hw4
recitation slides,hi all here are the slides from today's recitation recitation on regularization kernels perceptron pdf going through these will definitely help with some hw problems,public,hw4 logistics
inconsistency in handout and starter code,i think there is an error in the comments here the weight vector should have the same dimensions as the feature space i e a column vector of size d here also the handout says that alpha a is the count for the number of errors also just to note that the handout says that xtrain and xtest will have a different number of instances but they are both of rows in the given data,public,hw4
can i edit a page add page on gradescope,is there a way to update a particular answer on gradescope i don't seem to think there is but i might be wrong uploading all the answers again for one question's sake does not seem to be a straightforward way if there is a work around for this please let me know else i would like to know the considerations for choosing this medium for submissions i have used it in the past and have found it pretty painful to use,public,other
for b,for conditional log likelihood why we calculated it by just adding each log up but in this function we have to divide it by the number of points n,public,hw3
survey,where is the survey we have to fill out,public,logistics
kernel perceptron predict,in the kernel perceptron predict function why do we need xtrain ytrain since we are predicting label for x and we didn't use xtrain ytrain for perceptron predict,public,hw4
hw extension for autolab and gradescope,hi all sorry for all the inconveniences related to autolab for hw we consulted with the autolab development team and learned that you all had collectively submitted over versions of hw this overwhelmed their servers and took the whole system offline resulting in a period where you were unable to submit here are some important notes about logistics for hw deadlines and submissions deadline the deadline for hw autolab and gradescope submissions is now am friday feb tomorrow morning number of submissions we will not be imposing a limit on the number of autolab submissions for hw instead we are going to rely on your personal responsibility to restrict the number of times that you upload our contingency plan if the autolab servers become completely unresponsive again we will open a restricted submission period tomorrow feb during which time you will only be permitted autolab submissions the gradescope deadline will not change note that this restricted submission period will only be opened if we receive notice from the autolab development team that the servers have again become unresponsive and after they have been brought back up why are we lifting the submission limit because we trust that you all can act responsibly as a group several of you have submitted hundreds of versions of your hw before you submit each time please carefully run and test your code locally convince yourself that your code is correct and only then submit please note that because this hw deadline will not be moved again excepting our contingency plan it is in your collective best interest to submit early but not with many repeated submissions why are we also extending the gradescope deadline the original piazza note explaining the hw extension did not include mention of gradescope thus some of you may have received an email notification from piazza that suggested the extension was for both autolab and gradescope now it is i recognize that for those of you who worked extremely hard to have your work completed on time this extension is completely unfair you have my personal apologies for the inconvenience i hope that you are able to get an early start on hw and keep up the great work cheers matt,public,hw3 logistics
autolab,it takes about minutes to grade my code in autolab and the final score is why my last submission received,public,hw3
important autolab submission today,ignore this post instead see hi all just a fair warning today regarding uploading your hw submission to autolab we are restricting you to single hw submission to autolab after pm today if you are still trying to fix your code i would recommend giving it up and just submitting what you have now i am telling you this because the reason for last nights autolab errors came from the system being overloaded if everyone tries to submit it at the last minute again tonight we will have the same problem however this time there will be no extension and if you have to submit your code late because of autolab being overloaded then you will incur the late penalty you have been warned losing marks to not being able to fix one function is significantly more reasonable than losing of the entire assignment for being late we will probably restricting students to a submission limit going forward to stop this from happening again as you should not be using autolab to debug your code you should debug it locally with the knowledge you gained from class,public,hw3
linsgd logsga,i got points for all other functions except these two autolab says that the results are not what it expects i ran it in my terminal and everything works so it shouldn't be runtime or other problems i guess my numbers might be a little off but i checked everywhere in my code and couldn't find any mistakes most of the code is just using previous functions anyways i checked my constants and they should be all correct anyone run into the same problem any idea what might be wrong thanks a lot,public,hw3
final grade curved,are the final grade cutoffs determined by the performance of the class or is it set on stone a and so on if its the latter case can we know the cutoffs,public,logistics
logreg calcsg vector multiplication too slow,i have get the scalar to multiply the x i arrray and the sg should a vector which will be the transpose of the new x i array but when i try to multiple each element of x i by scalar it is extremely slow and autolab shows me only not working as expected i have on idea what is going on,public,hw3
gradescope submission,how do we submit our graphs to gradescope late without incurring a penalty also if our homework was not aligned correctly question to question will we still receive points i think mine was messed up because i didn't have the graphs in my initial submission,public,hw3
advanced readings structured perceptron,hi all tl dr here's an advanced reading for those that are curious in office hours a few folks were asking me about structured perceptron i mentioned it in class as the way to generalize the standard perceptron algorithm to handle multi class classification that is a setting where y comes from a perhaps exponentially large set mathcal y below is the link to the paper that introduced structured perceptron collins i'm also including graham neubig's slides on the same topic collins discriminative training methods for hidden markov models theory and experiments with perceptron algorithms http www aclweb org anthology w neubig nlp course slides on structured perceptron http www phontron com slides nlp programming en struct pdf the main background knowledge that you're missing at this point in order to understand the above material is hidden markov models which would usually be taught before this so you might find these easier to digest after we learn hmms later in the course cheers matt,public,other
fyi the autolab has recovered now,have a good one everyone xd,public,hw3
how exactly does the late policy work for hw,suppose i make a submission on gradescope today will there be a flat deduction of of marks or will it be of the marks i get for the right answers for example if not all my answers are right and i score only out for the questions on gradescope will my final score be of or of,public,hw3
autolab uptime notifiication,hi autolab is still down and i am not able to submit code by when could we expect the autolab to recover to test our submissions would a notification be sent regarding the same on piazza thank you,public,hw3
do we need to write every proof in a separate page,do we need to write every proof in a separate page i noticed such description in writeup is it necessary,public,hw3
hw writeup not accessible,when i go to resources i am unable to view the link for pdf of hw is this the problem with everyone,public,hw4
gradescope for time spent,hello where is the gradescope submission link for answering the time spent question it's worth point so i want to make sure i answer this,public,hw3
hw extension by hours,note the terms of the extension have changed see for more information due to autolab issues we are extending the deadline for hw by hours we will announce on piazza as soon as autolab is back up for please try to submit your code as soon as you can tomorrow the extension is just for autolab not for gradescope note this extension is purely to upload your submission you should not take this as an extra day to work on your code otherwise we will get this issue again later today there will not be any further extensions due to 'unable to upload to autolab' as you have all day to get this in,public,hw3
video download,hi is there a way to download the lecture video i've been trying to review the topic from those videos but the internet is terrible i have to wait and wait it would be nice if we could download them for watching thanks,public,videos
hw regularization kernel perceptron and svm,hi all homework has been released and is due at pm the handout of which you can download from autolab and piazza resources the assignment consists of parts a qna section a svm experiment section and an autolab programming section read the instructions carefully and be sure to submit everything to the correct place there will be a recitation covering materials in this homework this thursday at pm in ph also be sure to fill in the collaboration questions found at the end of the qna questions too good luck,public,hw4
request for an extension for hw due to autolab not working,i had a very limited amount of time to finish debugging my homework tonight due to several hours of mandatory meetings rehearsals and prior commitments as well as other homework assignments that are also due tonight at midnight because autolab submission has been down for over an hour now that time has been cut in half i have been testing my functions locally on my own computer but i don't see how i would know with certainty that my function is correct without being able to submit on autolab i was wondering if it is possible to extend the due date of the homework because of this malfunction i'm sure many others are in a similar situation,public,hw3
the autolab none issue has been happening for an hour,the instructor response was to wait a few minutes but it's been way longer than a few minutes almost an hour for me personally would one of the ta's mind looking into it,public,hw3
no file associated with submission,when i submit to autolab it shows up as none and i do not see a score is anyone else experiencing this,public,hw3
autolab showing none as submission,when i try to submit my hw tar file to autolab it is saying none on the submission has anyone else seen this or does anyone know what might be wrong here is a screenshot thank you for the help,public,hw3
can't submit on autolab,i tried several times to submit my file and autolab keeps saying that no file was submitted,public,hw3
linreg sgd is not working as expected,i am following the algorithm outlined in the notes how should i go about fixing this,public,hw3
logreg sga gives math range error,logreg sga runs fine on my local machine but autolab gives me a math range error the error disappears if i remove any calls to calcsg but i'm getting full points for calcsg and i'm pretty sure i have the right inputs in sga what could be wrong,public,hw3
linreg sgd,the error i'm getting from autolab is tuple index out of range the only thing is that i don't have any tuples in my code so the only tuple i can think of is the one that is being returned at the end of the function the only thing that would cause that is if i wasn't returning the right number of values but i'm returning like the write up asks for i don't get this error when i run it locally on my computer,public,hw3
midterm exam conflict form final chance,hi all this is your final chance to fill in the midterm exam conflict form at https goo gl forms d atkbftc vhpi k fill this form in if you have a conflict with the midterm exam details of which can be found at you have until monday th of feb to fill it in if you do not fill it in by that time your conflict will not be honored unless it is an emergency this form should be filled in as accurately and giving us as much information as possible only valid excuses will be considered for example 'i go to the cinema on saturday's' will not be considered a valid reason to why you cannot have an exam scheduled saturday we will appreciate you making a good effort to make yourself as available as possible for this exam as we are doing the same for you if you have any questions please post them here kind regards daniel bird,public,exam
is autolab down again,i have got full score on autolab however when i resubmit again i got the following error what's wrong with my submission thanks,public,hw3
hw g g number of iterations needed for convergence,after getting the graph how do i calculate the number of iterations needed for convergence how accurate does this need to be error measure what should i take the convergence criterion as can i look at when the slope of the line becomes close to zero and approximate a convergence point,public,hw3
kernel closure properties lecture section b,hi section b to date i've managed to keep the two sections almost exactly in sync however today i forgot to mention one important detail about the closure properties of kernels essentially this tells us how to construct new kernels from existing kernels please review the last two minutes of section a's lecture video for details watch from to the end as well this appears on the last page of section a's whiteboard notes both of these are linked below lecture kernels kernel perceptron svms slides whiteboard video i'll also review this at the start of monday's lecture for your convenience cheers matt,public,other
is my logic for linreg sgd wrong,i iterate from to each iteration update eta iterate through x find sg of each data set update w find trainloss for this iteration find testloss for this iteration my vectors for trainloss and testloss are blowing up but i passed all the tests on autolab for the implementations of the other functions,public,hw3
office hours right now,hi i see on the course website that there are office hours going on right now on gates kitchen area are the tas on their way here thanks,public,logistics
normalizing for linreg readinputs,i'm getting a out of for the linreg readinputs function and autolab says i have wrong normalization what i did was in the xtrain matrix for each row for each column i normalize the x value using the minimum and maximum value among that corresponding column in the xtrain matrix in the xtest matrix for each row for each column i normalize the x value using the minimum and maximum value among that corresponding column in the xtrain matrix what am i missing here thanks,public,hw3
matt's office hours this week,hi all i split my office hours this week they are thu am am fri pm pm looking forward to some new faces on friday cheers matt,public,other
g what threshold should we set to determine convergence,it seems to me that it is not precise to determine convergence by looking at loss versus epoch graph especially there are some noise points st datapoint nd datapoint and all others decreases to around some previous discussion on piazza says we could set a threshold to determine this but the question is what threshold should we pick say or anything thank you,public,hw3
logreg updateparams addition error,i'm trying to debug my updateparams function for logistic regression which is only one line but i'm having trouble adding vectors together using numpy i have one vector a that has dimensions n and one vector b that has dimensions n when i did a b i ended up with an nxn array when i did np add a b i also ended up with an nxn array,public,hw3
notation details,so what is the difference between gamma subscript w and just gamma in terms of margin and what is the definition of x i,public,other
logreg sga,is it okay that this takes about minutes to run thanks,public,hw3
the difference in algorithims,so linear regression tries to minimize using the least squares regression line logistic regression tries to minimize the sigmoid function i'm still confused on the difference between perceptron algorithim vs logistic regression,public,hw3 logistics
plots test error less than training error,i am somehow getting test error less than training error in the end for both linear and logistic regression though this is a possible scenario i wanted to check if anyone else is seeing the same,public,hw3
tar,error message unexpected token at ' all error ' hi i have this error i don't know what it means,public,hw3
autolab subnission error,hi i am getting a score after i submit my file in autolab even a previous version for which i received a score of is now scored as is there some issue,public,hw3
submission score zero,hi i am uploading my submission in autolab and it is getting a 'zero' score even if i download and upload submission which had scores assigned previously please suggest what to do,public,hw3 logistics
scan multiple pages for one problem,for gradescope problems if i scan each page of my work and i used more than one page for one problem is it ok to submit those more than one scan image files separately for that problem thank you,public,hw3
problem with autograder,get the following error in autograder bad two languages detected autolab cannot decide on which one to grade hint did you write your answers in the same programming language and name them properly but i only have python code in my submission tried several times but got the same feedback,public,hw3
is there a problem with the logreg updateparams in autolab,i get full credit even without implementing the function,public,hw3
a format,the handout says the format of log p y x w is in terms of x y w and can i write the solution in terms of xi yi w and the similar question is like a,public,hw3
python valueerror in autolab execution of logreg sga,my code runs locally without issue and produces what look like reasonable results for the logistic regression when i upload to autolab i receive full marks for every function except logreg sga autolab's output reads exception encountered in function logreg sga object too deep for desired array i've spent a couple hours tinkering with the code but autolab's exception persists any suggestion for what is happening,public,hw3
constants for linreg,so i know that if we had to use the cond log likelihood function as our objetive for linreg there will be a factor but since we're told to use the other l w as our objective function i don't see where there's a factor that we have to worry about thanks,public,hw3
linreg calcsg,i'm really confused about this function i have implemented exactly what was shown in the recitation slides y x w x and then the entire vector transposed to fit the return vector dimensions what am i doing wrong,public,hw3
scores became 's after doing f,the problem mentioned in is happening to me now i got full points on all functions except for f when i submitted code without the f done but when i submitted code after working on f all scores became can anyone give me tips solutions thanks,public,hw3
report number of epochs for convergence,a piazza post says does this mean that for problem g we plot both graphs but in regards to reporting the number of epochs required for convergence we do that only for the training error graph or do we report that for both graphs thanks,public,hw3
does the implementation of logreg sga require logreg calcobj,if i understand the question correctly we were asked to return the of misclassifications for every iterations that would be n x vector for train and test data final weight vector and final vector of predictions on xtest data i don't see why we need to make use of logreg calcobj for calculating any of the above is that right,public,hw3
linreg calcobj,in linreg calcobj function i am getting an error saying off by i just need to understand if i am implementing the code correctly following are the steps iterate through to n take the first row of xtrain and multiply it with weights x i w and subtract y vector take the square of this term add this to the loss value and keep on adding for each i th value of xtrain the final lossvalue is divided by n to get the final lossvalue is it right,public,hw3
runtimewarning overflow encountered in multiply,my code for linear regression has passed all tests except for linreg sgd when i run locally the first iteration will have trainloss e and the second iteration will overflow has anyone encountered anything like this,public,hw3
q a how to simplify in terms of matrices x and vector y w,so i'm trying to simplify the sum i n log rho i textbf w expression it doesn't seem like there's a nice form in terms of the matrices x y and w the question says we should write the cond log likelihood in terms of these matrices i'm not sure how to proceed thanks,public,hw3
hint on and theory,i've been watching and rereading the lecture notes but find where to find the information to solve namely i don't know how to incorporate trace of a mtrix into the derivation can someone point me to the right area where the professor went over this material,public,hw3
e explanation,what does 'intuitive explanation' means the weights can go to infinity only in some cases do we have to explain why the weights go to infinity in those cases i am able to show mathematically how the weights can go to infinity for the example that professor gormley mentioned in his note will that suffice,public,hw3
logreg calcobj does not give answer correctly,hi i can't understand what is wrong with my function logreg calcobj but autolab says my answer is off by autolab gives the following feedback logreg calcobj is not calculating the objective correctly off by i seem to be using the correct likelihood function but i still don't get the answer could you perhaps give me a hint what i'm doing wrong thanks,public,hw3
question about step size when plotting train error and test error in hw,does it matter which step size on x axis do we choose when plotting train test errors for example,public,hw3
a only using y and in the conditional log likelihood,i'm only using y and in my conditional log likelihood now all i did was take the log of the gaussian distribution could someone explain how x and w come into play thank you,public,hw3
about gradescope submissions,are multiple submissions allowed on gradescope and can we submit combinations of handwritten and typed pages i hand wrote most answers but typed one,public,hw3
linreg updateparams learning constant eta,what is the learning constant is that the same thing as the step size in which case the problem be solved by w w learning constant gradient w g eta,public,hw3
starting epoch,should we start our epochs at or when reporting convergence,public,hw3
dimensions for output of f,i just wanted to ensure that my output format for the results of logreg sga is correct trainpermiscl vector of around elements x testpermiscl vector of around elements x ypred vector of n predictions test input size x n w is w a cloumn vector of k x or a vecotor of x k thanks,public,hw3
hw svm experiment documentation,data and function description in svm folder of the handout we have provided data files hw data mat and hw data mat and two script files run svm py and run svm m you can use load function in octave and get data function defined in run svm py to load data x and y both hw data mat and hw data mat contain two matrices x and y x is n by d matrix where i th row of x is i th observationy is n by vector where i th entry of y is the label for i th observation a function run svm x y c which runs svm classifier on data x and y with penalty term c is provided in run svm py and run svm m the function run svm takes x in mathbb r n times d y in mathbb r n times and c in mathbb r as the objective function for svm doesn't have a closed form solution we need libraries that solve solve such optimization problems we are using fitcsvm built in function in matlab and scikit learn's svm class in python you are welcome to find documentations on the functions for detailed explanations experiment instructions you will need following steps of commands to conduct experiments run commands corresponding to pragramming language of your choice python run python at directory path to handout svm python import run svm py import run svm as rs get data from mat file x y rs get data hw data mat set penalty term c to each question specifies the value of the penalty term to be used in this example we are setting c to c call run svm function with appropriate arguments model rs run svm x y c octave run octave at directory path to handout svm octave get data from mat file load hw data mat set penalty term c to each question specifies the value of the penalty term to be used in this example we are setting c to c call run svm function with appropriate arguments model run svm x y c once the function is returned variable model holds the results of running svm one of the qna questions asks you to get indices of support vectors find the corresponding function from http scikit learn org stable modules generated sklearn svm svc html sklearn svm svc if you are using python and from https www mathworks com help stats fitcsvm html if you are using matlab,public,hw4
how to pass autolab for readinputs,i got a zero for linreg readinputs what i did basically is xtrain csvread filepath filesep 'linreg xtrain csv' i can read the files locally but autolab just gives me on this anyone can show me the right way to do readinputs i'm using octave by the way,public,hw3
answer latex template,is the downloaded answer latex template the same as our homework writeup,public,hw3
gradescope submissions,can we submit a scan of our written work done on paper on gradescope given that it is legible,public,hw3
linreg calcsg is not calculating the gradient correctly,i keep getting this error on autolab is the process not y x cdot w x i also tried omitting the negative and still got the same error i have no clue what else could be wrong any hints all i'm doing is taking the dot product of x and w with np dot subtract that from y negating it and then multiply by the vector x,public,hw3
plots,hey can we submit our plots as screenshots,public,hw3
missing a n in the class note,hi i just compare lecture with lecture notes on sgd it seems to me that there is a n missing on gradientj theta sum j theta i can someone let me know if my understanding is right,public,hw3
continuous or discrete plot in g,do we need to plot the trainerrorrate and testerrorrate continuously or discretely as a function of number of iterations,public,hw3
what version of numpy is being used,i'm trying to use np einsum in linreg calcobj but get this error exception encountered in function linreg calcobj operand has more dimensions than subscripts given in einstein sum but no ' ' ellipsis provided to broadcast the extra dimensions,public,hw3
a too many indices,i'm getting this error on autolab exception encountered in function linreg readinputs too many indices i don't get this error when i test locally and i don't index into the matrices so i'm not sure how there can be too many indices does anyone have any suggestions about what i should look for when trying to fix this,public,hw3
does it matter i write several answers in one pdf page,answers to some questions takes only one line does it matter i write answers of several questions in one pdf page and choose the same page for these questions in gradescope,public,hw3
latex template question,on the hw handout in the gradescope section it states each derivation proof should be completed ona separate page however in the latex template many of the your answer here sections are on the same page do we have to modify the latex template such that there is only one answer per page or is it fine to just put our answers in the your answer here section on the template thus having multiple answers on the same page,public,hw3
e relationship to code,hi is the rule asked in e the same rule that should be implemented in linreg calcsg,public,hw3
normalization with xtrain xtest,all my linreg functions have full score but i'm using max and min of xtrain xtest to normalize instead of only xtrain this seems incorrect because we shouldn't be modifying xtrain using information from xtest why is autolab giving me full grade for an incorrect approach just to be clear when i use max min of only xtrain autolab deducts points from my score for the linreg readinputs function,public,hw3
linreg readinputs or linreg sgd,when i initially submitted my files to autolab i was getting full credit on everything except linreg readinputs to fix this i changed path where the files are loaded by adding and additional to the end this fixed linreg readinputs function but now i am getting points on linreg sgd any hints on what the issue could be i'm also not sure that my train testloss graphs look correct is it possible that linreg sgd was wrong the whole time,public,hw3
what does this error mean,i submit the homework but the error i got just as follows but i do not know what is wrong with my code errors if any traceback most recent call last file python grader py line in import linreg file home autograde autolab autograde linreg py line in import matplotlib pylab as pl file usr lib python site packages matplotlib pylab py line in from matplotlib pyplot import file usr lib python site packages matplotlib pyplot py line in backend mod new figure manager draw if interactive show pylab setup file usr lib python site packages matplotlib backends init py line in pylab setup globals locals backend name file usr lib python site packages matplotlib backends backend gtkagg py line in from matplotlib backends backend gtk import gtk figuremanagergtk figurecanvasgtk file usr lib python site packages matplotlib backends backend gtk py line in import gtk gdk gtk gdk file usr lib python site packages gtk gtk init py line in init file usr lib python site packages gtk gtk init py line in init gtk init check runtimeerror could not open display,public,hw3
autolab grade,i got full marks before problem f however the whole grade turned to zero when i tested f on the autolab any idea about what happened,public,hw3
are scores for linreg and logreg implementations related,hi i'm getting partial scores on autolab for linreg py and getting the following message total size of new array must be unchanged i'm yet to finish some parts of logreg py so i was wondering if scoring was related between the two thanks,public,hw3
convergence is stated for test or train or both graphs,convergence is generally stated for test or train or both graphs,public,hw3
logreg calcobj not working in autolab,it says exception encountered in function logreg calcobj matrices are not alignedmy matrices are perfectly aligned and the function perfectly works when i call it while running in my computer but autolab is showing the above error i have completely vectorized and calculated the variable cll in just one expression as suggested i e i have used x dot w and np sum other than logreg calcobj all other functions are running perfectly fine can someone suggest any solution thanks,public,hw3
how to debuglogreg calcobj,hi sir i am trying to implement function logreg calcobj however i can't get the correct result for a long time could you please tell me how to debug my logreg calcobj i think my formula to calculate the log likelihood function is right thanks,public,hw3
test cases,as i said before i think the homework assignments are great with that said could you please give us basic test cases for the next homework probably the homework seems very clear during the formulation however there are many specific aspects variations and implementations issues that are not formalized on the handout and they make debug too time consuming ex why the shape is and not why ytest is but ytrain has an additional axis a small test case with correct values and shapes of the inputs and outputs would avoid all these hours looking for that small bug,public,hw3
sg dimension confusion,hi i understand that stochastic gradient returned from linreg calcsg should be a column vector however sg scalar value x here x is the row vector are we supposed to use the transpose of x here or do i misunderstand some point thanks in advance,public,hw3
final values of train loss,what is the final value for train loss and test loss for the th epoch how do i know that the algorithm works before submitting to autolab,public,hw3
gradescope collaboration questions,there are only collaboration questions the first question has parts but gradescope requires me to submit images what should i do,public,hw3
can we test linear regression and logistic regression seperately on autolab for octave,hi i am wondering if we can only upload linear regression related functions to autolab to test this part in octave i test linreg readinputs locally by setting pathname and everything worked fine but it cannot be opened on autolab i am curious about if it is related to me not uploading all the functions thanks a lot,public,hw3
trainloss and testloss,are they supposed to be returned as numpy arras or just regular vectors,public,hw3
d gradient value,i'm confused about the wording of question d it asks for the schocastic gradient of the function which from my understanding of linear algebra and the notes should be a m dimensional vector where m is the amount of features of our dataset but in the python code it asks for a schocastic gradient value as the return value of linreg calcsg and as the parameter of linreg updateparams how does this vector turn into a scalar value am i misunderstanding something,public,hw3
g reporting convergence,the question asks to report the number of epochs that are required for the algorithm to converge however it does not specify within what percentage of the final value is the function said to have converged based on this the answer will change what is the of final within which we consider it as converged,public,hw3
total size of new array must be unchanged,exception encountered in function linreg calcsg total size of new array must be unchanged exception encountered in function logreg calcsg total size of new array must be unchanged i have checked the size of matrix array they are fine my numpy version is but this bug is till there can someone tell me what is the possible cause of this bug,public,hw3
hw q a,the question says write down a formula for the conditional log likelihood of the training data using the feature matrix x the class labels y and the weight vector w since p y x takes different values when y and y i find no way other than to split it out into training examples to write the conditional log likelihood function but the question asks us to write in terms of x the full feature matrix can someone guide me on how i can do this,public,hw3
e logreg predictlables x y w,i have some problem using x i w to predict the value of y i think if x i w y should label and x i w y should label however after i run this function all the y labeled and autolab gives me full mark of this function i can't figure out what's wrong with this function can someone help me a little bit,public,hw3
a notation,hi i'm kind of confused by the notation in a what does it mean for p y x n y wtx o isn't n a distribution is it saying that the probability is given by the normal distribution,public,hw3
simplify to avoid division,how can we simplify the following to avoid division by case log frac e w t x,public,hw3
error for a linreg readinputs filepath,hi i'm getting an error for my readinputs that i just don't really understand it says exception encountered in function linreg readinputs operands could not be broadcast together with shapes i've been reading previous piazza posts that have the same error but i don't understand any of the answers or what i'm doing wrong are we supposed to be reshaping the matrix when we read it in from the csv file,public,hw3
e logreg predictlabels,i'm not sure how to approach this implementation say the function has received xtrain ytrain and trained w for each training examples in xtrain if the corresponding outcome of ytrain is sum up the logspaces of sigmoid function of w x and append it into a hyperplane list if y the sum up the logspaces of sigmoid wx instead and append it into a hyperplane list and predict y values based on the value of the hyperplane rule here and also i have been getting division by warnings for sigmoid wx calculation step any good idea to get around this,public,hw3
trainloss and testloss in linreg sgd,i am confused about the dimension of trainloss and testloss in linreg sgd should they be by or by also the dimension of w although i believe it should be something like n by just the double check when the question mentioned vector what does it mean a row vector or column vector,public,hw3
no place for collaboration question,i find that there is no place for collaboration question in the latex template should we add it by ourself,public,hw3
train test loss,the test losses are supposed to be larger than train losses as we saw in class today but is this always true i think it might be the other way round in the homework,public,hw3
q a not getting correct output but function appears to be correct,i believe that my implemented function is correct in logreg calcobj but i am getting an extremely low objective value after dividing by n however i am working in octave and receive no feedback on what's wrong with my code on autolab it just shows i receive no points for the code would any ta's be able to tell me where i am being led astray,public,hw3
a and b,for a if i use the model given in the lecture which is my part b is different than the lecture answer however if i flip the model which means i flip the result for y i and y i my part b can match the lecture result which is the following so which model should i use,public,hw3
a c,a when you say y should be nx should i create a d numpy array of shape n or a d array of shape n c what is the shape of w when numpy does dot operations it will treat both k or k as the same however the result will be an array of of shape n therefore the subtraction of this n array by a y of shape n or n are different the subtraction should be done by arrays of same shape in this sense the shape of y is critical to develop the algorithm of c,public,hw3
questions about learning rate,for logistic regression what is the difference between epochs and iterations i guess one epoch means that you go through the data from start to end and for each data point in data set it is one iteration is that correct,public,hw3
feedback form due friday,hi all please fill out this feedback form to let us know how we are doing so far this will count as a point homework toward your final grade so make sure you include your andrew e mail address it is due at the end of day pm friday thanks course staff,public,other
time of final exam,i just received an email saying that the final exam is may th is this the final decision or this date may change in the future,public,other
readings for the full semester,hi all i posted all the readings for the rest of the semester thanks to for the request if we make any additions i'll try to call them out in class as i usually do cheers matt,public,logistics
f where is the logreg calcobj function needed,i coded up the logreg sga function for part f of the homework but i didn't use the logreg calcobj function at all autolab says my code is correct the writeup says that we should implement this function by making use of the other functions including calcobj on that list i haven't seen any use for it here since we're not using it to measure error like we were in the linear regression part of the assignment am i missing anything here thanks matt,public,hw3
regularization preference,in today's lecture we learned that l and l prefer zero values of each theta m s and l prefers small values of each theta m s what does prefer mean here intuitively thanks,public,other
e question about the datapoint to represent sgd,in hw e i'm confused about the way to represent a datapoint the write up shows we need to use x i y i but the subscript i represents the i th feature which is a vector may be it means to use the superscript i or we just think it as a scalar like x j i the following is what on the write up could anyone please clarify it to me thank you,public,hw3
linreg trainloss,in sgd the trainload should be calculated for each sample and sum them up for trainloss in an epoch or just use the w after each epoch and apply it with xtrain and ytrain and come up with a trainloss for this epoch thanks,public,hw3
threshold difference,i saw that some of the piazza questions regarding the plotting problem g talk about using threshold difference can someone explain what using threshold difference is thank you,public,hw3
how do we break ties on the hyperplane,i guess this wasn't discussed in class but how do we decide the class of the data points when the probability estimates from our sigmoid functions fall at,public,hw3
b whiteboard justification for removing terms,on the mcle derivation in whiteboard b on the second to last line the frac sigma coefficient gets changed to frac i understand that sometimes constant coefficients can be removed because they are common to all possible values of theta and wouldn't affect the modal estimate but why isn't frac taken out along with sigma,public,hw3
logreg prediction,on our classification decision do we classify y as if p y x is higher than,public,hw3
f cannot run function linreg sgd,hi i am getting the following output from autolab when i run my package i'm scoring full points on all the other linreg functions except for sgd does anyone know why autolab wouldn't be able to run the sgd function grading script output cannot run function linreg sgd cannot run function logreg calcsg scores linreg readinputs linreg calcobj linreg calcsg linreg updateparams linreg sgd logreg readinputs logreg calcobj logreg calcsg logreg updateparams logreg predictlabels logreg sga,public,hw3
f invalid index to scalar variable,can any ta check my code to see why i get this error also when i try to print out the len of xtest it tells me that is a ny float we should do any modification of xtrain and xtest in this method so i am really confused what is going on,public,hw3
b logreg calcobj,does this function return a list of scalars just like the one in linreg so the logreg calcobj function adds the above values and then returns the logspace,public,hw3
office hours,can any office hours be added for before wednesday they're always so crowded and most questions can't be easily asked on piazza,public,hw4 logistics
write down update rule only a sentence,hi all i wonder for question like c are we only expected to write a single sentence like w w eta gradient with detailed form of gradient thx evan,public,hw3
g plot,can anyone clarify on what the x axis would be in the plot since the dimensions of xtrain and xtest are different we should expect different array size between trainerrorrate and testerrorrate then how do we make arrays with different size on the same plot and what would be the x axis,public,hw3
hw grader change,hi all the grader of hw has been changed the old grader doesn't check the normalization mentioned in a you should also use max x k and min x k from training set if your code is correct as per the handout instructions you should be able to pass the new grader,public,hw3
autolab submission,i see there are many posts saying that the autolab grading scripts have been modified and that the scores have been modified too i have got full marks in my latest submission but that might not be correct with regards to the latest autolab grading script do i have to resubmit my code because i have answered the theory questions based on the code that i have written and those might not be correct please clarify as soon as possible thank you,public,hw3
linreg calcobj,does linreg calcobj return a scalar or a vector thanks,public,hw3
a allowed to use sigmoid function assumption here,hi all as i see it to derive a useful conditional log likelihood function we should assume p y x w sigmoid function of w'x here is this allowed thx evan,public,hw3
i found the autolab is making some changes,will we extend the due for hw,public,hw3
linreg readinputs,incorrect normalization error is still showing i got points earlier and now it dropped to i am normalizing both train and test data also i haven't written any code for logreg updateparams and it is giving me full marks is there some issue in autolab,public,hw3
grade jumps from to,did anyone change autolab scripts of logreg calcobj logreg sga logreg predictlabels functions i got full credits pm this afternoon but now losing all points of the three functions logreg calcobj is not calculating the objective correctly off by nanexception encountered in function logreg sga invalid index to scalar variable exception encountered in function logreg predictlabels invalid index to scalar variable the error is suggesting some input has been changed to scalar,public,hw3
incorrect normalization,after passing logreg calcobj i lost points for linreg readinputs and logreg readinputs with the below error incorrect normalization incorrect readinputs function please do not normalize raw x and y in logreg i didnot normalize x and y in logreg i just added bias colums for xtest and xtrain and they were passing previously how can changing a function in logreg impact linearreg and readinputs has nothing to do with logreg calcobj why would it pass partially giving points,public,hw3
optimization for linear regression set gradient equals to zero then how to know it is min max,hi all in linear regression how do we know that the w mle that makes gradient equals to zero is actually the minimal point do we need to derive second derivative thx evan,public,hw3
autolab grading,after submitting q d the grade of q linreg readinputs dropped from to but i didn't even change that function anyone know why this happened thanks,public,hw3
stochastic gradient descent stopping criterion,could anyone tell me when stochastic gradient descent stops updating omega is the stopping criterion the same as that of the gradient descent also how can i plot validation error which set of data should i should what would the least point on the plot correspond to thanks in advance,public,hw3
confused about autolab problem description,the autolab says the truth value of an array with more than one element is ambiguous use a any or a all what does this mean,public,hw3
f ypred,should ypred be the output of the last iteration,public,hw3
cannot read inputs,i am getting the following error for linear read inputs can someone help error writing file ' home autolab octave hist' no such file or directoryerror ignoring octave execution exception while preparing to exit,public,hw3
q a standardization,if using max and min from xtrain and apply them to both xtrain and xtest will all elements in xtest lie in range as well thanks,public,hw3
does autolab give feedback on the code,i submitted my code and got zero on certain parts of which i thought the logic was correct i wrote a test script and it worked fine in the terminal does autolab give feedback on where the codes went wrong,public,hw3
d linreg calcsg,should the gradients be a vector sg where each element is equal to y i w i x i x i j like derived during lecture also with dimensions of x and w if k then x should be something like array but what should w look like array as well or array from class we derived that gradient is equal to yi txi xi here if w is k x matrix and x is x k matrix y wx would result in k x k matrix how do i multiply x which is x k matrix multiplying k x k and x k doesn't make sense to me,public,hw3
f iterating through the data set,hi i just want to clarify when it says 'each update counts as an iteration' and 'your function should iterate through your entire dataset times' does this mean that we should go through the rows of x i e the data points sequentially for data points and go through sequentially since we are told to 'not randomize training instances',public,hw3
logreg calcobj giving nan error,logreg calcobj is not calculating the objective correctly off by nani am doing in python and have tried by both ways dividing by n and not dividing by n but still this error persists can someone help,public,hw3
expected shape of linreg sgd return,what is the expected shape of trainloss and testloss i can pass all other functions for linear regression but not linreg sgd i implemented linreg sgd according to writeup i didn't see anything wrong with the code logics but failed the test i suspect it is because of the shape of return values,public,hw3
b hints,i check the whiteboard and up to the following point w argmin xw y t xw y argmin wt xt xw yt xw wtxt y yt y i do not know how to reduce the third term wtxty given the hints also i found that the hints wtr wt xt xw xt xw i am not sure about the meaning of the formula what is the meaning of tr,public,hw3
xi yi instead of x and y,when i are working on deriving parts i am wondering whether we can use xi and yi sometimes instead of x and y like in part a i review the white board but i really do not know how to write the function without xi and yi like there is a apart of the white board function yi w transpose xi and take product across i to i n i really do not know how to show this in vector form vector multiplied by vector are not a scalar,public,hw3
constants do matter an autolab note,hi all so the way autolab grading works we take your functions and run our own reference function on the same data if the outputs are the same you get full marks if the outputs are different then you do not so with cost functions j i w frac y i w tx i the constant frac doesn't matter we only have it in to make the derivative easier however since autolab is comparing two outputs if your answer is off by a factor of a half it is going to give you no marks so we are currently in the process of updating our pdf to try to match the changes to give you a indication of which you should be using some things to note are that the objective function for both linreg and logreg should be averages in this homework that is taken as frac n i feel like a lot of people have been getting caught out by this because they have just been translating matt's notes to code which usually works does not provide you with a good understanding of why it works i urge you to try to read into the math and understand what each pieces is doing this will give you a much greater understanding of ml and make you be more successful in the field kind regards daniel bird,public,hw3
c f error matrices are not aligned,i got the whole function running get the final result like this form but in autolab it shows the error below did someone have the same problem exception encountered in function linreg calcobj matrices are not aligned exception encountered in function linreg sgd matrices are not aligned,public,hw3
how to fix autodriver job timed out after seconds,hello when submit the hw to the autolab i get the time out response and there are no other feedbacks so what's the problem thank you,public,hw3
logreg calcsg sign issue,hi while calculating the derivative of log likelihood this is what was taught in class which was later simplified to the form but in the programming assignment the negative sign didn't allow me to pass the logreg calcsg function when i dropped the negative my program started working fine i am confused if my approach to drop the negative sign is correct as we are maximising the log likelihood it makes sense to maximise the positive value expression without the negative sign in front did proff matt make a mistake when he introduced the negative sign in rd line,public,hw3 other videos
question on logistic regression whiteboard,in the whiteboard b logistic regression matt used gd and sgd but aren't we supposed to use gradient ascent and stochastic gradient ascent in logistic regression instead of gd and sgd,public,hw3
linear reg final test error lesser than train error,hi in the linear regression part my final test error after epochs is lower than that of train error i don't think this happens much with large datasets as we are optimising on training set and not on test set anyone else observed this behaviour or did i possibly make some mistakes in my workflow,public,hw3
graph and handwritten answers,are we allowed to submit handwritten answers also for the loss graphs do we need to plot it using matplotlib or can we copy the values to an excel sheet and generate the graph in axcel,public,hw3
question on a,a requires us to write the formula for the conditional log likelihood of the training data using the feature matrix mathbf x the class labels mathbb y and the weight vector mathbb w but when i derive the formula i can't make it just contain these three symbols i also have sum ln and exp in my formula there are still some element wise calculations is that ok,public,hw3
constants do matter,hi all to get over autolab please please be careful about constants in objective function which determines constants in your gradient and also influence your stochastic gradient descent ascent result otherwise your time will be killed also we should divide cll by number of samples in logreg calcobj function at least for python users i don't know why but please do that and i really appreciate a errata pinned at top of q a forum it would save our life thank you and hope it helps evan,public,hw3
input type when testing on autolab,when i tested fuction linreg calcsg x y w i got some mistakes since the input type of x should be array x x x xn and w should be array w wm my question is does autolab automatically gives these type inputs or all it gives are two vectors in type of array and we have to change x and w into the right type ourselves thanks,public,hw2
linreg calcsg and linreg sga can anyone give me some hint,hi all i'm trying to pass on autolab with these two functions all other function get full score but i failed i don't even able to detect what's wrong with my function autolab simply reports linreg calcsg is not calculating the gradient correctly linreg sgd is not working as expected as i see it linreg calcsg gives wrong output while linreg sgd also somehow goes wrong i don't know why i simply use the same strategy in implementing linreg sgd almost the same as in logreg sga except for different output requirements and different epoch setting for linreg calcsg what i did is to simply translate below words into python code and finally output a k numpy array any help is appreciated thx,public,hw3
confused on xtrain and xtest standardization,here min xk denotes the minimum value of kth feature and max xk denotes the maximum value of that feature you need to use the same standardization formula for each feature in both the train and test dataset i saw one post answer is using min and max value of xtrain to xtest but i think i should choose the min and max value among all the kth column in xtrain and xtest am i wrong,public,hw3
do we need logreg calcobj call from logreg sga,i dont think we need to make any call to logreg calcobj from logreg sga can anyone else confirm please,public,hw3
a,i'm lost on the conditional log likelihood function is it the equation in summation notation sum log p x i y i theta but that isn't closed form also i'm not sure where x i and y i come from in this problem are those x and y,public,hw3
gradient descent vs ascent,is gradient descent always the loss function and gradient ascent always the likelihood function if so why do the loss function and the likelihood function always have opposite contours such that we minimize one and maximize the other,public,hw3
logistic regression representation,on whiteboard the logistic regression has such representation for p mathbb y mathbb x theta large p mathbb y mathbb x theta frac exp theta top mathbb x but on the mitchell's book the representation is different large p mathbb y mathbb x theta frac exp theta sum i n theta i mathbb x i may i ask what's the difference between these two representations and which version should we use in the homework,public,hw3
g plotting threshold difference,in prob g which is plotting and reporting number of epochs required for convergence do we report such number of epochs for the training loss and that for test loss respectively moreover what's a threshold difference thanks,public,hw3
normalize in log reg,no need to do that right only need to add bias column,public,hw3
how to test our function,do i need to write a script like hw script to test our function,public,hw3
inconsistency between latex template and writeup,hi all in latex template d is used but in write up it's different please clarify,public,hw3
f iter,in prob f which is the linreg sgd function is iter the indexing for each training example in a single epoch so iter goes from to number of training examples,public,hw3
a do not standardize features separately,what does it mean that we shouldn't standardize the features in train and test datasets separately the dimensions of train dataset and test dataset are different how can we standardize both within the same loop,public,hw3
linreg readinputs octave,dear instructor i am very confused about this function how can you give it a 'filepath' string parameter and get matrix that's soooooo ridiculous the csvread function need 'filename' rather than a 'filepath' to read a csv file could you please tell me how to do it,public,hw3
which score in autolab is used to determine our homework score,the latest submit or the highest score if i got a full mark but later submit a version with some error do i need to re submit the correct one again,public,hw3
b do we need to prove the two given identities,hi all in b it says following identities may help yes they do help do we need to prove the two identities or can we simply apply them thx evan,public,hw3
about the normalize,the function should also standardize each feature in the feature matrix to lie in the range by using the following transformation xk min xk max xk min xk here min xk denotes the minimum value of kth feature and max xk denotes the maximum value of that feature you need to use the same standardization formula for each feature in both the train and test dataset do not standardize features in train dataset and test dataset separately so it means i need to choose the max min in the every column just make sure thx,public,hw3
error in linreg readinputs,everytime i try running the readinput fucntion for linear regression i get the following error on autolab but my code runs properly on octave can someone please help me out errors if any octave x display environment variable not set octave disabling gui features warning linreg calcobj some elements in list of return values are undefined warning linreg calcsg some elements in list of return values are undefined warning linreg sgd some elements in list of return values are undefined warning logreg readinputs some elements in list of return values are undefined warning logreg calcobj some elements in list of return values are undefined warning logreg calcsg some elements in list of return values are undefined warning logreg predictlabels some elements in list of return values are undefined warning logreg sga some elements in list of return values are undefined error writing file ' home autolab octave hist' no such file or directory error ignoring octave execution exception while preparing to exit grading script output cannot run function linreg readinputs cannot run function linreg calcsg cannot run function logreg readinputs cannot run function logreg calcsg scores linreg readinputs linreg calcobj linreg calcsg linreg updateparams linreg sgd logreg readinputs logreg calcobj logreg calcsg logreg updateparams logreg predictlabels logreg sga score for this problem,public,hw3
logreg calcobj want to figure out where my understanding get wrong,hi all i wonder why my code for logreg calcobj goes wrong as instructed i calculate the log conditional likelihood here more detailed i simply follow these two formula below is that correct thx,public,hw3
meaning of tr,w tr wt xt xw xt xw what does tr here mean,public,hw3
g is there an specific convergence threshold,since the threshold for convergence can be arbitrary is it ok to pick a number as long as it seems reasonable or is there an specific number that we should be aiming for,public,hw3
c what is the correct notation to represent a column on a vector is x ij ok,what is the correct notation to represent a column on a vector is x ij ok,public,hw3
c d what is the difference between this two questions,aside of the fact that we need to write the gradient descent update rule what is the difference between question c and d don't i need to calculate the gradient on c to be able to show that minimizing the mean squared error is equivalent to maximizing the data likehood,public,hw3
training and testing error plots,do we have to plot both of them on a single graph,public,hw3
b how can i get rid of the transpose in the parameters w,is w tau x i x i tau w where tau is the transpose,public,hw3
about using numpy matmul,i finish my codes and it seems to work fine by my own testing however the autolab only gives points for two readinputs function and gives zeros for all other functions here is the grading script output exception encountered in function linreg calcobj 'module' object has no attribute 'matmul' exception encountered in function linreg calcsg 'module' object has no attribute 'matmul' exception encountered in function logreg calcobj 'module' object has no attribute 'matmul' exception encountered in function logreg calcsg 'module' object has no attribute 'matmul' logreg updateparams is not working as expected exception encountered in function logreg sga 'module' object has no attribute 'matmul' exception encountered in function logreg predictlabels 'module' object has no attribute 'matmul' scores linreg readinputs linreg calcsg logreg calcobj logreg calcsg linreg calcobj logreg sga logreg updateparams linreg updateparams logreg predictlabels logreg readinputs linreg sgd does this mean that i shouldn't use the function numpy matmul or i made some other mistakes,public,hw3
checking linreg readinputs,before i proceed with other functions i just wanted to ensure my linreg readinputs is correct i was able to test locally but when i submit to autolab i always get a with the following error is the grader not checking individual functions start running test suite errors if any traceback most recent call last file python grader py line in main file python grader py line in main grade log reg data dir file python grader py line in grade log reg w np random rand xtrain shape unboundlocalerror local variable 'xtrain' referenced before assignment grading script output linreg calcobj is not calculating the objective correctly off by exception encountered in function linreg calcsg 'int' object has no attribute 'reshape' exception encountered in function logreg readinputs global name 'xtrain' is not defined score for this problem,public,hw3
what does this error mean,codes work fine on my computer but got this error cannot run function linreg readinputs cannot run function linreg calcobj cannot run function linreg calcsg cannot run function logreg readinputs cannot run function logreg calcsg,public,hw3
logreg calcobj,the function's name is misleading do we have to calculate the objective function or the cll i have tried both however on autolab it shows that the objective is off by a large value not sure what the problem is as this is a straight forward application of the formula the permiscl is decreasing and the cll is increasing so i am not sure where the bug is any prods in the right direction all my other functions evaluate fine,public,hw3
f dimensions of trainerrorrate and testerrorrate,we need to calculate the percentage of misclassifications at every iterations this means that the length of the trainerrorrate vector is the number of multiples of in the length of xtrain here i am confused about how the number of epochs feature into this do i return the value of trainerrorrate after all epochs are done or if i calculate this for each epoch should i average over the number of epochs here,public,hw3
why am i getting this error,so i finished both linreg readinputs and logreg readinputs and wanted to check the code after i submit my code to autolab i got this error what does this mean the codes give the correct output on my laptop error writing file ' home autolab octave hist' no such file or directory error ignoring octave execution exception while preparing to exit,public,hw3
linreg calcsg x y w output form,should the output of the linreg calcsg x y w function be a in terms of np array k by numpy d array e g array a b c or just an numpy d array of length k e g array a b c or some different form i think my math is right but autolab gives me so i'm guessing my output's form is wrong thanks,public,hw3
what is numpy version in autolab,may i understand what numpy version is in use by autolab i can run my python script successfully in local but with exception in autolab exception encountered in function linreg calcsg matrices are not aligned i suspect it is because of numpy version,public,hw3
tom's notes gnb and logistic regression asymptotically converge towards identical classifiers,hi all in tom's notes on nb and logreg he says in fact if the gnb assumptions hold then asymptotically as the number of training examples grows toward infinity the gnb and logistic regression converge toward identical classifiers i guess it can be a result from law of large number can anyone explain that thx in advance evan,public,other
hw data type,hello when doing the hw programming i am confused about the data type of numpy matrix numpy vector numpy array or python list when does these works the same way i think they work in different ways since these give me some errors my question is for example for w sg should we use list or np array or np matrix or something else i think i meet problems when dealing with these types,public,hw3
c loss function,just want to make sure i'm understanding the terminology correctly would the function frac n x cdot w y be equivalent to frac n sqrt sum i k x i cdot w y where x i is the ith feature of x so an nx vector do the dimensions line up here is there something i'm not thinking about,public,hw3
c linreg calcobj,what does it mean by exception encountered in function linreg calcobj operands could not be broadcast together with shapes even when i reverted my code back to def linreg calcobj x y w tlossval treturn lossval autolab still gives me the same error,public,hw3
hw question g,hi the problem statement states that we have to plot trainerrorrate and trainerrorrate against stochastic gradient ascent per iterations but by the end of each iteration sga is k vector do we have to average out all k elements and plot error rates for it how do we go about it thanks,public,hw3
oh,my oh are from pm today at hbh sorry for the late notice,public,logistics
cant get into oh,i think only ece majors can get to the rd floor all the doors are locked for me,public,logistics
answers to past homework in qna,i got number wrong on homework in qna so i want to go back and solve it correctly it would help if i could check my answer against the correct answer but the incorrect answer text doesn't reveal what the correct answer is so i have the following questions what was the correct answer to that question could the course administrators please include the answer in the help text thanks,public,hw2
numpy vector dimension,for numpy array are n x matrix and x n matrix the same or is there a way to differentiate between them e g np zeros initializes a x n matrix i e an array or a row vector with all zeros is there a separate way to initialize a n x matrix i e a column vector,public,hw3
q c,i am not able to understand norm is x means sqrt x x x,public,hw3
a getting,i tried submitting the code after only completing the part a linreg readinputs just to check if i did it correctly i keep getting the question is should i be receiving if i didn't complete the other functions or should this be a problem with my implementation for sure the log says errors if any traceback most recent call last file python grader py line in main file python grader py line in main grade log reg data dir file python grader py line in grade log reg w np random rand xtrain shape unboundlocalerror local variable 'xtrain' referenced before assignment,public,hw3
q clarification,i'm not sure if i'm thinking about this the right way any guidance is appreciated for either of these questions given that p d w p x y w p x y w p y w how are we supposed to know what p x y w is is p y w the gaussian distribution where y n w tx sigma in part b it is unclear to me how the vector w tx i can become w tx with x being the entire matrix of feature vectors the summation in the function for finding the mle should sum each w tx i with the y vector and this occurs individually right in the hints is the w matrix the same size as the x matrix n x k then and w tx is more illustrating that the same operation occurs for every row of x,public,hw3
errors in autolab,what's the meaning of the following errors errors if any octave x display environment variable not set octave disabling gui features error writing file ' home autolab octave hist' no such file or directory error ignoring octave execution exception while preparing to exit,public,hw3
autolab comments on other functions,i did the coding part for linear regression a and b so only the linreg readinputs filepath function i submitted to autolab to check if i coded this function correctly i got a on everything including this function but the comment says nothing problematic about this function and only mentions about other functions which i haven't worked on yet is this something that is supposed to happen,public,hw3
generative vs discriminative learn step,hi all i am confused about learn step when professor compared generative and discriminative model in generative model p x y theta is multiplied together as a likelihood function while in discriminative model p y x theta is multiplied together as i see it i can use naive bayes to represent generative model and use logistic regression to represent discriminative model when i estimate theta for my nb classifier in hw what i do there is simply estimate p xw y and p xw y they are denoted as theta i don't see a process that multiply all p x y theta together and find the best theta but in logistic regression i do find such a process can anyone explain thanks in advance evan,public,other
changes in homework,could someone please highlight the changes updates made to homework i am unable to identify the differences between the two versions of the handout,public,hw3
logreg calcsg and logreg updateparams,in logreg calcsg the output argument for stochastic gradient is retval the next question requires the value from this function but its input argument is called g is it okay to rename the output argument in the previous part to g also the argument is called g in the pdf and sg in the starter code,public,hw3
the difference between and in p,what does p theta y x or just sign in p mean here,public,other
q a what to do when max min,when all the training values for a particular feature are the same max min should we normalise these values to or vidhan,public,hw3
getting error on autolab but program is running locally can anyone help,autodriver job exited with status rm rf autograde tar mxvf hw tar hw hw linreg py hw logreg py tar mxvf autograde tar dev null ls py m xargs cp t autograde dev null ls cannot access py no such file or directory ls cannot access m no such file or directory make all error,public,hw3
g trainloss and testloss plots,do we have to print out the convergence epoch number for trainloss and testloss separately or for testloss only and do we have to find that manually or do we have to use a threshold difference to get that number,public,hw3
importing matplotlib,any idea how to fix the above error,public,hw3
input xtrain error,hi could someone please help me with this i keep getting this error i think it's to do with the testing script on autolab when it is trying to access xtrain xtrain is being read properly when i run locally just to see if it would throw another error i commented out xtrain and tested it and it does throw a separate error saying xtrain wasn't declared so i don't know what this error is referring to,public,hw3
number of features,in prob for each row in the n by k matrix x is the setting x already done and so there are k features of x's and k entries in w or is it that there are originally k features x x k and there are k entries in w,public,hw3
square of vector's magnitude,is left vector right quad equal to the square of the magnitude of the vector e g hw part c,public,hw3
latex template,would the graders mind if i removed the text in the latex template irrelevant to the question being answered e g problem descriptions submission instructions instructions etc,public,hw3
file path used to load files,so if i wanted to use my linreg readinputs function to load the files what file path should i give it,public,hw3
dimensions,just wanted to clarify in part a w is a k by matrix i e a vector and each x i is a by k matrix is this right,public,hw3
can we inverse x'x how to analyze this problem,hi all as mention by professor given that n is the row count of x and m the column count of x whether inverse of x'x exists x' here stands for x transpose here depends on relationship between m and n i know that a matrix a has inverse only if it is full ranked but why we should consider whether x is full ranked here can anyone explain why and how also why m and n seems to have different role here any help is appreciated thanks evan,public,other
function linreg sgd matrices are not aligned,hi i run the linreg sgd on my pc and it can return the vector w and trainloss testloss however it is not working on the autolab which returns exception encountered in function linreg sgd matrices are not aligned please help me understand what is going on submitted as junrongh andrew cmu edu appreciated,public,hw3
f linred sgd,in the homework handout it says that this function has inputs xtrain ytrain xtest and ytest but in the code the inputs mentioned are only xtrain and ytrain what inputs should i take,public,hw3
about the linreg sgd xtrain ytrain xtest ytest,in my linreg calcobj function i print wx y in python is there any difference between their shape i always get this error valueerror operands could not be broadcast together with shapes other functions in linear regression part return me full mark except for this function,public,hw3
f randomization,if we don't randomize our training instances how do we choose the x y to call linreg calcsg on,public,hw3
question on linreg sgd,when i run linreg sgd on my pc i have obtained a training loss vector with dimensionality and ranges from over to about i go through the training dataset for times and each time i calculate the w and losses but i still get score for linreg sgd does anyone know why is that,public,hw3
use of logreg calcobj in sga,should we use logreg calcobj function while implementing gradient ascent algorithm i'm not able to understand its usage in sga,public,hw3
logistic regression where y is one of many values,this is from page of mitchell's writing about nb and logistic regression why is the numerator for y y k,public,other
autolab q,nvm i cant read,public,hw3
logreg calcobj should i multiply theta times x or the other way around,should i be using theta tx as my probability function becasuse theta is a vector with dimensions x m and x is also vector with dimensions x m thus theta tx is going to give me a full matrix which i don't think that's what we want on the other hand i can do x theta t to get the scalar is this the correct way if it is why did we have the other method on the lecture,public,hw3
functions tested independently in autolab,do scores or testing for one function in autolab affect the scores or testing of other functions in autolab for example autolab grades everything as a zero unless logreg readinputs is completed another stranger thing i've noticed is that without changing the code of linreg updateparams whatsoever in between submissions while changing the code of linreg sgd my score for updateparams oscillates between zero and perfect while my score for linreg sgd remains zero why would changing code for one function affect if another function passes the test cases,public,hw3
linear regression readings ch from tom mitchell's book,hi all i find ch from mitchell's book introduce neural networks but not linear regression is it a typo in our schedule thx evan,public,other
hw f linreg sgd,hi prof i came across this problem with linreg sgd i check the result from my terminal and it seems correct and all other part have full marks where is the problem what is the correct format about the initialization of w and trainloss simply a vector shape x or it has to be np array which shape is x y wait for your reply exception encountered in function linreg sgd setting an array element with a sequence,public,hw3
matrices not aligned and not normalized,hello i'm having two problems with autograder that i can't quite figure out i'm submitting in python i'm getting a matrices not aligned error with linreg calcobj and linreg sgd my calcsg function works fine i'm not getting any errors when i run the code and my matrices have the following shapes in sgd xtrain x ytrain x xtest x ytest x sg x w x all matrices in calcobj they are of the same shape the only matrix subtraction and multiplication i do is diffsmatrix x w y after that it's just squaring values and taking square roots i output a float value for lossval i'm also at a loss as to the normalization error that i'm getting when i inspect the x matrices output by my import function the values range from to inclusive the main normalization line i am using is xtrain rowidx colidx xtrain rowidx colidx mincol maxcol mincol where maxcol and mincol are the max and min values across training and test datasets in the current feature column thanks for any help michael,public,hw3
office hours today at,there are several of us waiting outside ghc but no ta is the oh cancelled,public,logistics
d linreg calcsg,in the recitation slides x is a column matrix k x but in the code x seems to be xk matrix please clarify this because i've tried all possible combinations and autolab grades me,public,hw3
problem in reading input,can someone please tell me why does this error come up errors if any octave x display environment variable not setoctave disabling gui featureswarning linreg calcobj some elements in list of return values are undefinedwarning linreg calcsg some elements in list of return values are undefinedwarning linreg sgd some elements in list of return values are undefinedwarning logreg readinputs some elements in list of return values are undefinedwarning logreg calcobj some elements in list of return values are undefinedwarning logreg calcsg some elements in list of return values are undefinedwarning logreg predictlabels some elements in list of return values are undefinedwarning logreg sga some elements in list of return values are undefinederror writing file ' home autolab octave hist' no such file or directoryerror ignoring octave execution exception while preparing to exit grading script outputcannot run function linreg readinputscannot run function linreg calcsgcannot run function logreg readinputscannot run function logreg calcsg scores linreg readinputs linreg calcobj linreg calcsg linreg updateparams linreg sgd logreg readinputs logreg calcobj logreg calcsg logreg updateparams logreg predictlabels logreg sga score for this problem my code runs properly on octave on my pc,public,hw3
setting an array element with a sequence,hi prof when i submit the solution linreg sgd report zero but other methods are full mark and autolab told me exception encountered in function linreg sgd setting an array element with a sequence when i check the result it seems correct so can you tell me what wrong,public,hw2
linreg calcsg x y w,y actual output for the input x y is a matrix or just a value,public,hw3
about the grader,if i only finished the linear regression part actually i am not starting logistic part yet could i only test linear reg part on the autolab would autolab give me part of the grade if i do some of the functions correctly but i would hand out the tar with both files linear and logistic,public,hw3
question on linreg calcsg,i tried several ways with and without as the coefficient to calculate linreg calcsg but never passed can anyone give me some advice on the implementation of this function,public,hw3
c,the question asks us to minimize the cost function using gradient descent but the equation used in error function l w is n x w y shouldnt it be and not n since we using gd if it were sgd it would be n right,public,hw3
question on stochastic gradient descent,in lecture matt said that we can use a to eliminate the from the exponential part when we derive the stochastic gradient value from a specific data point but in homework i only see a n should i keep the in my stochastic gradient value i see both euqations w w eta x w w eta x in several places when should we use plus minus sign in the gradient descent update process,public,hw3
reading from,can anybody explain how l' w can be stated as identity matrix with all eigenvalues equal to here,public,other
f when to use train vs test data and value of eta,for question f implement linreg sgd i am not sure when we are supposed to use the training and test sets respectively and what the exact values for eta should be can someone please let me know if the following understanding is correct or not in each epoch we are supposed to execute linreg calcsg and linreg updateparams using only the training datathen after we have the updated value for w we should run linreg calcobj for both the training and test data once for each set as mentioned in the handout eta should be square root of iter should iter be reset to at the beginning of each epoch or should it continue increasing that is if in the last epoch iter reached the value of then in the next epoch it will start from,public,hw3
f incredible large testloss,for some reason my testloss shoots up very high for their first two epocs but then converge immediately towards the function works completely fun with training data and after epoch it converges to around after further testing i'm pretty sure it's a test data set issue but this presents another problem if i include both plots into the same graph testloss will be very overpowering and trainloss will be hard to see should i submit two figures instead,public,hw3
definition for dot product between matrix and vector,can i have the mathematical definition for the dot product between a matrix and vector as used in c i assume we multiply either the rows or columns of x with each element of w except w has n elements so it should be a summation from to n but then that means we do it for rows of x but that results in a vector with k elements so how do we subtract y which has n elements the dimensions don't add up can i just have a definition,public,hw3
wrong readings for linear regression,the slides mention we should readup from mitchell's book but these sections have nothing much to talk on regression or gradient descent i think the relevant section is can someone please confirm,public,hw3 videos
recitation slides,have the slides from today's recitation been posted yet i can't find them under resources,public,hw3 other
problem in standardize each feature in the feature matrix,hi everyone in homework question it says the function should also standardize each feature in the feature matrix to lie in the range by using the following transformation and they gave a formula in min and max but the given formula is of normalizing data and not standardizing data std x mu sigma please correct me if i'm wrong thanks,public,hw3
issues submitting on octave,i am receiving an error when submitting my octave code that i can't decipher an error occurred while parsing the autoresult returned by the autograder error message unexpected token at ' ' this looked similar to a question that someone posted about an issue they were having with a python submission except i don't think the solution to their question applies to me does you have an idea of what the issue may be,public,hw3
a linreg readinputs score,i submitted my code by completing the linreg readinputs function it is working correctly in my computer but when i upload it autograder give me a score of i checked the autograder message there are errors reported about other functions eg linreg calcobj and logreg readinputs but nothing is mentioned about any error in linreg readinputs the only problem in my code could be in determining what to use for x min and x max but i tried using the min and max of xtrain only as well as min and max of xtrain and xtest combined in both the cases my grade is still could someone please give me some hints about what i could be doing wrong,public,hw3
lin regression coding part f,for our implementation of linreg sgd should our epoch number start at or start at in appending our train and test loss vectors should we compute this before or after we train with sgd e g for the first element in these vectors will it be the result of calculating the loss with a weight vector of all,public,hw3
hw question a b,hi tas i cannot pass the autolab for hw linreg readinputs and logreg readinputs the error says that ioerror errno no such file or directory ' data linreg xtrain csv' ioerror errno no such file or directory ' data logreg xtrain csv' need help on my code about inputing files code submitted as junrongh andrew cmu edu appreciated,public,hw3
a clarification,the write up says you need to use the same standardization formula for each feature in both the train and test dataset do not standardize features in train dataset and test dataset separately can someone clarify this for me because it seems a little contradictory do we calculate the standardization for each feature using the train dataset and apply it to the ith feature of the train data set as well as the ith feature of the test dataset otherwise i don't understand,public,hw3
issues submitting using octave,hello i am receiving an error when submitting my octave code that i can't decipher an error occurred while parsing the autoresult returned by the autograder error message unexpected token at ' ' do you have an idea of what the issue may be thanks max,public,hw3
hw question e,hi all i wanted to add two important clarifications about question e in homework the first part of the question has a subtle error now corrected the correct statement is if you train logistic regression for infinite iterations without l or l regularization the weights can go to infinity that is they don't necessarily go to infinity but they can in certain situations for example this can occur when there is a feature m such that x m i in all the training examples where y i but x m i in all the training examples where y i to answer the question what is an intuitive explanation for this phenomenon you should think through the gradients in this situation from there it should become clear how theta m could end up running off to infinity the second part of the question asks you to explain how regularization can help correct the problem of parameters running off to infinity this is a great question however you don't yet have the background to properly answer it please wait until after class on monday to answer this question it will be a rather simple answer in the end sorry for the inconvenience cheers matt,public,hw3
maximum conditional likelihood estimate,when i take the derivative of the conditional log likelihood estimate i get a scalar multiplied by a vector how do i set this equal to and solve for the mle of w,public,hw3
f loss values,could someone explain the meaning of the term loss values trainloss testloss or give a definition thanks,public,hw3
problem d,can someone explain the size inputs and output for linreg calcsg x y w x is a k y is a scalar w is k so the output is k am i right,public,hw3
can i write my work using word and submit as pdf,can i write my work using word and finally submit as pdf,public,hw3
vector in numpy,i got in all the cases but i can run it locally am i supposed to use n or n in numpy i didn't even pass the first test case,public,hw3
linreg calcobj x y w,xtrain nx k numpy matrix containing n number of k dimensional training features do i need to add column contain to the xtrain xtest,public,hw3
dimensions of w weight vector,hi in the programming questions what are the dimensions of w is it a row vector or a column vector thanks and regards arashnoor singh minhas,public,hw3
a,should that be logp y w x sigma instead of logp d w,public,hw3
logistic regression sga,should we assign a fixed length to trainerrorrate testerrorrate,public,hw3
about sgd process,i am a little confused about what action we should do to the train data and test data should we only implement sgd to train data and after obtaining the w using the w in the test data just to see the test error or should we implement sgd to both train data and test data to get the train loss and test loss,public,hw3
choosing a learning rate,for implementing sgd for linear regression how should we choose our learning rate eta i reviewed the whiteboard notes but couldn't find any further information,public,hw3
logistic regression programming part,what is retval in logreg readinputs shouldn't it be xtrain xtest ytrain ytest as in linreg readinputs,public,hw3
autolab python submission,the autolab had been working properly until pm today it was able to give me feedback and corresponding scores before but now keeps giving me error message after pm i literally submitted the exact same files an error occurred while parsing the autoresult returned by the autograder error message unexpected token at '',public,hw3
estimating parameters for logistic regression,hello when reading estimating parameters for logistic regression i do not understand the following part very well can anyone give some description about this why we assign p y x like this or how to compute this thanks,public,other
what is minimum variance unbiased estimator,on the reading material of lecture mitchell's book chapter page there is a minimum variance unbiased estimator what is it exactly and why add in the denominator shown in above figure,public,logistics
generative vs discriminative models,can someone please explain generative vs descriminative models in simple terms,public,other
filepath in linreg readinputs filepath,what is passed in the filepath to the function readinputs filepath solved its the path to the folder with all the files,public,hw3
no office hours this week,hi all i am traveling this week and need to cancel my office hours on friday they will resume as usual next week,public,other
gradient of j,in lecture while defining the gradient of j we took a vector of m partial derivatives here is 'm' the number of parameters and what is n while defining sgd,public,videos
epoch and iteration,in the linear regression sgd part since we are randomly selecting data instance how will we know that one epoch has completed if the selections are random then we might not even cover the whole data instances or are we looping over the training examples one by one in no random order and one complete loop is referred to as an epoch and repeat for epochs if this is the case then how is this stochastic,public,hw3
standardization in programming part,it is written in the writeup do not standardize features in train dataset and test dataset separately what does this mean is the x k minimum value of feature over training and test data combined,public,hw3
hw python submission,i kept getting point after i turned in my hw tar i am pretty sure that i include all required files and my code could run in my machine the following is the feedback i received from autolab could you please help me out i will appreciate it an error occurred while parsing the autoresult returned by the autograder error message unexpected token at '' autograder wed feb success autodriver returned normally autograder wed feb here is the output from the autograder autodriver job exited with status rm rf autograde tar mxvf hw tar logreg py linreg py tar mxvf autograde tar dev null ls py m xargs cp t autograde dev null ls cannot access m no such file or directory cd autograde tpython grader py trying to determine the programming language you used good python detected start running test suite score for this problem graded by,public,hw3
meaning for least mean squares lms,i still confuse about the sgd and gd if y y y y y yn t x x x x x m xn xn xn xnn does gd means we need to consider every single x x to xnn under each yi y yn but does sgd mean only need to choose one of the x through each rows in this case there are n rows so why it is a least mean squares algorithm,public,other
first time autolab user,i just submitted my ps late in python and i got zero for every function since i have consulted the ta i think at least some parts are right how can i check the feedback for errors on autolab thanks,public,hw2
question on whiteboard notes in the gradient descent section,should there be a n before the summation symbol at the last line in the following from the notes i think we said the expectation of the random picked gradient should be the gradient which gives a n thanks,public,other
linear regression representation,i am watching the class video for linear regression i am confused about the notation used in class if we have x matrix that have features in row and samples in columns should the representation be y x trans theta instead of y trans theta x,public,other
access to gradescope,hi prof what is the entry code for gradescope registration it seems like i didn't receive any email about that look forward to your reply,public,hw3
about readinputs,i am confused about how to use the parameter 'filepath' in the readinputs function in octave should i just simply put the 'filepath' in the csv cell as a parameter can anyone help me,public,hw3
linear regression hw submission,i am trying to tar the files in octave and find that linreg main m is missing in the handouts it says that if we are missing any function specific files autolab gives zero are we supposed to put in linreg main m when i am submitting the code it says cannot run function xxxxx,public,hw3
question about expression of linear algebra,in previous lecture hat y theta t x i but theta in r k x i in r k the dot product of this term should be n n but what we really want is a scalar is there a typo or we define theta differently,public,hw3
collaboration policy,should i mention something in the collaboration section if i have discussed problems with someone not currently enrolled in this course,public,other
sgd algorithm with runtime n,could you provide a resource that explains the algorithm for the most optimal implementation of sgd,public,other
hw f,will autolab give a perfect score only to the most optimal solution or will a slightly suboptimal solutions be considered at par assuming we use the most optimal implementation of sgd,public,hw3
bias in the naive bayes for continus inputs,on the page of the reading http www cs cmu edu tom mlbook nbayeslogreg pdf it says that mle for standard deviation of equation is biased but what do they mean by this and how does equation solve this problem other,public,other
request for lecture video of wed feb and mon feb,when i got into our course website i cannot find the link of these two day's lectures could you add links to the schedule page since i want relook some of the parts of these lectures thank you,public,other videos
questions about q,i believe that the ith column of the big x in question should be the training samples rather than rows otherwise w tx will not be a scalar tell me if i am wrong,public,hw3
about hw,just feel curious i notice syllabus shows there are total hw but the course description is only hw so how many homework will we have in total,public,other
please release required readings in advance,would it be possible to release the readings required for a particular lecture a bit ahead of time it would work well for us to go through the material before attending the lectures,public,logistics
hw linear and logistic regression,hi all homework has been released and is due at pm the handout of which you can download from autolab the assignment consists of parts a gradescope submission section and an autolab programming section read the instructions carefully and be sure to submit everything to the correct place the gradescope questions can be either handwritten or completed by modifying the latex document in the handout the autolab section is similar to the naive bayes programming you completed last week you may use python or octave there will be a recitation covering materials in this homework this thursday at pm in ph also be sure to fill in the collaboration questions found at the end of the write up into gradescope too good luck,public,hw3
cannot determine programming language,bad cannot determine your programming language from your source files hint did you write your answers in the same programming language and name them properly,public,hw2
only length arrays can be converted to python scalars,i'm getting this error typeerror only length arrays can be converted to python scalars when i try running my code it happens when i'm calculating values for yhat in nb classify i looked up the error and it seems like it usually happens when you call math library functions on numpy objects however i'm not calling math anywhere has any one experienced this any pointers would be very useful,public,hw2
does the mle for p y count as a parameter,when answering problem does the mle for p y count as a parameter for the model under nb assumption,public,hw2
hw grades available on autolab,final scores for hw combined score for background test and exercises are now on autolab out of all submissions the mean score was with standard deviation of note late penalties have not yet been applied so if you submitted any of your qna late you might receive a deduction later,public,hw1
value of p for nb classify,what value should we use for p,public,hw2
oh cancelled,hi i am th floor ghc is the oh cancelled or postponed for today vidhan,public,logistics hw2
qna q,could someone help me or give me a hint on how to compute the posterior probability distribution for problem i e p theta it seems to me that the posterior does not depend on theta,public,hw1
edward's oh,earlier today i saw edward's oh on the calendar for today but they are no longer there have these been cancelled thanks,public,logistics
stochastic gradient descent,i was reading about sgd on wikipedia there it is written that instead of calculating full gradient matrix gradient over one randomly chosen example is calculated but from my understanding of professor matt lectures i think that the gradient over one randomly chosen feature is calculated he explained on the d error contour graph over x and x that instead of traversing diagonally to minima sgd traverses in straight lines randomly over either x or x if that's the case the gradient is calculated over features right probably i have misunderstood the logic he was trying to explain could anybody explain the correct logic,public,other
mcle,in the last part of today's lecture professor gormley wrote mcle what does mcle stand for thanks,public,other
are the homeworks weighted equally in our final grade,are the homeworks weighted equally in our final grade,public,logistics
q q which is the right way to calculate p t t,currently i have two methods p t t p t cancer p t no cancer p t cancer p t no cancer p t t p t t cancer p cancer p t t no cancer p no cancer which is the right way and why those two are different,public,hw1
classify,for nb classify i'm creating a list of all the respective log prob of each x however i'm confused as to when we need to include log p for y and log p when y do we do it after we logprod the list like let's say i have proby is the list of probabilities for an article assuming y and proby is the list of probabilities for an article assuming y would i logprod proby log p and logprod proby log p or do the log p and log p for each probabiilite,public,hw2
stochastic gradient descent,if we have all the time in the world is there any case when sgd is not the optimal strategy for optimization,public,other
pkg undefined error,i am trying to run my files but due to the pkg not being recognized i can't test them can someone help,public,hw2
section c in person attendence,hi section c you are now welcome to attend either section a or b in person there seem to be plenty of seats now of course the same restriction as before still applies if there is not a seat for some reason then you can not attend due to fire code restrictions cheers matt,public,other
lecture missing from panopto,lecture seems to have disappeared from panopto it was there a few minutes ago but now is gone was it taken down intentionally there is information on that lecture we need to complete the homework,public,videos
q doubt about calculating probability of getting some data,suppose i pick powers of there are powers of possible while calculating the probability of this data occurring do i calculate it as or think that of these possibilities of output have been explored in the data i got so it should be,public,hw2
anyone can open qna,i can not qna and it says it's adding new features i need finish my homework what can i do,public,hw2
medical q q,i am just wondering whether my approach is right we want to find p cancer postive and negative we can find p negative and positive cancer p postive cancer p negative cancer is this right after that we know p negative and positive cancer p negative and positive and cancer p cancer knowing p cancer we can find p negative and positive and cancer after that we can find p positive and p negative and find the p cancer and positive and negative p positive and p negative is this right especially the first part,public,hw2
q q q,i have already reviewed the related posts on q and q but still a little bit confused we should get p theta d which is equal to p d theta p theta which is equal to mle and priori product but in q and q we assume the probability for prior is the same which means each distribution is equally likely so are we assuming that we are compare mle since it is the only different part and for q the question given some different prior for each distribution we need to multiply the mle and the prior and compare them,public,hw2
classificationerror example,i keep getting a zero on classificationerror i wanted to confirm that i have the question right for yhat and ytruth the result would be since they disagree on of the outputs,public,hw2
nb xgiveny,i'm getting half points on nb xgiveny i'm not sure what to look for the autograder doesn't really say much any suggestions recommendations thank you,public,hw2
confused about classify,i'm very confused how to integrate the vectors from xtest into how yhat is calculated don't we only need matrix d and probability p,public,hw1
homework,when will we receive our homework grades,public,hw1
autolab submission error,problem reading output of logprod problem reading output of nb xgiveny problem reading output of nb yprior problem reading output of nb classify problem reading output of classificationerror,public,videos hw1
q sample space for each problem,it states that p a b is the probability that the person reports outcome b given that the actual outcome was a so while calculating the mles in each problem should our sample space be the entire set x or the subset of x that corresponds to x i a,public,hw2
octave fail to open after update,i update homebrew then suddenly octave is unable to be opened could any one familiar octave advise how to solve this issue i really need octave to complete my homework i tried uninstall and reinstall many times but still fail error code dyld library not loaded usr local opt suite sparse lib libsuitesparseconfig dylib referenced from usr local bin octave reason image not found,public,other
problem reading output of nb xgiveny,this was asked in and but no one has posted an answer when i run the nb xgiveny function in autolab it gives this error trying to determine the programming language you used good python detected start running test suite problem reading output of nb xgiveny the output size and type are even if i just return an array of ones or zeros it gives the same error has anyone figured out why this happens thanks,public,hw2
what is the meaning of sigma not shared in the lecture slides,can anyone explains this to me thanks in advance,public,other
q is f x a pdf,is the suggested p d f of x f x x leq x leq a valid p d f i mean it doesn't integrate to right i maybe missing something really stupid,public,hw2
qna mle decision making,the question mentions we should based on the mles calculated for the three distributions to choose the model but what evaluation criterion we should use to choose model just compare mles the bigger the mle the better the model i don't know can anyone give some hint thanks in advance,public,hw2
q,hi in q why we need to compute alpha first by answering q we have a equation which only have xi and n being unknown right why couldn't i just substitute n and each xi one by one using the given dataset and get the mle alpha directly thanks,public,hw2
how to approach q,i have no idea how to approach the q what is the meaning of map estimate of x given that y is observed i know map should be argmax theta p d theta p theta what how is this related with p x p y and p x y what is the function that we are try to maximize,public,hw2
coding style,will we be graded on coding style for homework,public,hw2
map,how do we calculate something like p d theta where theta pr x y would it just be the number of articles of type where x is divided by the number of articles of type,public,hw1
qna no correct answer,in class notes and mitchell's book i know that we need to estimate n parameters but in qna i cannot see this answer is that my understanding wrong thanks in advance,public,hw2
q,i don't quite understand that what does it mean in q that comes back negative of the time it's so unclear,public,hw2
qna we are working on adding new features check back shortly,hi all it seems we cannot log into qna for now when can it fixed,public,hw2
experiment,i am confused for two reasons mitchell says that frac theta beta theta beta b beta beta is the beta function the handout uses alpha and beta instead of beta and beta that is ok however it says that the beta function is the is the denominator b alpha beta despite the divergence b should be a normalization function that integrates everything to one is there a formula for this is it part of the assignment to discover this b should we plot without normalization,public,hw2
how do i start,how do i begin homework i understand naive bayes but i dont know how to begin any help,public,hw2
nb yprior,i do not get it is a mle for a bernoulli distribution but my autolab score is i do not want the answer but could anyone give me a hint to reinterpret this problem and put me on the right track,public,hw2
qna problem test error from the smaller larger training set,hi all does test error from smaller training set means using classifier trained from smaller training set and derive classification error on xtest or does smaller training set specifically means xtrainsmaller and ytrainsmaller thanks evan,public,hw2
qna problem which test set to test on,hi all it says train your classifier using the smaller training set xtrainsmall and ytrainsmall report your classification error on the test set below what does test set below here means xtest or anything else thank you best evan,public,hw2
q,i'm trying to follow along with the notes on mle but i don't think the solution strategy in the notes applies to question i have p d theta frac b a where theta a b then frac d da frac b a b a then what do i set this derivative to then take a i never even used the actual datapoints so this strategy seems wrong,public,hw2
can't run scrip py,when i tried to run the scrip py it shows this vocabulary list x for x in reader csv error iterator should return strings not bytes did you open the file in text mode how can i fix this,public,hw2
map estimate vs mle,is the map estimate the parameters that with the best prior while the mle is the parameters with the best posterior i'm a bit confused about what these two estimates are on a high level,public,hw2
code submission,hi do we have to submit our code anywhere else apart from running it on autolab,public,hw2
nb classify logspace,hi i'm getting on my classify function and based on previous piazza posts it seems like the log space is the problem i have taken log using numpy log functions i took log on theta values in d and p before multiplying them together i used logprod which is similar to sum function to add all the values together in each row and converted the value out of log space and the problem is still occurring any suggestions,public,hw2
nb classify,my y predicted turns out to be all zeros when i train it autolab gives me a has anyone faced this issue,public,hw2
suggestion on question summary format,hi all as there are lots of questions to solve for each homework i suggest using qna as a prefix for example to ask a question related to that specific problem it will make us search for wanted discussion more easily for example qna what does conditional independent stand for best evan,public,hw2
plot of pdf over theta wy,in octave when i use the plot function my command line hangs has this happened to anyone else,public,hw2
q and q qna,so for q i was ale to analytically solve the minimization problem and then evaluate the closed form solution to find alhpa sq mle i attempted to do the same for q but the prior in there adds an extra term and i was unable to find a closed form solution it would not be hard to solve using a minimization routine on the log or alternately numerically solve the derivative equal to zero using fzero root finding in matlab or something however my inability to find a closed form makes me think i did something wrong i guess the question is are we expected to use numerical techniques optimization root finding on the qna portions of the homework and specifically for hw q,public,hw2
questions about sgd,hi when we are randomly choosing one observation from our training sample at each step to calculate the gradient is it a problem that we only use part of the samples in the entire process or if we happen to select the same observation at each iteration will it affect the efficiency of the algorithm is there mechanism to guarantee we don't trap ourselves in only a small portion of the samples thx,public,other
q hypothesis category for mle,which hypothesis would be the mle for the true category your friends use considering that there are more even number days in the year isn't this kind of obvious hypothesis choice for mle i hope i'm looking at it the right way can any one clarify,public,hw2
q q how do i pick the best hypothesis,we can use mle map to estimate the parameters after assuming that the data is coming from a distribution can someone guide me on how i should go about picking the best hypothesis would i need to use something like an error measure like mean squared error on how data would fit into the chosen distribution,public,hw2
question problem's meaning,hi all in hw question now suppose someone else observes the coin flip still denoted by x and tells you y the outcome of the flip but this person only reports the correct result with probability p does it mean what actually happens is but the guy who sometimes lies says it is then what's the probability that the cheating guy tells the truth according to this interpretation i don't think it is a solvable problem update does it mean we can take the guy lies as an event and gives a mle of p event happens,public,hw2
how to compute beta prior distribution,so in order to compute the beta prior for nb xgiveny i'm using scipy to obtain the beta pdf however for the inputs and the two possible values for y the output of the beta pdf always seems to be or infinity which doesn't make it a useful prior is this the proper way to compute the beta pdf,public,hw2
problem reading output,i'm getting a problem reading output error for all of the functions except for log prod but it seems like the type is correct and nb xgiveny runs fine with the appropriate dimensions on one of my test cases on my computer any suggestions on how to fix this additionally for nb yprior should i just take the number of zeros in the matrix and divide by the total number of entries in the matrix,public,hw2
qna question,i'm able to get p person has cancer first test positive and p person has cancer second test negative i'm not sure how to use these two result to formulate a final answer for question thanks for the help,public,hw1
hw script py where to turn in,i don't quite understand the sentence that you are asked to turn the file but not submit the script itself where and how we should turn in the script py file where can i check the grade for last homework thank you for anyone who can help,public,hw2
problem reading output of nb xgiveny,hi sir i have just implemented the function nb xgiveny what i return is a v vector however the autolab shows that problem reading output of nb xgiveny could i know how should i check whether my output format is correct or not,public,hw2
autolab couldn't identify programming langauge,my programs run fine on octave but gives an error on autolab has anyone experienced same issue and were able to resolve bad cannot determine your programming language from your source files hint did you write your answers in the same programming language and name them properly ps i am creating tar file using zip not sure if that is causing any issues,public,hw2
experiment,i input the alpha beta xtrain and ytrain in to function nb xgiveny and tried to plot the output but octave gave me a plot that is not comprehensible at all am i plotting the right thing,public,hw1
order of d,does it matter what order the element of matrix d is in for example can d have dimensions like thetax v y y or does it have to be thetax v y y,public,hw2
payoff x in q q in qna,is x defined as payoff in these questions or do we need to calculate the x entry fee and use that as input of mle,public,hw2
question,in this situation can i still discard the denominator in the nb formulae,public,hw2
negative theta as outcome in nbxgiveny,i've implemented the nb xgiveny function when i test it with alpha and beta some of the element of d has negative numbers is this possible or does this mean my implementation has a flaw,public,hw2
numpy accessing elements,i'm getting a too many indices error it says file hw script py line in print nb nb xgiveny xtrainsmall ytrainsmall file users anonymous hw python nb py line in nb xgiveny d i j thetayw i j alpha beta ytrain xtrain file users anonymous hw python nb py line in thetayw if ytrain i y the number of arguments in thetayw match up same for nb xgiveny so i believe its due to the ytrain i etc because y is a nx matrix is this to correct way to access the element at ytrain at row i column,public,hw2
xtrain ytrain,so this xtrain and ytrain will be array or matrix of s and s,public,hw2
my nb classify got a zero on autolab,the error message is not so helpful problem reading output of nb classify what did i do wrong it doesn't look like a timeout to me i created the tar file using software z instead of the command tar cvf hw handin tar logprod m nb xgiveny m nb yprior m nb classify m classificationerror m because this command raised an error my other functions got full marks autograder sat feb success autodriver returned normally autograder sat feb here is the output from the autograder autodriver job exited with status tar xvf autograde tar autogradehw autogradehw answer autogradehw classificationerror t m autogradehw data autogradehw generatedata py autogradehw grader py autogradehw log autogradehw logprod t m autogradehw nb classify t m autogradehw nb t py autogradehw nb xgiveny t m autogradehw nb yprior t m autogradehw octave grader m autogradehw python grader py autogradehw student answer autogradehw data vocabulary csv autogradehw data xtest csv autogradehw data xtrain csv autogradehw data xtrainsmall csv autogradehw data ytest csv autogradehw data ytrain csv autogradehw data ytrainsmall csv autogradehw answer q txt autogradehw answer q txt autogradehw answer q txt autogradehw answer q txt cp handin tar autogradehw cd autogradehw tar xvf handin tar classificationerror m logprod m nb classify m nb xgiveny m nb yprior m cd autogradehw python grader py trying to determine the programming language you used good octave detected start running test suite problem reading output of nb classify your total autograded score for this assignment submission is out of scores logprod nb xgiveny nb yprior nb classify classificationerror score for this problem graded by,public,hw1
likelihood expression for distributions with conditional densities,how do we generate the likelihood expression for distributions with conditional densities many of the questions in the homework have distributions that say f x if x in a certain range and otherwise for bernoulli it was simple because x was either or and we could raise the probability to the x but in these other cases x is not simply or how do we handle the otherwise cases when generating our likelihood expression,public,hw2
cannot create tar,when i try to run octave tar cvf hw handin tar logprod m nb xgiveny m nb yprior m nb classify m classificationerror m it won't allow me to create a tar error message is the following error invalid call to tar correct usage is filelist tar tarfile files filelist tar tarfile files rootdir,public,hw2
x given y and y prior,i am extremely confused with the map is p d theta p theta equal p x y p y what is the difference between p d theta and p x y or p theta and p y i understand the idea of using hallucinated samples to avoid over fitting however i do not understand conceptually how p theta beta beta beta is representing p y that should be the probability of a certain tag or in the hw it becomes more confuse as the programming has two separate functions nb xgiveny xtrain ytrain alpha beta nb yprior ytrain but only xgiveny has the parameters for the beta function as arguments yprior only has the ytrain argument,public,hw2
windows pc anaconda,i am a windows pc user and i'm planning to do the programming assignments with python which i have set up already i downloaded anaconda went through all the installation processes i just went with the default settings including advanced options such as adding path to environment variables when i write import numpy as np in python in the sublime text editor which i usually use for python i still get the message saying importerror no module named numpy i just checked that when i work in spyder which is the text editor python console software included in the anaconda package importing numpy works is numpy supposed to only work in spyder thanks,public,other
classification after training,i have two questions here i appreciate it in advance for anyone who can help me why do we we use posterior not likelihood as criterion for classification are the posterior for classification the same as the one we use map training,public,hw2
after submitting score is zero,my code runs on octave and displays error when alpha and beta but when i submit it on autolab my score reads zero can you help me out with this thanks in advance,public,hw2
autolab small deduction in nb classify,i finished all problems in autolab but got a small deduction in problem nb classify the autolab showed nb classify i had no clue to debug this problem do anyone give some hints or suggestions thanks,public,hw2
consider ytest as ytruth,should i consider ytest dataset as ytruth when testing the performance of my classifier since i noticed ytest isn't any parameters of all functions thanks,public,hw2
autolab test with octave,i finished my code using octave and submitted on autolab but got zero for all questions i tested all the codes in my laptop and got correct answer and i checked the way i tar all files and it is also correct i don't know why all the scores are zero does anyone know what the problem is thanks,public,hw2
qna q probability density function,in question it is given the probability distribution function i think it should be called the probability density function or just probability distribution as i known there is no such called probability distribution function appreciated,public,hw2
within a margin of,in qna it says to write numerical answers that are fractions within a margin of does this mean when i can't neatly express it as fraction to round off so that i have numbers after the decimal point for example if my answer is i should write it as and if my answer is i should write it as thanks,public,hw2
getting ypred as all zeros when training with small training sets,my y predicted turns out to be all zeros when i train with the small training sets xtrainsmall and ytrainsmall i get a combination of ones and zeros in the predicted output when i train with the large training sets xtrain ytrain autolab gives me full marks but something feels strange with all predicted labels begin zeros is anyone else seeing the same please also comment if you see a combination of ones and zeros in y predicted so that i will know that i need to re check my code and that it is not simply a bias in data,public,hw2
qna,hi all i am confused in qna does that mean that i need to use the function nb xgiveny xtrain ytrain alpha beta to calculate the d with different alpha and beta and then calculate the number of elements in d that are in the interval respectively and choose the alpha and beta with larger number of elements in this interval thank you,public,hw1
why can't read csv files in hw script py,i used pycharm as an ide and completed my part of code when i tried to run hw script py it said ioerror errno no such file or directory ' data vocabulary csv' but actually i have put the data file in the same folder with nb py and hw script py i tried lots of times and still failed to fix this could anyone please tell me how to do thanks a lot,public,hw2
'tar' is not recognized as an internal or external command operable program or batch file,when i try to use tar on cmd console 'tar' is not recognized as an internal or external command operable program or batch file shows up i have cygwin installed but this shows up anyone know how to get this fixed,public,other
where is the lec whiteboard,thx,public,other
q,i've computed the mle expression for but i'm not sure what to do with the payoffs from as this a list of uniform values how do i incorporate that or is computing the expression the wrong way to look at it,public,hw2
q map,trying to figure out calculating map i first plugged in gamma x for the f y equation and then plugged in y to that equation but i'm wondering if that's the wrong order now i'm trying to find the log likelihood of x e x and i realized i have no y to take the derivative of should i be taking the derivative of x or did i do this in the wrong order,public,hw2
collaboration questions,on the question did you receive any help does that include tas,public,hw2
are the functions in autolab checked independentlt,hi i was just thinking if the functions in autolab are run independently or run like a pipeline such that if one function is wrong than all after that will be wrong i mean this in terms of submission thanks,public,hw2
parameters of category vs bernoulli,in the second part of find parameters we are asked what if p x y theta is categorical not bernoulli but what does this mean since x y can only be zero or one it should be bernoulli does this mean x can be some value other than and here there is no hyper parameter involved yet what is the meaning of catergory distribution if x can only be zero and one what is the difference thanks,public,hw2
autolab testing,i finished my code and submitted on autolab but only got points for the classification error question it tells me that it has problem reading the output for nb classify but i tested all the functions with the given data in python and everything worked perfectly does anyone know what the problem is thanks,public,hw2
where can we find info about the office hour timings,where can we find info about the office hour timings i searched in the course website but could not figure out,public,logistics
where's whiteboard and video for lecture linear regression optimization for ml,where's whiteboard and video for lecture linear regression optimization for ml thanks,public,other videos
oh today,hi all sorry due to an emergency i couldn't be there for my oh at i will be holding oh today at pm in th floor commons to make up for it apology for the inconvenience,public,logistics
office hours,hi according to the course website there are oh's at in the th floor of ghc there are about students here waiting including myself there are no ta's yet thank you,public,hw2 logistics
office hour,the schedule page of shows that there is office hour in th common area in ghc but by clicking the map there is no exact place and i wonder where is the common area on th floor,public,hw2
what values of alpha beta should be considered to test the results locally,hi everyone can someone suggest me what values of alpha and beta should be considered to test results on local computer i tried with values like and where i got all my predictions to be and when i did i got few nan's as theta became negative and that made log ve thanks in advance,public,hw2
autolab error,when i try submitting my autolab says error message unexpected token at 'cd autogradehw python grader py',public,hw2
hw what distribution to use for y prior,in the coding question for calculating nb yprior using ytrain should i assume that my prior has bernoulli distribution or beta or does this not matter at all,public,hw2
octave,hey can someone tell me how to download octave for mac or can i continue to use,public,other
argmax vs argmin,when do you use argmax and when do you use argmin also for the theta why are there two columns for theta shouldn't it just be one theta and then find the likelihood for when y and when y including a second column of thetas doesn't make sense,public,other
octave,once installed the prompt says that the gui version of is experimental windows so is there any other alternative,public,logistics
question,hi i'm having trouble applying mle to a list like this is there a basic procedure for how we are to proceed map is also confusing me for question i haven't seen a lot of simple examples like this for either so i'm not sure how in depth the calculations need to be or even honestly how to apply the information to these equations tried going to oh but it was too crowded,public,hw2
how to implement argmax,hi given the following formula i don't know how to implement it in my program so that can get y what we have is the map estimate of p x y and the mle of p y they are all calculated as actual values if we multiply them we would get real numbers so how to maximum the value and get the most likely labels like the coding question we need to classify each row of xtest using the result of q q thank you,public,hw2
midterm exam,hi all the midterm exam is scheduled to take place on tuesday march th from pm to pm although the exam may not take the entire h min we ask that you be available during this time frame section a will take the exam in ph sections b and c will take the exam in dh note you will be allowed to bring a page sheet of notes front and back to use during the exam warm regards brynn,public,exam
expected error rates,i finished working on the hw and now i am running my program i created a small test with manually calculated probabilities and the algorithm gives the expected values now i am running it with xtest and ytest what error rates should i expect,public,hw2
q map guttenberg distribution,the question is with the same data as the previous question drawn from the guttenberg distribution assuming a standard normal prior over the values of calculate the map estimate of report the value of just want to make sure this question means alpha normal or it means the pdf of the prior is pdf of normal alpha a bit confused about this,public,hw2
autolab submission error cannot determine programming language,hello i am getting the error pasted below i wrote my script in sublime using python but have made sure the script runs properly on my machine with python any ideas i am creating a tar file that only contains nb py i've also tried naming the tar file hw handin thanks michael bad cannot determine your programming language from your source files hint did you write your answers in the same programming language and name them properly traceback most recent call last file grader py line in main file grader py line in main raise exception submission error exception submission error make all error,public,hw2
generative vs discriminative models,what is the difference between generative and discriminative modeling any example which one is better than the other under what circumstances,public,other
testing,when using the provided script for testing are you suggesting that we perform unit tests for all functions i e in the case of nb xgiveny create for example a x matrix for xtrain a corresponding vector for ytrain and so on calculate the results we expect and then check if our code outputs the same results,public,hw2
mle,can mle be greater than or does it depend on the distribution being bernoulli or uniform,public,hw2
priors in naive bayes,in lecture we show that the number of parameters for naive bayes is only m but this only accounts for all p theta i not the additional prior p phi is the value of this prior considered a parameter to find in the naive bayes model,public,other
bayes parameters,in lecture professor gormley said m parameters are needed without the naive assumption why isn't it m parameters isn't it possible to condense the number of parameters we need if p x x x y p x x x y also what is the significance of including the minus in terms of complexity it seems frivolous to write thanks,public,other
number of submissions per assignment,is there a cap to the number of times can we submit our code to autolab,public,logistics
about hw recitation,what will be covered in todays recitation something new or solving doubts from hw,public,hw2
bernoulli parameters,for the generative story in model bernoulli nb in lec what does the phi refer to is true or false the only value for theta thanks,public,other
office hours this week,hi all my office hours this week will be changed to friday feb th pm matt,public,other
naive bayes y sampling,in class today we studied cases of how y is sampled bernoulli and categorical can y be sampled from a gaussian distribution i have a feeling the answer is yes but i wanted to know if there are any reasons for or against using this distribution,public,hw2
failing unit tests,is there a way to access the unit tests to get an idea to why a certain function might be failing my nb classify seems to only want to give me a on,public,hw2
how to represent the data likelihood for non bernoulli distributions,on previous lecture when we wanted to obtain map the first step was to get the data likelihood when working with bernoulli there is a trick that allows us to get rid of the if statement but i am not sure how to apply this concept to other distributions such as the gaussian discussed in today's lecture how can i interchage phi by mu sigma in this model,public,hw2
can someone please tell me where is hbh,there will be an office hour tomorrow at hbh so what's the full name of the building and where's its location thanks,public,other
how exactly can we use hw script to test out the functions,so i'm using octave and want to test my codes by using hw script but i don't know how to use it do we need to implement some lines of codes in it,public,hw2
q understanding,i am wondering whether i am understand the problem correctly for each point we need to find the closest point including itself by compare distance x y and get the majority label of them and then set this label as training result compare this label with it real label get how many percentage is rightly predicted so the whole process is about training there is not test set or validation set at all,public,hw2
office hours today,hi where are the office hours today i'm outside ghc but there's no one here thanks,public,logistics other hw2
office hours for yongjin updated,hi all my office hour schedule is updated please take a look at http www cs cmu edu mgormley courses s people html,public,other
naive bayes phi and theta in plain english,hello so i've been reading through the notes on naive bayes and the process is making sense to me but i'm having a hard time conceptualizing the phi and theta values that we are supposed to be estimating is there an intuitive plain english explanation of the values anywhere thank you,public,hw2
readings on continuous optimization,hi all required reading this week's reading on optimization for ml comes from geoff gordon's lecture notes this is not considered background material we do not expect you to have prior experience with convex optimization continuous optimization lecture notes https qna cs cmu edu pages view optional reading if you are looking for a much more advanced treatment of the same topics you can also check out boyd and vandenberghe 's textbook which is free online this is the place to look after today's lecture if you'd like to learn a lot more particularly about convex analysis the b v textbook is entirely optional our focus is the material in chapter convex optimization boyd and vandenberghe http web stanford edu boyd cvxbook cheers matt,public,other
logprod function,why do we need logprod function it's just summing the numbers for example if x then logprod x i can use sum x for that,public,hw2
question,what does any of and mean like out of the possibilities of those what is the probability that these numbers showed up,public,hw2
will only the final version be viewed,will only the final version we submitted to autolab be viewed or all versions will be viewed,public,hw2
is it ok to use octave,just want to make sure,public,other
qna questions,qna question what does the following mean for the following questions you should assume that the test results are independent of each other conditioned on the true state cancer or no cancer i would understand if the conditioned on the true state cancer or no cancer part wasn't in there that phrase is kind of confusing me also if i think the mle and map converge together as the data increases is that the same as map converging to mle,public,hw2
get points on nb classify,i got points on nb classify and the total points is what does it mean i can not find any wrong message on the grader,public,hw2
question about the mitchell's book,when i was reading the new edition of tom mitchell's book i found one thing that i can't understand in chapter section it says that for equation theta ij equiv p left x x i y y j right to calculate the exact number of required parameters note for any fixed j the sum over i of theta ij must be one however according to my understanding assuming y is a boolean variable then the sum over i of theta i the sum over i of theta i should be ranther then only theta i or theta i,public,hw2
logprod function,what does log means log or ln,public,hw2
where are monday office hours held,they are with edward thanks,public,logistics
on problem,hi all in problem p x x y y is a categorical distribution but no parameter on the categorical distribution is provided in the description e g how many categories can anyone clarify best evan,public,hw2
mle of categorical distribution,in lecture when we used lagrange multiplier method to get mle of categorical distribution the last step was how did we get from the two results of each derivative set to to the final result of theta j thanks,public,other
hw script,do i have to do something to be able to call the functions from nb py i tried just saying print logprod and it said that the name was not defined,public,hw2
section c attending class in person,hi section c there are now plenty of open seats about in section a am am ph please attend in person if possible section b pm pm ghc technically has open seats you are welcome to try to attend in person but must give priority to those registered for section b if there are not open seats we unfortunately will have to ask that you continue watching the online lectures cheers matt,public,logistics
qna,hi i have confusion in solving question can anyone provide the hint to solve this problem especially how to take the f x f y into the expression thanks,public,hw1
q,for questions on the qna i'm having a difficult time understanding how we can use x and y to find the mle for p a b does this individual base his probability on what y's outcome is too,public,hw2
number or ratio on q,q ask us to calculate the classification error i want to know that whether the error is the number of error points or the ratio of the error to the whole dataset,public,hw2
shall we write answers like or,does answer as a number fraction or a decimal e g or within a margin of mean that we need to transmit the answer to or it's fine to answer,public,hw2
installing jupyter notebook,i have python preinstalled on my mac should i install anaconda as recommended by the website to install jupyter notebook also should i install jupyter before i can open the python tutorial ipynb my mac does not recognise the format of it as of now thanks,public,hw2
classification vs training error,is classification error the same as training error or is it a more general error for which training error is one example thank you,public,hw2
where is the video for the lec on wed,is there a link for all the lectures,public,videos
q in qna y,y is using the same value from q however y means the coin toss outcome reported by the person in q or the person in q,public,hw2
probability density vs probability,i feel like there is a simple answer for this question but it's not clear to me from the notes in our example of a map estimate we look at a bernoulli distributed random variable we go on to make the assumption that the parameter is from a beta distribution and we write out the probability density function it then follows that the probability of being in an interval a b is the integral of the density function over that interval everything makes sense up to here but then when we define the prior in our map estimate it appears that we use the density function not the integral of it why aren't we using the integral,public,hw2
install octave,hi i have difficulty in installing octave in windows i try much but none of them can work well who can provide a tutorial that describes the detail thank you,public,hw1
q ambiguity,hi the question asks us to compute the value of alpha then asks us to report the value of alpha which answer should we submit thanks,public,hw2
question in qna validation set,here it says that training set and test set have been drawn from the same distribution but in actuality error is minimised using the validation distribution does this mean validation isn't included could someone help me out with this thanks in advance,public,hw2
how to compute alpha and beta value of a beta distribution,we considered that the prior for bernoulli's follows a beta distribution now how do we calculate the parameters alpha and beta of this beta distribution won't we have to again compute the mle or map for this beta distribution thanks,public,hw2 other
choosing beta distribution as a prior for bernoulli's distribution,why did we only consider beta distribution as a prior for bernoulli's distribution and not some other distribution i read that the conjugate pair for a bernoulli's distribution is beta distribution so does this become a rule that if our likelihood is a bernoulli then our prior will have beta distribution thanks,public,other hw2
converting data to log space,hi as said in homework we transform the data into logspace to avoid precision error especially in case of probability when the values are in between and if this is the case then why do we normalize the data and get the data in the range of to aren't we unnecessarily leading to precision loss errors due to normalization thanks,public,hw2
get points in nb classify,my submission to autolab shows that all the tests except nb classify is passed and for nb classify i get points reduction it's bizarre since i get full score for nb xgiveny and nb yprior part i cannot get any useful information in the feedback given by autolab what may be the reason,public,hw2
map assumption probability of success in bernoulli trails follows a beta distribution,in the lecture matt assumed the prior for a coin toss success or heads to follow a beta distribution isn't the whole point of a prior hmm coins are usually fair so my prior is phi is the hallucinating data dependent on the choice of alpha and beta i e the choice of the prior does choosing alpha and beta such that phi is strongly weighted towards the side create more heads in the hallucinated data,public,hw2
q classification error,in q the classification error is the percent misclassifications or just the number of misclassifications,public,hw2
confusion about the output of the function nb xgiveny,for the function nb xgiveny in the handout it says that the entry of output d y w where y is the class label however in the previous parts it says the class label in ytrain equals to or however in octave the index of element in a matrix starts from that means y cannot be so can this y be different from the class label defined in the ytrain,public,hw2
python recitation resource uploaded,hi all the notebook file we used for python tutorial and the resources for getting started with octave is now uploaded at the resource page of the course piazza,public,other
how to move a vector to log space that contain elements with value,on the programming instruction there is hint which says hint in this function you will want to use the logprod function to avoid numerical problems what happened if a word has occurrences when y how do you move the the x vector to the log space since log is undefined,public,hw2
access to jupyter notebook,hello i installed jupyter notebook but i could only view the files on my own laptop how could i see the python notes on the recitation of february thursday,public,logistics
understanding of last part of lecture,do i understand it correctly that the p x y theta is in fact one of the small theta in the theta matrix,public,other
when is hw due,when is hw due,public,hw2
tom's book what does the intuition behind map's fomula,hi all in tom mitchell's book chapter he says for me definition of theta mle is quite intuitive what underlying parameter theta generates such data but i don't understand why we want a theta that maximize the chance that p theta d presents what does p theta d means does it means oh i see the data let's guess what the underlying parameter theta is i have so many guess options theta theta theta and there must be a theta that makes itself most possible given current data we see it seems circular reasoning for me and this is why i feel uncomfortable about tom's explanation on map however if we apply bayes rule and want to find a theta that maximize p d theta p thata i feel a little bit more comfortable as p theta means knowledge and p d theta is what i feel good about but i still be confused about the intuitive meaning of the multiplication here yes this is absolutely correct mathematically but i just cannot convince myself to believe it finally i know bayes rule and i understand all induction here i want some help on intuitive explanation thank you so much for time on this weird question best evan,public,other
confusion about ytrain,ytrain states that is a d numpy array of length v which is the size of the vocabulary but the handout states ytrain is a n xd dimensional vector containing the class labels for the training documents ytrain i is if the i th document belongs to the economist and if it belongs to the onion which is it,public,hw2
probabilistic decision rule,hi all i don't understand how does probabilistic decision rule work can anyone give me an example on this thank you,public,other
python,can we use python for this course or python is better,public,hw2
recitation,could you please conduct the recitations on weekends many of us are facing course conflicts we would at least be able to attend it if not could you please record it,public,logistics
how to calculate classification error,i understand how to classify a query point by using knn but i'm nor quite sure how to calculate the classification error can anyone provide me with an example with the specific math,public,hw2
expected runtime for the categorical distribution example th january lecture,could you please explain the expected runtime concept discussed for the categorical distribution k the answer discussed was theta theta theta theta theta theta,public,videos
testing error vs training error,i'm still confused about these two concepts ask for an explanation thanks a lot,public,other
the place for oh today,could you please tell me where the oh holds thanks,public,other
hw,how can i see the answers for hw,public,hw1
background test class statistics,it was mentioned in the lecture that the class performance on the background test has been made available for viewing where can i find these statistics,public,hw1
why does p y x theta p x y theta p y theta,hi i have a question in the video from to where professor described that the decision rule y hat h x is defined as argmax y is p y x theta then he said according to bayes rule p y x theta is equivalent to p x y theta p y theta could someone explain to me why would bayes rule generate such result thanks,public,videos
scores for hw,how can we see the scores for hw,public,hw1
setup sublime text for python,i took here at cmu where we used python with the sublime text as the text editor and so my windows pc has those set up sublime text editor working for python code i downloaded python today and i would like to make my sublime text editor to work for python codes can anyone explain me how i can do this i've asked someone and he told me to add the python directory path to my environment variable path and change python into python in the python with ui options py file but my sublime text editor still only works for python and not for python thank you,public,other
use of octave,couple of questions if we are using octave can we use it via windows will we be able to do the tar function while submitting octave code via windows machines,public,hw2
an error occurred when clicking submit button on qna,hi when i hit submit button on qna an error occurred could you please help me with this screenshot is attached thanks,public,hw2
why nearest neighbors of k equals one has zero error rate,i am confused of about what is one nearest neighbor does this include the test example or not if this single one nearest neighbor is not the test sample itself but its nearest neighbor then we can not make sure our prediction is right if this nearest neighbor is the test sample itself then we cannot predict anymore if we do not have the original data we cannot make any prediction based on the test sample itself it will be a recursion,public,logistics
homework has been released,hi all homework is now posted you can find the pdf handout for the homework in the resources tab on piazza the homework consists of two parts you will submit the first part of the homework through qna and the second part through autolab see the pdf handout for detailed submission instructions collaboration policy questions are included at the end of the qna section,public,hw2
choosing k in knn,when choosing k for knn should we choose k based on the number of classes we know exists in reality or should we choose k based on the minimal error we find through f fold cross validation for example in the post office example their are only possible choices for each digit when recognizing the digits in a zip code so it seems like here k must be but are their examples where you'd use cross validation over the known number of classes,public,videos
how to submit hw,just want to double check that as song as i finish all of the questions in qna i'm all set,public,hw1
when will hw be released,hi i see hw is released today on slides but i cannot find it on course website https www cs cmu edu mgormley courses s coursework html thanks,public,hw2
map vs mle,when do you use map and when do you use mle what is a lagrange multiplier why can't you use lagrange multiplier for map,public,other
lecture,can someone just explain what's going on in this part i don't understand what's happening in the likelihood part and why you log the likelihood,public,other
argmax,why do we log for both mle and map what's wrong with our function,public,other
matt's office hours this week,hi all i'm shifting my office hours just this week to fri feb pm pm the google calendar is updated accordingly sorry about the moving target cheers matt,public,other
hw collaboration policy,hi all for homework we do not require a collaboration policy however going forward all homeworks should be submitted with a collaboration policy as discussed in matt's first lecture remember that these should be filled in completely honestly as we will follow up any course conduct violation thanks,public,hw7 hw6 hw4 hw5 hw3 hw2 hw1
recitiation jan slides,hi could we get access to the material which was taught in the recitation today we missed the recitation,public,hw1
recitation problem,i am quite confused about the time and space complexity of the fibonacci number based on recursion method in the recitation the ta told us that the time complexity is o n but by the formula t n t n t n i think the time complexity is o n which one is right talking about the space complexity of this recursion method it will occupy lots of stack space because of the inefficient recursion calls but for the space complexity though it doesn't save any result but i do think the space complexity is based on the recursion depth which is o n rather than the constant space o i am really confused about this and hope someone could help me with this problem,public,hw1
big o limit approach,this is the scenario that we were discussing on today's recitation the one that in the excel seemed to give one answer and then another one way of being sure is with the limit approach step by step since both tend to infinity we apply l'hospital derivating numerator and denominator since both tend to infinity we apply l'hospital derivating numerator and denominator note you can discard constants since both tend to infinity we apply l'hospital derivating numerator and denominator note you can discard constants which means that generally you will see a trend without having to do all the derivations general rule,public,hw1 exam
recitation cs foundations programming sections,hi all there will be a recitation at tonight in ph to review the material covered in the cs foundations and programming sections of the background test there will be one session for all sections of the course thanks sarah,public,other
is there any recitation today,i see there's a recitation posted on the course website but not here could you please tell me wether there is a recitation today,public,other
office hours schedule,please find office hours schedule here if place not listed by default it is ghc th floor lounge outside,public,logistics
oh today,do you have office hours today,public,hw1
is homework background test graded by sections,i'm sure the professor already addressed this before but i just need clarification are the homework and background tests graded by sections this means if i got all of the programming part of the background test right i do not have to do the programming exercises on homework and still get,public,hw1
hw collaboration policy submissions,do we need to submit information concerning the presence or absence of collaboration for homework as defined here in the course about page,public,hw1
how to check hw submission status,hi all i already submitted all answers for hw where can i check my hw submission status i went to gradescope but didn't see any record items related to hw thank you,public,hw1
awesome materials utilizing knn to recognize images,professor fei fei li et al from stanford use knn to conduct image recognition as she mentions knn is never been used but she really gives a good example that is really easy to understand how can we apply knn to do something tons of images with detailed explanation hope it helps http cs n github io classification,public,other
edward's office hour this week,sorry for the late notice but i am out of town today and so i have to move my oh to thursday,public,other
programming question,hi i do not quite understand programming section question from what can be seen from the code it will only update position and position len a in fact i tried it out in python and it shows me only places are updated how could it end up with the following options,public,hw1
background test q big o notation,can someone help me understand the logic for comparing complexity of n and n the point of intersection for both graphs is i used a calculator to find and to see how the curves behave beyond that point the intuition isn't clear to me how would you approach this problem without a calculator,public,exam
big o notation,i would like to see a graph comparison of o n o n n and o c n can someone provide a resource or draw it out,public,hw1
meaning of the symbols in home work system,what are the meanings of those symbols i have clicked submit for all the questions but why some of them looked different,public,hw1
background test,for question why is the answer false and not true,public,exam
background test question,the question asks what would be the space of the optimal function in terms of memory usage for fib x and asserts the correct answer to be constant space the optimal function for fib x would store previous values so they don't have to be calculated again memoization storing previous values would use o n space where x n since x values would need to be stored in total i don't understand how a function like this could use constant space for memory storage thanks in advance for your help link to background test,public,hw1 other
recursion,i came across the statement anything that can be solved recursively can also be solved iteratively is this statement always true are there no exceptions to this could someone provide any intuition or resource to help me appreciate this claim,public,hw1
stable error,while i understand it is desirable what does stable error actually mean,public,other
q background test,most efficient way to determine if the median of unsorted array with numbers in is answer given merge sort and lookup o nlog n linear search can be used with two counters one for the ones and one for the number of elements less than this is o n what am i missing here,public,exam
qna no courses on the homepage,so i am able to login the qna website with my andrew id and password but i was not added to any courses is this normal for everyone,public,other
determinant,is a determinant always positive,public,hw1
test training errors,where does if d is then y i if d is then y i come from and what does it mean exactly is it related to the test training error plot but the y axis on the plot represents errors do the percentages for training validation and test in d train and d test demonstrate the proportion of data belonging to training validation and test i e for any given learning algorithm approximately of its total data intake is for training for validation and for testing what does validation refer to,public,other
where is the x test on fisher iris data,could you point out where the x test on fisher iris data is for the special case on p of lecture when k is there one x test point for every colored dot what is the definition of gaussian data,public,other
how many sections exist in background test,hi are there prob stats math cs programming or are there flipping out mean variance etc each of the sub headings under the previously mentioned four this affects the questions i need to do for credit thanks edit just saw on the course webpage that the number of sections is four so must be the first option,public,hw1
optimization resource,please suggest share resources for optimization,public,hw1
probability question notation,in this sentence p x y does ' ' mean 'or',public,hw1
clarification on big o,i tried to look up how to solve the background questions on the big o notations since i missed the recitation and the video is not up it says to set a constant to be solved to check if the two functions are equal however i am still confused on how to solve questions and of that section could anyone provide some sort of proof for it so far for question i get c log n n and for question i get c n n what is the next step to prove this,public,other
still can't log into gradescope,when i tried to log in with my andrew email and password it said invalid email password combination anyone can help me out of this problem thanks,public,logistics
answer of background test algorithm problem,i think the problem can be solved in linear time we can know whether the median is by counting the numbers less than one and larger than one,public,hw1
course conflict google form,hi all we are trying to find out how many people may have course conflicts with recitation times and possible future exam schedules as such we would like you all to fill in this quick less than minutes form to give us some valuable information scheduling conflicts form thanks ta staff,public,logistics
background test has been added under resources,hi all we've uploaded the background test to the resources section note that this a corrected version if you took the background test on you had a slightly different version of question and the correct answer was b only while on this version it is both a b you can view it on the course page https piazza com cmu spring resources,public,exam
hw programming q,could somebody help me understand the differences between dp and recursion i'm having trouble understanding the exact nuances and the internet isn't helping much,public,hw1
background test score for each section,dear graders how do we know how many points we got for each sections so we may not need to do the hw for that part or we have to do all the parts no matter whether we got perfect for each section thanks a lot,public,hw1
where can i find recitation video of,hi i looked at there https scs hosted panopto com panopto pages sessions list aspx folderid c f e fd f f b e cd dfb foldersets and cannot find it has it been posted thanks,public,videos
question paper for background test,how can i see the question paper for background test in gardescope only the answer sheet is added it will be very useful if we can see the questions for which we got wrong answers and then learn from it,public,hw1
homework,hello i just saw on autolab that homework has been released and it's due on monday with no handout do you mean homework also i still can't see my exam scores on gradescope when will those be released so that i can do the right homework questions thanks,public,hw1
hw programming question,i'm confused about question to me fact produces an error because of overflow the integer result is too massive to represent how would any of the choices address this memoization this won't help overflow it just increases speed use a different programming language still bounded by computer architecture fix a logical error i don't see one and fixing one wouldn't address overflow get a laptop with more memory again not addressing overflow any pointers thanks,public,hw1
hw linear algebra calculus q,i think that there is an error with q 's correct answer either a log x is missing or a should be changed to,public,hw1
office hours for ta,who are having office hours tomorrow please reply with timings and location at the earliest,public,logistics
hw linear algebra calculus question,just for clarification is this question if you take the derivative of x x set the derivative to and solve for x you will find asking about what x is or what the corresponding polynomial is,public,hw1
additional background materials,hi all i just added a few additional probability linear algebra resources after the lecture notes in the piazza note resources for math review see them here cheers matt ps if you find any excellent review materials feel free to send suggestions via a private note i e only to instructors we'd be happy to hear what you're reading and pass along references if appropriate,public,hw1
ml an algorithmic perspective,does the course instructor have any opinion on this book,public,other
does how much of hw we have to do correctly depend on our test score,title thanks,public,hw1
homework corrections,hi all so there have been a few mistakes fixed in hw which i will use this post to highlight so you can head back into the qna and change your answers for them here are the mistakes prob stats question heads is and tails is this was the wrong way around and has been fixed please fix your answers respectfully programming the code for q programming had an infinite loop it has now been fixed,public,hw1
video recording for recitation,hi there i am wondering whether the today's recitation would also get video typed thanks in advanced,public,other
q probability and statistics,consider the following joint probability table where both x and y are binary variables does binary also imply that these values are equally likely i e p x p y,public,hw1
office hours,when are the office hours for the instructors,public,logistics
big o notation,just wanted to confirm whether the ' ' signs on the big o questions should instead be in instead,public,hw1
statistics heads and tails,hello for the statistics section of hw problems define heads as a and tails as a however questions use the same sequence but define heads as a and tails as a so how should we interpret the sequence for questions t t h t h or h h t h t thank you,public,hw1
probability and statistics question,is anyone else also getting as the answer its not in the options,public,hw1
might have mistakes in programming part q,the question is shown below while i length a while j to length b if a i append output a i else append output b j return output array it do not have i in it so the program will run forever but in that case none of the answers is correct,public,hw1 logistics
streamlining flow of information,hi a small suggestion for consideration is it possible to get one unified place for all the important information such as homework links exam details important announcements etc currently it is hard to keep track on piazza as the important stuff often gets buried under other posts and is easily missed it will be more useful if all the announcements assignments exam dates and other important info be posted on the course website,public,logistics
homework release links,hi all homework is officially released it is in four parts probability statistics linear algebra calculus programming cs foundations as described in the course the marks you get on these homeworks will make up for the marks you lost during the background exam so it is advised that you give these sections your best effort to try to achieve a full the homework is due wednesday at important note the due date on qna is not the correct due date the homeworks should be completed by by we will not accept excuses based on this fact as you have been warned good luck previous queries if we submit our answer we cannot change it anymore right answer when you click submit it saves your answer it will only grade the last answer you clicked submit to when the homework is due so you can change it just pick a different answer and click submit so we don't know how many marks we get until we click the final submit button answer you will not know your final score until after the deadline quick fixes prob stats question heads is and tails is this was the wrong way around and has been fixed please fix your answers respectfully,public,hw1
cs background,are there any materials covering the cs background for machine learning,public,other
when will our homework be released,hi when will our homework be released cuz i didn't see anything on the website,public,hw1
reading,when it comes to the readings on the course website i find there are different chapters in textbooks do we need to read all of them or just pick one of them,public,logistics
knn,can someone explain in more detail the difference between training data test data and validation data the one i'm having the most trouble understanding is validation data because it was just brought up in lecture without much explanation thanks,public,other
cannot see homework on autolab,i wonder if the homework has been released i cannot see any assignment on autolab,public,hw1
about usage of f fold cross validation,i have a question on finding k of k nn when we use f fold cross validation for each of the cases discussed in class cases for e g case train on folds and predict on we can potentially settle for a different value of k if that is true how to we concatenate all the predictions to evaluate error or we keep k of k nn constant when we use different cases of f fold cross validation in this case when do we find k thanks,public,other
when and where is hw going to be posted,when and where is hw going to be posted,public,hw1
lecture videos,hi all section c take note due to your overwhelming vote in favor of panopto of you preferred it we'll be sticking with panopto for the rest of the semester after each video is posted it will be available at the link below all lecture videos panopto folder https scs hosted panopto com panopto pages sessions list aspx folderid c f e fd f f b e cd dfb section c lecture is up there now and ready for you to watch cheers matt,public,logistics videos
test result,hi when can we expect the result of the test,public,other
when will we know our scores of background test may we receive the graded paper,thanks,public,other
what's hw on autolab,hi i've seen a hw on autolab but i'm curious what's that because we've just completed the test and there should be hw instead of hw and the ddl is so close thursday i'm quite curious what's it thanks,public,hw2
background test,can we bring calculator for background test,public,other
background test,i attend my class at ph so background test at same location right,public,exam
having problem access autolab,i got enrolled to section c yesterday still can't get access to autolab and gradescope do anyone from section c have the same issue,public,other
about k nn method,i have one question about calculating the distance in k nn method in the example of classifying the flowers iris all the data have the same unit length in inch or cm etc however if the data includes more diversity such as area and weight which do not have the same unit how should the distance between data points be calculated thanks,public,other
background test grade,hi i have confusion about the relationship between background test and exercise i wonder if the background test gets and background exercise get could the homework get the full score thank you,public,exam hw1
make up background exam schedules sent,hi all if you have been waiting to hear back from us regarding make up exam time and place then you should have received an email to the address you contacted the assistant instructors if you do not have this email please contact me immediately at dpbird andrew cmu edu the exams are scheduled this wednesday and this thursday so check your email and make sure you know which one to show up to please try to arrive minutes early so we can get everyone seated and started on time thanks daniel bird,public,exam
octave vs python,what is recommended in my experience python can be slow and octave can crash,public,other
makeup background test,hi is there a final data and location for the makeup background test thank you,public,other
skewness,i have come across the term skewed data set a lot in machine learning problems can you elaborate on that,public,other
programming in background test,it was mentioned that we would be asked to write pseudocode in the background test independent of programming language i don't fully understand what that means could you share an example of such a programming problem and a sample of the answer you would expect to it,public,exam
length of the background test,how much time will be given for the test and how long will it be,public,other
make up background test times,hello if we have sent in an email about being absent for the original background test and gave a list of available times when should we expect to hear back from the assistant instructors thanks in advance,public,exam
programming language,is coding in matlab the same as coding in octave can i submit my matlab codes in autolab,public,other
mathematics background recitation,hi all i will be hosting two identical recitations on thursday in ph the first recitation for sections a and c of the course will start at pm and end at pm the second recitation for section b will start at pm and end at pm the content of these recitations will be focused on probability statistics calculus and linear algebra of which you will see in the exam on tuesday and on the corresponding homework while recitations are not mandatory people who struggle with these topics will benefit a lot by showing up as these subjects are something that will help you grasp the fundamentals of machine learning i look forward to seeing you there daniel bird,public,hw1
will the lowest scored homework dropped,same as summary,public,logistics
lecture videos and poll,hi all for the first lecture we used two completely different video recording services going forward we're only going to use one to me there seems to be an obvious winner but i wanted to make sure you all agreed please briefly click through the two options and then vote on which you think provides a better experience comments are welcome panopto https scs hosted panopto com panopto pages sessions list aspx folderid c f e fd f f b e cd dfb mediatech https mediatech stream andrew cmu edu mediasite catalog full c a d de fd fba a e d note to section c these are recordings of the am and pm lectures respectively the lectures were identical so you can watch either one there is no need to watch both except to briefly review the options for the poll cheers matt poll question which of the two video recordings do you prefer o panopto o mediatech,public,polls videos
audit policy,hi all i just updated the audit policy on the course website please see below http www cs cmu edu mgormley courses s about html audit policy in brief we strongly prioritize students wishing to take this course for a letter grade that said i'm happy to allow students to audit section c and will sign the form at any time if you are currently registered for section a or b and wish to audit i recommend that you switch to section c to do so for sections a and b we will only allow auditors in after the waitlist has been cleared and everyone wishing to register for a letter grade has been given an opportunity it's possible this won't happen before the add deadline in which case we will not permit any auditors in a b matt,public,logistics
lecture video,when will the lecture video be available on the website thx,public,other
review for related probability linear algebra calculus,could you please give us links to review related topics on these three aspects we do not know which of topics on these areas are related with machine learning besides the murphy's ml do we have some cmu resources for math part,public,exam logistics
homework due dates,on what day of the week will homework usually be due for this class,public,logistics
probability and discrete mathmatics tutorial,anyone know some good overview tutorial for probability and discrete mathmatics thanks,public,hw1
notation in tom m mitchell's book same with what we use in this course,does the notation in machine learning by tom m mitchell same with what we will see in this course,public,other
autolab subbmit times,can we subbmit homeworks to autolab as many times as we want or only once,public,logistics
excellent geometric explanation on linear algebra,hi all for those who merely know how to calculate linear algebra stuff determinant inverse eigenvalues etc but have no idea how do all these magic work me here are excellent materials by blue brown that help me really a lot with tons of animation not long videos each minutes english version https www youtube com playlist list plzhqobowtqdpd mizzm xvfitgf he ab english version with chinese caption https www youtube com playlist list pl ycoezaqdvsudwj uetgct baxawraq hope it helps,public,hw1 other
qna gradescope and autolab logins,hi i am currently registered for this course but i did not get the links to autolab qna and gradescope have they been sent out to everybody or they are not available yet,public,logistics
pass fail policy,i wonder what's the differences if i choose to take the course and receive a pass fail other than the grade itself,public,logistics
python version,i was wondering for those of us who are planning on using python which version of python we should be using for the programming assignments i have had issues with auto grading and the syntax differences between python x and x in previous courses,public,logistics
absent for background test,if you are unable to make it to the background test which is scheduled for tuesday th of january at pm then email assistant instructors mailman srv cs cmu edu with the subject 'absent for background test' in the main body please let us know what dates and times you can attend between the rd and th of january for your benefit please include multiple dates and times during which you are available this test is scheduled for a hour block so plan accordingly,public,other
office hours,when are office hours and where are they,public,other
course policy about pass fail petition,i want to apply for pass fail for this class is it allowable in this class i have just downloaded the form from university registrars office can i just drop it at the office or should i first got any written permission from professor gormley thanks,public,other
qna autolab gradescope sign up,hi all we will be using platforms for hw submission and grading this semester qna autolab and gradescope for all of these we expect you to sign up using your andrew email if you do not do this you may not receive credit for assignments submitted under another email best brynn,public,logistics
is the background test pen and paper based,i understand that the background test will be in pen and paper mode will you allow notes during the exam,public,exam
gradescope code,gradescope is asking for a six character course entry code when signing up where can i find this code,public,other
hours required for homeworks,are there any reliable estimates of the average number of hours one would end up spending on each of the homework assignments for this course,public,logistics
some questions about the course policy,hi professor i am currently in the waiting list and as i saw from today's lecture we can actually audit this course may i know if i choose to audit can i still submit the homework and get some feedback may i know the deadline for dropping this course also according to the audit policy after i got the permission from the instructor i can register this course as an auditor however there is only a register option but no audit option in sio registration section am i automatically audited or it requires some additional action thank you so much for answering,public,other
background test tue jan pm,hi all this semester we've developed a new way to provide you with an early assessment of your background knowledge all of you will take a background test next week in the evening you are required to attend any points you miss on the exam can be made up through the background exercises i e homework see the about page below for more details http www cs cmu edu mgormley courses s about html background test homework background exercises the background exam is scheduled for tue jan at pm you are assigned to one of two locations based on your status in the course location if you are on the roster not the waitlist for section a you will be taking the exam in ph location if you are on the roster for section b the roster for section c or the waitlist for any section you will be taking the exam in mcconomy auditorium the exams will be identical across the two locations cheers matt,public,exam
why does section c occasionally have a waitlist,section c is not full nor will it be full it has effectively unlimited capacity the waitlist of section c requires some manual intervention so students are only moved from the waitlist to the roster about once per day if it's been two days and you're still stuck feel free to followup below,public,logistics
recitations,the pinned post about the waitlist mentions recitations however there is no recitation for this course on sio when will these recitations be held,public,logistics
project for this course and autolab question,hi instructors is there any project for this class are there any limit on number of submission on autolab looking forward to attend this course thanks,public,other
are you stuck on the waitlist we have a solution for you,to students currently waitlisted for each semester we run into the same problem more students register for this course than we have seats in the classroom some time after the add deadline enough students drop the course that we are left with empty seats those seats could have been given to those waitlisted but by then it's too late as a result many students excited about machine learning miss out to address this issue we've created a third section c this semester that is that is identical to the other sections except that the lectures are online students in section c will be required to attend exams in person and will have access to all other in person aspects of the course recitations office hours etc if you join section c you will be a full part of the course here's the good part if physical seats open up in the other sections you will be able to join for in person lectures too can we guarantee students in section c will eventually get a seat no however the historical stats are in your favor last semester b's final roster was about of the peak registration our peak registration this semester is about two thirds of that is only and we have seats across sections a and b so if you are currently waitlisted for section a or b we encourage you to sign up for section c i look forward to having you online and be sure to drop by my office hours so we can meet in person too cheers matt,public,logistics
programming languages,hi all this semester one of the key aspects of the homework will be implementing machine learning algorithms and running them on real data your assignments will be auto graded by autolab for each assignment you will be able to code in either python or octave an open source variant of matlab the two languages above were chosen carefully for a variety of reasons however we would like to know what your programming language preferences are as they may influence future offerings of this course matt poll question if you could choose only one language for all of the programming assignments in this course which would you choose o python o octave matlab o java o c o c o c o r o scala o haskell o lua o perl o javascript o ruby,public,logistics polls
welcome to piazza,hi all welcome to piazza we'll be conducting all class related discussion here this term the quicker you begin asking questions on piazza rather than via emails the quicker you'll benefit from the collective knowledge of your classmates and instructors we encourage you to ask questions when you're struggling to understand a concept you can even do so anonymously matt,public,other
